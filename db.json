{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/img/about_time.jpg","path":"img/about_time.jpg","modified":1,"renderable":0},{"_id":"source/img/agg-pro.jpg","path":"img/agg-pro.jpg","modified":1,"renderable":0},{"_id":"source/img/check-error-event.png","path":"img/check-error-event.png","modified":1,"renderable":0},{"_id":"source/img/email_1.png","path":"img/email_1.png","modified":1,"renderable":0},{"_id":"source/img/email_2.png","path":"img/email_2.png","modified":1,"renderable":0},{"_id":"source/img/google.jpg","path":"img/google.jpg","modified":1,"renderable":0},{"_id":"source/img/jalon.jpg","path":"img/jalon.jpg","modified":1,"renderable":0},{"_id":"source/img/judge_code.jpg","path":"img/judge_code.jpg","modified":1,"renderable":0},{"_id":"source/img/openfalcon-web .png","path":"img/openfalcon-web .png","modified":1,"renderable":0},{"_id":"source/img/programmer.png","path":"img/programmer.png","modified":1,"renderable":0},{"_id":"source/img/prometheus1.png","path":"img/prometheus1.png","modified":1,"renderable":0},{"_id":"source/img/promethues-alarm.png","path":"img/promethues-alarm.png","modified":1,"renderable":0},{"_id":"source/img/rule_file.png","path":"img/rule_file.png","modified":1,"renderable":0},{"_id":"source/img/sensu-support-platforms.png","path":"img/sensu-support-platforms.png","modified":1,"renderable":0},{"_id":"source/img/uchiwa.png","path":"img/uchiwa.png","modified":1,"renderable":0},{"_id":"themes/yilia/source/main.266c1c.css","path":"main.266c1c.css","modified":1,"renderable":1},{"_id":"themes/yilia/source/slider.096dc6.js","path":"slider.096dc6.js","modified":1,"renderable":1},{"_id":"source/img/sensu-diagram.gif","path":"img/sensu-diagram.gif","modified":1,"renderable":0},{"_id":"source/img/sensu组成部分.png","path":"img/sensu组成部分.png","modified":1,"renderable":0},{"_id":"source/img/tick.png","path":"img/tick.png","modified":1,"renderable":0},{"_id":"themes/yilia/source/main.266c1c.js","path":"main.266c1c.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/mobile.906508.js","path":"mobile.906508.js","modified":1,"renderable":1},{"_id":"source/img/bmw.jpg","path":"img/bmw.jpg","modified":1,"renderable":0},{"_id":"source/img/alipay.png","path":"img/alipay.png","modified":1,"renderable":0},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":1,"renderable":1},{"_id":"source/img/weixinpay.png","path":"img/weixinpay.png","modified":1,"renderable":0},{"_id":"source/img/openfalcon-func.png","path":"img/openfalcon-func.png","modified":1,"renderable":0}],"Cache":[{"_id":"themes/yilia/.editorconfig","hash":"daaa8757fac18f8735fadd0a37a42c06f421ca14","modified":1524802263658},{"_id":"themes/yilia/.babelrc","hash":"db600d40e93e6d8023737a65d58d3be7370e5e30","modified":1524802263655},{"_id":"themes/yilia/.eslintignore","hash":"ed9d8911ca08c3dd5072c48dd0be4d06f8897730","modified":1524802263663},{"_id":"themes/yilia/.eslintrc.js","hash":"303d25adf02ad65720e537a16a4a137d14bb755f","modified":1524802263665},{"_id":"themes/yilia/README.md","hash":"86757b00d393bd4956a252d92a469f11f2ae8914","modified":1524802263668},{"_id":"themes/yilia/_config.yml","hash":"18857cc465a26ef8b36dbdc2090669a4271778c8","modified":1524811746006},{"_id":"themes/yilia/package.json","hash":"ee6aa61f1cb89fd549e3e087c0232207a9c9ee30","modified":1524802263802},{"_id":"themes/yilia/webpack.config.js","hash":"da7657347109ddb4ab8602b219778117254677fe","modified":1524802264015},{"_id":"source/_drafts/my-secret.md","hash":"c8af738a7cfd9579ec83f89f53decedea107c23e","modified":1524802263329},{"_id":"source/_posts/Google-Full.md","hash":"6d536fd8c51be7beb42e7d38a26a32e7b1bf64d2","modified":1524802263329},{"_id":"source/_posts/be-yourself.md","hash":"073f7e8137b76a9f38d62828a6f5d7cc6fd821d8","modified":1524802263330},{"_id":"source/_posts/clean-code.md","hash":"ab847209d21f114f3acec5e1a26247074006920c","modified":1524802263330},{"_id":"source/_posts/compared.md","hash":"ed53474ede604a8b557cd0153975529b3f18c25d","modified":1526560751808},{"_id":"source/_posts/elasticsearch-monitor.md","hash":"a6b2f43dabf6356ed4e5e78e8484094bfa838f45","modified":1524802263334},{"_id":"source/_posts/git-github.md","hash":"4c3e1ba9327d199b0d7d59385a589a934f623e19","modified":1524802263341},{"_id":"source/_posts/hello-world.md","hash":"6886d51c210b73581b259618daf975e35236cf9b","modified":1524802263345},{"_id":"source/_posts/joel-on-software-1-1.md","hash":"42337890346bf6ebfdb8c6a7f8e66684b3c6f793","modified":1524802263348},{"_id":"source/_posts/joel-on-software-1-2.md","hash":"6acbe4d91d9c31d9b8d3a4206c9ca69cb25d975c","modified":1524802263352},{"_id":"source/_posts/lamp-build.md","hash":"a66d79b8be9ba5bd7d7b178b719f35efb3f466c8","modified":1524802263356},{"_id":"source/_posts/more-joel-on-software.md","hash":"46ec2714d7d2e1572efa101b5b7f79d7e759519c","modified":1524802263361},{"_id":"source/_posts/open-falcon.md","hash":"c5b408080642a0faaed74741fd1489a1a4718515","modified":1524808823717},{"_id":"source/_posts/phoenix.md","hash":"df27b7d5485794ac1bfffc087cdb64b2df90f1f3","modified":1526561554416},{"_id":"source/_posts/programmer-thought.md","hash":"b5040cc0c27693ba2c43d87636af0d552441170d","modified":1524802263364},{"_id":"source/_posts/prometheus.md","hash":"8fc794a9e68162336a61eb37120601d8f04508b9","modified":1524809675031},{"_id":"source/_posts/python-build.md","hash":"6b45d9d502f3acec3f5347d53e9d2688b1be0b98","modified":1524802263367},{"_id":"source/_posts/sensu.md","hash":"97d5f86634808e21f0c9ca4d79c05d4c1929158f","modified":1524805326550},{"_id":"source/_posts/tick.md","hash":"0b79d1d8a9b20e6a74874b4a2d5c2dc8a898534f","modified":1524809648104},{"_id":"source/_posts/wisdom-in-stocks.md","hash":"965b71e0ebbccb6b50a3116d5f4f82513d8c4872","modified":1524802263370},{"_id":"source/_posts/zookeeper-monitor.md","hash":"3061fb28c900aa6f1e309f80dee01f92934c667b","modified":1524802263373},{"_id":"source/img/about_time.jpg","hash":"89a86b255771bdac646343dc9c6c4a3075c01fa0","modified":1524802263378},{"_id":"source/img/agg-pro.jpg","hash":"5bffb7f623c6071595eac344cd13a3def22b2872","modified":1515419127131},{"_id":"source/img/check-error-event.png","hash":"3d70d6143e367c1c76d0fd9e98ea2a62c679c4f1","modified":1517390842467},{"_id":"source/img/email_1.png","hash":"5911e8d70ef39013be19dab6530bbfd1c0edfe3f","modified":1521794359342},{"_id":"source/img/email_2.png","hash":"41c649aa93a87649a9d8014696240a91b1c6a94f","modified":1521795790776},{"_id":"source/img/google.jpg","hash":"877f97f1dac3ec6bfb30fce3546c368831d1a0de","modified":1524802263389},{"_id":"source/img/jalon.jpg","hash":"dab191c8c6f5b0204a4af1f015c036c5c9d72ec3","modified":1524802263393},{"_id":"source/img/judge_code.jpg","hash":"224ebbf4949bd936a376dc3405bade46e1afcf08","modified":1524802263398},{"_id":"source/img/openfalcon-web .png","hash":"40757cd8437bb6caaaa2138f43a1e1a070fccec4","modified":1518165079852},{"_id":"source/img/programmer.png","hash":"f3decc389c703855f5da4a82baa045957ed910cc","modified":1524802263400},{"_id":"source/img/prometheus1.png","hash":"351f3f29d1d13b67335c0107eefa9dcdd723d733","modified":1520410489270},{"_id":"source/img/promethues-alarm.png","hash":"e6d3153926c7d365f6984dfda4583b582690ca92","modified":1521687624256},{"_id":"source/img/rule_file.png","hash":"cdeb8556bd66978cc37916afc14bcd827ce42837","modified":1521687964063},{"_id":"source/img/sensu-support-platforms.png","hash":"c8791a792b51731ebcb7dcd5e2cf28263de738ed","modified":1516590737146},{"_id":"source/img/uchiwa.png","hash":"97684cfb9ae228068dd9d363bc520f1a1b9edcb8","modified":1516617089229},{"_id":"themes/yilia/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1524802263673},{"_id":"themes/yilia/languages/fr.yml","hash":"b4be1c1592a72012e48df2b3ec41cc9685573e50","modified":1524802263676},{"_id":"themes/yilia/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1524802263678},{"_id":"themes/yilia/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1524802263681},{"_id":"themes/yilia/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1524802263683},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1524802263685},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1524802263687},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1524802263780},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1524802263783},{"_id":"themes/yilia/layout/index.ejs","hash":"ec498c6c0606acde997ce195dad97b267418d980","modified":1524802263786},{"_id":"themes/yilia/layout/layout.ejs","hash":"b471ab706d48e0be3f783eab1c94bf5878ef5a94","modified":1524802263789},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1524802263793},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1524802263796},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1524802263799},{"_id":"themes/yilia/source/main.266c1c.css","hash":"6b9cfabb81f021081a93da5a069674e9be910194","modified":1524802263997},{"_id":"themes/yilia/source/slider.096dc6.js","hash":"25e34d09ead8cabd34d777997c4b1f073918f6cf","modified":1524802264013},{"_id":"themes/yilia/source-src/css.ejs","hash":"cf7eab48d626433120d1ef9697f719a359817018","modified":1524802263808},{"_id":"themes/yilia/source-src/script.ejs","hash":"28abac2426761d7e715b38aadd86ce6549c8ae77","modified":1524802263967},{"_id":"source/img/sensu-diagram.gif","hash":"87a902f0a8274a48ae380b6f82ae8beb25032fd4","modified":1516348821686},{"_id":"source/img/sensu组成部分.png","hash":"e6d81e948584afddbe40ea3f53830fed494994ba","modified":1516347636657},{"_id":"source/img/tick.png","hash":"e0284ecfcca97173f6df1e864f4015776c2209ef","modified":1522658249739},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1524802263768},{"_id":"themes/yilia/source/main.266c1c.js","hash":"42f38b932426a0bd24a41343a75f8517ca00e8eb","modified":1524802264000},{"_id":"themes/yilia/source/mobile.906508.js","hash":"60329066ec16a2f264b438b94c9d1cc44a551f88","modified":1524802264009},{"_id":"source/img/bmw.jpg","hash":"ddfef63ef878c15f0bc0ab0847d5aeab7c0af43c","modified":1524802263386},{"_id":"source/img/alipay.png","hash":"e6ba6d37773c24a784f877962e2563ea5fbcf2a9","modified":1524810473622},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"c70f367f54064a441e574c913f5e0ea121d0f899","modified":1524802263692},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"edc0154b30a4127acda10297bec6aacf754b4ac4","modified":1524802263695},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a4eacc2bc1278095a0ef99f904b0634c78f980eb","modified":1524802263697},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"751e5deab5365348be5243688b419c82d337ab9a","modified":1524802263702},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"dff6e1f3b5e82495ec776baa24d9e6bbaad883df","modified":1524802263699},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"155327c23607f69989b58845f24d842a54e504b8","modified":1524802263705},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"871f81cacd5d41cb2eb001cd56254217a857dc2f","modified":1524802263710},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"9bfcbd9e71401b6da6b2bbbe61e97625ca247b7a","modified":1524802263707},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1524802263712},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"12ca7d8dba56bc767b9309dda9526dcbaffc1614","modified":1524802263715},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"b69855e07b65117769adc515cb64b803932068c9","modified":1524802263717},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"e2b3f2b3631ef211a4d98d11f0da2d285340f10e","modified":1524802263719},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"11550a418921d330e6553be0569a94ab5a217967","modified":1524802263723},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"ccec1fc70f021cb50ac85b524e7949878ab93a18","modified":1524802263729},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"0ffcb251b79e8a920c9b4cb6bb7a96a808816165","modified":1524802263771},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"cc1c39903aed0a0601d104238d2bbd13ad2a36f3","modified":1524802263777},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1524802263976},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1524802263972},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1524802263979},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1524802263983},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1524802263981},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1524802263985},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1524802263988},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1524802263991},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1524802263995},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"29ba600e98ed55f7af4ade8038272c84cba21188","modified":1524802263812},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"ce227b6f5a9af194fd5d455200630f32c05e151f","modified":1524802263815},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"d6a7dd88404b383b5b94e4c7ec675a410c41f3cc","modified":1524802263818},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"f7388f5c11370ef462f7cb913d8f72edf24ecaf9","modified":1524802263822},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"8f82fe898ba1c1bd00c24a7d8270feddc7eba3bc","modified":1524802263828},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"1577a2336b3ad122f49f60dff2bc1a97d4e7b18b","modified":1524802263826},{"_id":"themes/yilia/source-src/css/article.scss","hash":"55d082fec4c6bb341725567acaa29ce37d50320a","modified":1524802263831},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"07244c188f58ecfb90bb7c047b8cde977f1dc4b4","modified":1524802263834},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"2d1c70bb606c0d87e4f68ec2e600e08b27f32b99","modified":1524802263836},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"96d7eb1d42c06fdcccb8ef969f6ecd30c3194903","modified":1524802263854},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7ca837a4cc34db1c35f01baec85eb10ccc64ea86","modified":1524802263868},{"_id":"themes/yilia/source-src/css/global.scss","hash":"b4cb4f45a55d4250cd9056f76dab2a3c0dabcec4","modified":1524802263871},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"f53ea8270752b5919ec5d79224d22af91f2eda12","modified":1524802263874},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"40e5aa5056dc0b3b9f51c5b387370b612e265d4e","modified":1524802263876},{"_id":"themes/yilia/source-src/css/left.scss","hash":"80dac621e43581a254d0152d5df901e4d0b01c09","modified":1524802263888},{"_id":"themes/yilia/source-src/css/main.scss","hash":"9eba1fcf4805256697528fcf3b767cf6dd8d0591","modified":1524802263890},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"19f10fd2f0c3377aa4b165b3c2291ecf86dd9351","modified":1524802263893},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"d995dcd483a250fe61b426158afb61bf8923a927","modified":1524802263896},{"_id":"themes/yilia/source-src/css/page.scss","hash":"244c4d75c375978ff9edb74acc68825e63c6b235","modified":1524802263898},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"a557a9ed244c82b8b71e9da9de3339d92783499f","modified":1524802263900},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"2495f7e4e3b055735c531f944b5f40a118a351ec","modified":1524802263903},{"_id":"themes/yilia/source-src/css/share.scss","hash":"9d6f6884f40c191882e56a1e1e1192400944a515","modified":1524802263906},{"_id":"themes/yilia/source-src/css/social.scss","hash":"a10a038a1dac8953cb4ffc7e04272eff9fac54e4","modified":1524802263910},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"399744e98e7c67939ed9b23c2670d8baad044eda","modified":1524802263913},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"915c93edd67c5326695cc7dc84b14c5f154dbcc8","modified":1524802263916},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"6932c642bf8191768d7090982a91c8c1f1c4ed1e","modified":1524802263918},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"b81cedbe31accca82e597801186911a7b5e6841c","modified":1524802263921},{"_id":"themes/yilia/source-src/js/Q.js","hash":"e56d9710afa79b31ca6b9fbd845f6d1895f5214b","modified":1524802263928},{"_id":"themes/yilia/source-src/js/anm.js","hash":"d18f6276a352b871390a4112d479b9e58b8cdbbe","modified":1524802263932},{"_id":"themes/yilia/source-src/js/aside.js","hash":"5e4c3c3d61f1e1ce2f09688d3aff25fadc851fff","modified":1524802263936},{"_id":"themes/yilia/source-src/js/browser.js","hash":"4dc04845cf27f350922b63f1813a9c82e6e33b05","modified":1524802263938},{"_id":"themes/yilia/source-src/js/fix.js","hash":"d12df875d3b587354ce59fb7c431ecece53560e3","modified":1524802263944},{"_id":"themes/yilia/source-src/js/main.js","hash":"fe98bf90ce61658fe16ae057f8b6a512a845af3b","modified":1524802263945},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"461c08ffcbc724d74ec7e0ff38e171eefe0f89fd","modified":1524802263949},{"_id":"themes/yilia/source-src/js/report.js","hash":"57680f9a23bd0a1eaafd64ae08cc33e20627ab15","modified":1524802263952},{"_id":"themes/yilia/source-src/js/share.js","hash":"d4ccff8266c37363b3904226f5d035b7db882c61","modified":1524802263955},{"_id":"themes/yilia/source-src/js/slider.js","hash":"707842efee006e3ea9b6765d7460f4ef4f08e41f","modified":1524802263959},{"_id":"themes/yilia/source-src/js/util.js","hash":"3bcdeb95072b85600874424e6929e3e22cfddaa0","modified":1524802263961},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"3e0fd4479a40ddbd1571c6c953df7e23637b61f5","modified":1524802263965},{"_id":"source/img/weixinpay.png","hash":"42703319b16c43ffc5a0084f2b8b3f7526ee83b0","modified":1524810492442},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"c71c3e704e844df3676f4a1b82d9cd8286f0b06b","modified":1524802263766},{"_id":"source/img/openfalcon-func.png","hash":"6e06aee431cd8f2d1fcf52fecd0ed4f51f19264f","modified":1518059388135},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"f75b236818b6c0ec0e5e6c12a517825d6230d756","modified":1524802263733},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"cc384aeaed9ffde92efdf192c26db4da3fe5858f","modified":1524802263736},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"aae96de18d48cd3b9b7bf6fed0100e15b53cca97","modified":1524802263739},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"f6b4c4eaafb5ac386273354b5f64a26139b7a3b0","modified":1524802263744},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"b6a97043f9ec37e571aacacfedcda1d4d75e3c7c","modified":1524802263748},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"06a2dd18ac9a43fbc9a59c61e6f795f9326e9927","modified":1524802263752},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2c4e4ca36c9bb4318506c38aca7127f1f44d827f","modified":1524802263755},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1524802263759},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"fb022502c741b4a26bad6b2ad37245c10ede3f1a","modified":1524802263762},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"1834c3ed8560716e63bb3a50be94cac87fbbeaf3","modified":1524802263840},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"262ffcd88775080b7f511db37f58d2bcb1b2bfc7","modified":1524802263842},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"91db061c9c17628291a005e5bd4936cf9d35a6c4","modified":1524802263845},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"398a49913b4a47d928103562b1ce94520be4026a","modified":1524802263848},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"6e75bdaa46de83094ba0873099c6e7d656a22453","modified":1524802263851},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1524802263858},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1524802263861},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1524802263864},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1524802263866},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1524802263880},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1524802263883},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1524802263885}],"Category":[{"name":"技术","_id":"cjhajczoc0007e4rw4adiezct"}],"Data":[],"Page":[],"Post":[{"title":"my-secret","_content":"","source":"_drafts/my-secret.md","raw":"---\ntitle: my-secret\ntags: 随笔\n---\n","slug":"my-secret","published":0,"date":"2018-04-27T04:11:03.329Z","updated":"2018-04-27T04:11:03.329Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajcznm0000e4rwcj6fy8zu","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"做最好的自己","date":"2014-08-17T15:34:28.000Z","_content":"\n# 无情岁月增中减，有味诗书淡后甜\n>一月你还没有出现；二月你睡在了隔壁；三月下起了大雨；四月遍地蔷薇；五月我们对面坐着，犹如梦中，就这样六月到了；六月里青草盛开，处处芬芳；七月，悲喜交加，麦浪翻滚连同草地，直到天涯；八月就是八月，八月我守口如瓶，八月我是瓶中的水，你是青天白云；九月和十月，是两双眼睛，装满了大海，你在海上。我在海下；十一月尚未到来，透着它的窗口，我望见了十二月，十二月大雪弥漫。\n你看，这无情的时光却似处处有情，处处藏情，这样你那朝五晚九、没日没夜的努力学习，似乎也晴朗明媚了不少吧！\n\n# 静坐常思己过，闲谈莫论人非\n>能受苦乃为志士，肯吃亏不是痴人，敬君子方显有德，怕小人不算无能，如得意不宜重往，凡做事应有余步。持黄金为珍贵，知安乐方值千金，事临头三思为妙，怒上心忍让最高。\n\n>朝金缨在《格言联壁》中有云：“静坐常思已过，闲谈莫论人非”。上联讲严于律己，下联讲宽厚待人。综上所述，读诵经典，思惟经义，把经典里面的教诲落实在生活与工作中，凡人亦会变得优雅、宁静、志远、真诚、清净、平等、正觉、慈悲、看破、放下、自在、随缘、念佛。\n\n\n![Alt text](/img/bmw.jpg \"宝马\")","source":"_posts/be-yourself.md","raw":"---\ntitle: 做最好的自己\ndate: 2014-08-17 23:34:28\ntags: \n- 随笔 \n---\n\n# 无情岁月增中减，有味诗书淡后甜\n>一月你还没有出现；二月你睡在了隔壁；三月下起了大雨；四月遍地蔷薇；五月我们对面坐着，犹如梦中，就这样六月到了；六月里青草盛开，处处芬芳；七月，悲喜交加，麦浪翻滚连同草地，直到天涯；八月就是八月，八月我守口如瓶，八月我是瓶中的水，你是青天白云；九月和十月，是两双眼睛，装满了大海，你在海上。我在海下；十一月尚未到来，透着它的窗口，我望见了十二月，十二月大雪弥漫。\n你看，这无情的时光却似处处有情，处处藏情，这样你那朝五晚九、没日没夜的努力学习，似乎也晴朗明媚了不少吧！\n\n# 静坐常思己过，闲谈莫论人非\n>能受苦乃为志士，肯吃亏不是痴人，敬君子方显有德，怕小人不算无能，如得意不宜重往，凡做事应有余步。持黄金为珍贵，知安乐方值千金，事临头三思为妙，怒上心忍让最高。\n\n>朝金缨在《格言联壁》中有云：“静坐常思已过，闲谈莫论人非”。上联讲严于律己，下联讲宽厚待人。综上所述，读诵经典，思惟经义，把经典里面的教诲落实在生活与工作中，凡人亦会变得优雅、宁静、志远、真诚、清净、平等、正觉、慈悲、看破、放下、自在、随缘、念佛。\n\n\n![Alt text](/img/bmw.jpg \"宝马\")","slug":"be-yourself","published":1,"updated":"2018-04-27T04:11:03.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajcznv0001e4rwxsxtyr3d","content":"<h1 id=\"无情岁月增中减，有味诗书淡后甜\"><a href=\"#无情岁月增中减，有味诗书淡后甜\" class=\"headerlink\" title=\"无情岁月增中减，有味诗书淡后甜\"></a>无情岁月增中减，有味诗书淡后甜</h1><blockquote>\n<p>一月你还没有出现；二月你睡在了隔壁；三月下起了大雨；四月遍地蔷薇；五月我们对面坐着，犹如梦中，就这样六月到了；六月里青草盛开，处处芬芳；七月，悲喜交加，麦浪翻滚连同草地，直到天涯；八月就是八月，八月我守口如瓶，八月我是瓶中的水，你是青天白云；九月和十月，是两双眼睛，装满了大海，你在海上。我在海下；十一月尚未到来，透着它的窗口，我望见了十二月，十二月大雪弥漫。<br>你看，这无情的时光却似处处有情，处处藏情，这样你那朝五晚九、没日没夜的努力学习，似乎也晴朗明媚了不少吧！</p>\n</blockquote>\n<h1 id=\"静坐常思己过，闲谈莫论人非\"><a href=\"#静坐常思己过，闲谈莫论人非\" class=\"headerlink\" title=\"静坐常思己过，闲谈莫论人非\"></a>静坐常思己过，闲谈莫论人非</h1><blockquote>\n<p>能受苦乃为志士，肯吃亏不是痴人，敬君子方显有德，怕小人不算无能，如得意不宜重往，凡做事应有余步。持黄金为珍贵，知安乐方值千金，事临头三思为妙，怒上心忍让最高。</p>\n<p>朝金缨在《格言联壁》中有云：“静坐常思已过，闲谈莫论人非”。上联讲严于律己，下联讲宽厚待人。综上所述，读诵经典，思惟经义，把经典里面的教诲落实在生活与工作中，凡人亦会变得优雅、宁静、志远、真诚、清净、平等、正觉、慈悲、看破、放下、自在、随缘、念佛。</p>\n</blockquote>\n<p><img src=\"/img/bmw.jpg\" alt=\"Alt text\" title=\"宝马\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"无情岁月增中减，有味诗书淡后甜\"><a href=\"#无情岁月增中减，有味诗书淡后甜\" class=\"headerlink\" title=\"无情岁月增中减，有味诗书淡后甜\"></a>无情岁月增中减，有味诗书淡后甜</h1><blockquote>\n<p>一月你还没有出现；二月你睡在了隔壁；三月下起了大雨；四月遍地蔷薇；五月我们对面坐着，犹如梦中，就这样六月到了；六月里青草盛开，处处芬芳；七月，悲喜交加，麦浪翻滚连同草地，直到天涯；八月就是八月，八月我守口如瓶，八月我是瓶中的水，你是青天白云；九月和十月，是两双眼睛，装满了大海，你在海上。我在海下；十一月尚未到来，透着它的窗口，我望见了十二月，十二月大雪弥漫。<br>你看，这无情的时光却似处处有情，处处藏情，这样你那朝五晚九、没日没夜的努力学习，似乎也晴朗明媚了不少吧！</p>\n</blockquote>\n<h1 id=\"静坐常思己过，闲谈莫论人非\"><a href=\"#静坐常思己过，闲谈莫论人非\" class=\"headerlink\" title=\"静坐常思己过，闲谈莫论人非\"></a>静坐常思己过，闲谈莫论人非</h1><blockquote>\n<p>能受苦乃为志士，肯吃亏不是痴人，敬君子方显有德，怕小人不算无能，如得意不宜重往，凡做事应有余步。持黄金为珍贵，知安乐方值千金，事临头三思为妙，怒上心忍让最高。</p>\n<p>朝金缨在《格言联壁》中有云：“静坐常思已过，闲谈莫论人非”。上联讲严于律己，下联讲宽厚待人。综上所述，读诵经典，思惟经义，把经典里面的教诲落实在生活与工作中，凡人亦会变得优雅、宁静、志远、真诚、清净、平等、正觉、慈悲、看破、放下、自在、随缘、念佛。</p>\n</blockquote>\n<p><img src=\"/img/bmw.jpg\" alt=\"Alt text\" title=\"宝马\"></p>\n"},{"title":"Google 使用技巧","date":"2015-08-19T14:53:53.000Z","_content":"![Google Img](/img/google.jpg)\n# 下载离线包 \n通过该链接下载离线下载最新的chrome官方离线安装包\n[Download Url](https://www.google.com/intl/zh-CN/chrome/browser/desktop/index.html?standalone=1 \"离线下载\")  \n\n\n# 常用插件\n>Adblock Plus  ：广告过滤\nAppspector ： Detect web applications and javascript libraries run on browsing website.\ncrxMouse Chrome Gestures ：鼠标手势\nHumble New Tab Page ：书签管理、最常访问、最近关闭等\nIE Tab：IE内核打开网页\nSwitchyOmega ：代理工具 \nLastPass： Free Password Manager 密码管理器\nOctotree ：Code tree for GitHub and GitLab\nOneTab ：节省高达95％的内存，并减轻标签页混乱现象\nAxure RP Extension for Chrome ： Axure RP 浏览器插件\n\n# 我喜欢的主题\n>炭黑+銀色金屬\n\n<!-- more -->\n\n# APPs\n>Postman：http测试工具  \nTypeClub：打字练习\n\n# google 使用技巧\n>link:URL = 列出到链接到目标URL的网页清单.\nrelated:URL = 列出于目标URL地址有关的网页.\nsite:Domain Name Registration and Web Hosting 搜索区域仅限于目标网站.\nallinurl:WORDS = 只显示在URL地址里有搜索结果的页面.\ninurl:WORD = 跟allinurl类似,但是只在URL中搜索第一个词.\nallintitle:WORD = 搜索网页标题.\nintitle:WORD = 跟allintitle类似,但是只在标题里搜索第一个词.\ncache:URL = 将显示关于URL的Google缓存(中国不可用).\ninfo:URL = 将显示一个包含了这些元素的页面:类似结果的链接,反向链接,还有包括了这个URL的页面.在搜索框里直接输入URL会起到同样的效果.\nfiletype:SOMEFILETYPE = 指定文件类型.\n-filetype:SOMEFILETYPE = 剔除指定文件类型.\nsite:Welcome to SomeSite.Net ! “+Welcome to SomeSite.Net !” = 显示该站点有多少网页被google收录\nallintext: = 搜索文本,但不包括网页标题和链接\nallinlinks: = 搜索链接, 不包括文本和标题\nWordA OR WordB = 搜索包含两关键词之一的页面\n“Word” OR “Phrase” = 精确的要求搜索单词或者句子\nWordA -WordB = 包含单词A但是不包含单词B\nWordA +WordB = 都包含\n~WORD = 寻找此单词和它的同义词\n~WORD-WORD = 只搜索同义词,不要原词\n","source":"_posts/Google-Full.md","raw":"---\ntitle: Google 使用技巧\ndate: 2015-08-19 22:53:53\ntags: Google \n---\n![Google Img](/img/google.jpg)\n# 下载离线包 \n通过该链接下载离线下载最新的chrome官方离线安装包\n[Download Url](https://www.google.com/intl/zh-CN/chrome/browser/desktop/index.html?standalone=1 \"离线下载\")  \n\n\n# 常用插件\n>Adblock Plus  ：广告过滤\nAppspector ： Detect web applications and javascript libraries run on browsing website.\ncrxMouse Chrome Gestures ：鼠标手势\nHumble New Tab Page ：书签管理、最常访问、最近关闭等\nIE Tab：IE内核打开网页\nSwitchyOmega ：代理工具 \nLastPass： Free Password Manager 密码管理器\nOctotree ：Code tree for GitHub and GitLab\nOneTab ：节省高达95％的内存，并减轻标签页混乱现象\nAxure RP Extension for Chrome ： Axure RP 浏览器插件\n\n# 我喜欢的主题\n>炭黑+銀色金屬\n\n<!-- more -->\n\n# APPs\n>Postman：http测试工具  \nTypeClub：打字练习\n\n# google 使用技巧\n>link:URL = 列出到链接到目标URL的网页清单.\nrelated:URL = 列出于目标URL地址有关的网页.\nsite:Domain Name Registration and Web Hosting 搜索区域仅限于目标网站.\nallinurl:WORDS = 只显示在URL地址里有搜索结果的页面.\ninurl:WORD = 跟allinurl类似,但是只在URL中搜索第一个词.\nallintitle:WORD = 搜索网页标题.\nintitle:WORD = 跟allintitle类似,但是只在标题里搜索第一个词.\ncache:URL = 将显示关于URL的Google缓存(中国不可用).\ninfo:URL = 将显示一个包含了这些元素的页面:类似结果的链接,反向链接,还有包括了这个URL的页面.在搜索框里直接输入URL会起到同样的效果.\nfiletype:SOMEFILETYPE = 指定文件类型.\n-filetype:SOMEFILETYPE = 剔除指定文件类型.\nsite:Welcome to SomeSite.Net ! “+Welcome to SomeSite.Net !” = 显示该站点有多少网页被google收录\nallintext: = 搜索文本,但不包括网页标题和链接\nallinlinks: = 搜索链接, 不包括文本和标题\nWordA OR WordB = 搜索包含两关键词之一的页面\n“Word” OR “Phrase” = 精确的要求搜索单词或者句子\nWordA -WordB = 包含单词A但是不包含单词B\nWordA +WordB = 都包含\n~WORD = 寻找此单词和它的同义词\n~WORD-WORD = 只搜索同义词,不要原词\n","slug":"Google-Full","published":1,"updated":"2018-04-27T04:11:03.329Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczo30003e4rw5oibrebo","content":"<p><img src=\"/img/google.jpg\" alt=\"Google Img\"></p>\n<h1 id=\"下载离线包\"><a href=\"#下载离线包\" class=\"headerlink\" title=\"下载离线包\"></a>下载离线包</h1><p>通过该链接下载离线下载最新的chrome官方离线安装包<br><a href=\"https://www.google.com/intl/zh-CN/chrome/browser/desktop/index.html?standalone=1\" title=\"离线下载\" target=\"_blank\" rel=\"external\">Download Url</a>  </p>\n<h1 id=\"常用插件\"><a href=\"#常用插件\" class=\"headerlink\" title=\"常用插件\"></a>常用插件</h1><blockquote>\n<p>Adblock Plus  ：广告过滤<br>Appspector ： Detect web applications and javascript libraries run on browsing website.<br>crxMouse Chrome Gestures ：鼠标手势<br>Humble New Tab Page ：书签管理、最常访问、最近关闭等<br>IE Tab：IE内核打开网页<br>SwitchyOmega ：代理工具<br>LastPass： Free Password Manager 密码管理器<br>Octotree ：Code tree for GitHub and GitLab<br>OneTab ：节省高达95％的内存，并减轻标签页混乱现象<br>Axure RP Extension for Chrome ： Axure RP 浏览器插件</p>\n</blockquote>\n<h1 id=\"我喜欢的主题\"><a href=\"#我喜欢的主题\" class=\"headerlink\" title=\"我喜欢的主题\"></a>我喜欢的主题</h1><blockquote>\n<p>炭黑+銀色金屬</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"APPs\"><a href=\"#APPs\" class=\"headerlink\" title=\"APPs\"></a>APPs</h1><blockquote>\n<p>Postman：http测试工具<br>TypeClub：打字练习</p>\n</blockquote>\n<h1 id=\"google-使用技巧\"><a href=\"#google-使用技巧\" class=\"headerlink\" title=\"google 使用技巧\"></a>google 使用技巧</h1><blockquote>\n<p>link:URL = 列出到链接到目标URL的网页清单.<br>related:URL = 列出于目标URL地址有关的网页.<br>site:Domain Name Registration and Web Hosting 搜索区域仅限于目标网站.<br>allinurl:WORDS = 只显示在URL地址里有搜索结果的页面.<br>inurl:WORD = 跟allinurl类似,但是只在URL中搜索第一个词.<br>allintitle:WORD = 搜索网页标题.<br>intitle:WORD = 跟allintitle类似,但是只在标题里搜索第一个词.<br>cache:URL = 将显示关于URL的Google缓存(中国不可用).<br>info:URL = 将显示一个包含了这些元素的页面:类似结果的链接,反向链接,还有包括了这个URL的页面.在搜索框里直接输入URL会起到同样的效果.<br>filetype:SOMEFILETYPE = 指定文件类型.<br>-filetype:SOMEFILETYPE = 剔除指定文件类型.<br>site:Welcome to SomeSite.Net ! “+Welcome to SomeSite.Net !” = 显示该站点有多少网页被google收录<br>allintext: = 搜索文本,但不包括网页标题和链接<br>allinlinks: = 搜索链接, 不包括文本和标题<br>WordA OR WordB = 搜索包含两关键词之一的页面<br>“Word” OR “Phrase” = 精确的要求搜索单词或者句子<br>WordA -WordB = 包含单词A但是不包含单词B<br>WordA +WordB = 都包含<br>~WORD = 寻找此单词和它的同义词<br>~WORD-WORD = 只搜索同义词,不要原词</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p><img src=\"/img/google.jpg\" alt=\"Google Img\"></p>\n<h1 id=\"下载离线包\"><a href=\"#下载离线包\" class=\"headerlink\" title=\"下载离线包\"></a>下载离线包</h1><p>通过该链接下载离线下载最新的chrome官方离线安装包<br><a href=\"https://www.google.com/intl/zh-CN/chrome/browser/desktop/index.html?standalone=1\" title=\"离线下载\" target=\"_blank\" rel=\"external\">Download Url</a>  </p>\n<h1 id=\"常用插件\"><a href=\"#常用插件\" class=\"headerlink\" title=\"常用插件\"></a>常用插件</h1><blockquote>\n<p>Adblock Plus  ：广告过滤<br>Appspector ： Detect web applications and javascript libraries run on browsing website.<br>crxMouse Chrome Gestures ：鼠标手势<br>Humble New Tab Page ：书签管理、最常访问、最近关闭等<br>IE Tab：IE内核打开网页<br>SwitchyOmega ：代理工具<br>LastPass： Free Password Manager 密码管理器<br>Octotree ：Code tree for GitHub and GitLab<br>OneTab ：节省高达95％的内存，并减轻标签页混乱现象<br>Axure RP Extension for Chrome ： Axure RP 浏览器插件</p>\n</blockquote>\n<h1 id=\"我喜欢的主题\"><a href=\"#我喜欢的主题\" class=\"headerlink\" title=\"我喜欢的主题\"></a>我喜欢的主题</h1><blockquote>\n<p>炭黑+銀色金屬</p>\n</blockquote>","more":"<h1 id=\"APPs\"><a href=\"#APPs\" class=\"headerlink\" title=\"APPs\"></a>APPs</h1><blockquote>\n<p>Postman：http测试工具<br>TypeClub：打字练习</p>\n</blockquote>\n<h1 id=\"google-使用技巧\"><a href=\"#google-使用技巧\" class=\"headerlink\" title=\"google 使用技巧\"></a>google 使用技巧</h1><blockquote>\n<p>link:URL = 列出到链接到目标URL的网页清单.<br>related:URL = 列出于目标URL地址有关的网页.<br>site:Domain Name Registration and Web Hosting 搜索区域仅限于目标网站.<br>allinurl:WORDS = 只显示在URL地址里有搜索结果的页面.<br>inurl:WORD = 跟allinurl类似,但是只在URL中搜索第一个词.<br>allintitle:WORD = 搜索网页标题.<br>intitle:WORD = 跟allintitle类似,但是只在标题里搜索第一个词.<br>cache:URL = 将显示关于URL的Google缓存(中国不可用).<br>info:URL = 将显示一个包含了这些元素的页面:类似结果的链接,反向链接,还有包括了这个URL的页面.在搜索框里直接输入URL会起到同样的效果.<br>filetype:SOMEFILETYPE = 指定文件类型.<br>-filetype:SOMEFILETYPE = 剔除指定文件类型.<br>site:Welcome to SomeSite.Net ! “+Welcome to SomeSite.Net !” = 显示该站点有多少网页被google收录<br>allintext: = 搜索文本,但不包括网页标题和链接<br>allinlinks: = 搜索链接, 不包括文本和标题<br>WordA OR WordB = 搜索包含两关键词之一的页面<br>“Word” OR “Phrase” = 精确的要求搜索单词或者句子<br>WordA -WordB = 包含单词A但是不包含单词B<br>WordA +WordB = 都包含<br>~WORD = 寻找此单词和它的同义词<br>~WORD-WORD = 只搜索同义词,不要原词</p>\n</blockquote>"},{"title":"开源监控体系对比","date":"2018-05-16T15:10:07.000Z","_content":"\n## Prometheus、TICK、Sensu、Openfalcon 对比\n\n**目的**\n\n- 研究开源监控系统架构，完善现有的后台采集结构\n- 利用开源监控体系中的采集插件，节省KM研究、开发新监控对象（各类分布式组件）的时间\n- 使用开源监控系统为独立的一套监控系统，作为端到端等分布式应用场景的监控系统\n- 与现有网管后台结合，将开源监控系统作为一类采集数据源\n\n\n\n OpenTSDB、Graphite 偏向数据存储，并无完整的监控体系（采集、存储、告警、展示）。\n\n## 对比表格\n\n以下列出几个重要的关注点\n\n|                              |               Prometheus               |     TICK     |        Sensu         |      Openfalcon      |\n| :--------------------------: | :------------------------------------: | :----------: | :------------------: | :------------------: |\n|             开发语言             |                   Go                   |      Go      |         ruby         |          Go          |\n| <a href=\"#数据收集方式\">数据收集方式</a> |            Pull/Pushgateway            |     Push     |         Push         |         Push         |\n|            采集客户端             |               各种Exporter               |   telegraf   | sensu-client<br>各种脚本 | Falcon-agent<br>各种脚本 |\n|   <a href=\"#数据模型\">数据模型</a>   |                key+tag                 |   key+tag    |         json         |       key+tag        |\n|              存储              | 本地存储 <br>远程数据库(influxDB可读写/OpenTSDB只写) |   influxDB   |        redis         |    mysql/opentsdb    |\n|          agent部署方式           |                   人工                   |      人工      |          人工          |          人工          |\n|            任务更新策略            |                   无                    |      无       |          无           | dashbord可关联主机和pluins |\n|   <a href=\"#数据查询\">数据查询</a>   |                HTTP API                | SQL/HTTP API |  HTTP API/redis-cli  |         sql          |\n\n<!-- more -->\n\n## 数据收集方式\n\nPrometheus 与众不同的采用Pull方式，由服务端主动从被监控机器上面抓取数据。Prometheus 也提供Pushgateway的方式，支持其他数据源主动推送数据到Pushgateway，Pushgateway只做数据缓存，之后仍然是等待服务端抓取。Exporter作为被监控对象暴露指标的客户端，运行在被监控对象上面，并且在Prometheus 服务端配置作为Job，需配置抓取地址端口和间隔。针对各种监控对象，可部署各种Exporter。\n\nPull和Push的主要区别在于Pull方式下，监控系统可以方便的增加删除被监控对象，但是需要被监控对象主动开放端口，这对防火墙/NAT方式下的被监控对象是特殊的要求。而Push模式下，每个采集客户端需要知道服务端的信息，才能上报数据。相比之下，网管后台使用Rabbitmq隔离了服务端的信息，但是仍然需要客户端配置Rabbitmq信息。\n\nTICK使用telegraf作为数据采集端，由telegraf 根据input配置主动采集并发送到output配置的后端，一般是InfluxDB数据库。telegraf还能对采集数据做聚合过滤等处理。telegraf是Go开发的二进制可执行对象，各种对象的采集均打包在一起，通过指定input插件类型，可以指定采集某类指标。相比之下，网管后台使用Java+KM的方式，由Java负责进程调度，KM负责指定采集对象。\n\nSensu 也是采用Push 方式，Sensu由Client发送采集数据到transport，服务端再去transport 读取数据，transport一般使用Rabbitmq。这点跟网管有点类似。Client利用插件采集数据，是ruby脚本，需要额外安装。安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。采集配置较为繁琐。\n\nOpenfalcon 也是采用Push 方式，由Client发送采集数据到transport，与Sensu  不同的是，transport 会做一些数据规整，检查之后，转发到多个后端系统去处理。transfer目前支持的业务后端，有三种，judge、graph、opentsdb。judge是告警判定组件，graph作为高性能数据存储、归档、查询组件，opentsdb主要用作数据存储服务。falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。\n\n\n\n综上，其实介绍了四种主要的采集逻辑。以两种不同对象的采集作为示例说明\n\n- 主机类指标CPU\n- 开源软件Redis\n\n<a href=\"#对比表格\">返回目录</a>\n\n## 数据模型\n\n架构的分层隔离，依赖于各层之间接口的规范。对于采集数据而言，Pull/Push 体现的是传输方式，而数据格式，则是数据组织的规范。以下是各个系统的数据格式。\n\n- openfalcon  采用和OpenTSDB相似的数据格式：metric、endpoint加多组key value tags\n\n```\n{\n    metric: load.1min,\n    endpoint: open-falcon-host,\n    tags: srv=falcon,idc=aws-sgp,group=az1,\n    value: 1.5,\n    timestamp: `date +%s`,\n    counterType: GAUGE,\n    step: 60\n}\n```\n\n其中，metric是监控指标名称，endpoint是监控实体，tags是监控数据的属性标签，counterType是Open-Falcon定义的数据类型(取值为GAUGE、COUNTER)，step为监控数据的上报周期，value和timestamp是有效的监控数据。\n\n- prometheus    <metric name>{<label name>=<label value>, ...}\n\n  prometheus 有四种类型的指标：counter、gauge、[summary、histogram](https://prometheus.io/docs/practices/histograms/) ，[示例](http://192.168.7.176:9090/metrics)\n\n```\n# HELP http_requests_total Total number of HTTP requests made.\n# TYPE http_requests_total counter\nhttp_requests_total{code=\"200\",handler=\"alerts\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"config\",method=\"get\"} 1\nhttp_requests_total{code=\"200\",handler=\"flags\",method=\"get\"} 2\n\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 235\n\n# HELP go_gc_duration_seconds A summary of the GC invocation durations.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 4.5975e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 8.3846e-05\ngo_gc_duration_seconds{quantile=\"0.5\"} 0.000100729\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.000123377\ngo_gc_duration_seconds{quantile=\"1\"} 0.026837959\ngo_gc_duration_seconds_sum 1.990353198\ngo_gc_duration_seconds_count 10956\n\n# HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction\n# TYPE prometheus_tsdb_compaction_chunk_range histogram\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"100\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"400\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1600\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6400\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"25600\"} 2336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"102400\"} 269009\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"409600\"} 271929\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1.6384e+06\"} 4.2524554e+07\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6.5536e+06\"} 4.3107242e+07\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"2.62144e+07\"} 4.3107877e+07\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"+Inf\"} 4.3107877e+07\nprometheus_tsdb_compaction_chunk_range_sum 4.4190173791382e+13\nprometheus_tsdb_compaction_chunk_range_count 4.3107877e+07\n```\n\n不同类型的指标，有不同的查询方法，需根据指标含义选择合适的查询方法\n\nhistogram_quantile(0.9, rate(prometheus_tsdb_compaction_chunk_range_bucket[10m]))\n\n- Telegraf 支持多种输入输出格式，重点讲解InfluxDB Line Protocol，另外两种是json/Graphite\n\n```\nweather,location=us-midwest temperature=82 1465839830100400200\n  |    -------------------- --------------  |\n  |             |             |             |\n  |             |             |             |\n+-----------+--------+-+---------+-+---------+\n|measurement|,tag_set| |field_set| |timestamp|\n+-----------+--------+-+---------+-+---------+\n\n> cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000\n> cpu,cpu=cpu-total,host=0336dcb23579    usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000\n```\n\ncpu：measurements ，类似oracle的表名  \n\ncpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；    内部以，分割 \n\nusage_guest_nice=0,usage_idle=100,usage_nice=0... : usage_guest_nice等为field，即被采集的指标字段。\n\n***field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面***\n\n1515338025000000000： time 时间戳\n\n这里顺便提下 influx metric -> graphite 的转换格式\n\n```\ntemplate = \"host.tags.measurement.field\"\n```\n\n```\ncpu,cpu=cpu-total,dc=us-east-1,host=tars usage_idle=98.09,usage_user=0.89 1455320660004257758\n=>\ntars.cpu-total.us-east-1.cpu.usage_user 0.89 1455320690\ntars.cpu-total.us-east-1.cpu.usage_idle 98.09 1455320690\n```\n\n- Sensu 指标数据，实际上是check的返回结果。应该是json字符串\n\n```shell\n{\n    \"client\": \"tick-client\",\n    \"check\": {\n      \"type\": \"metric\",\n      \"command\": \"metrics-cpu.rb\",\n      \"subscribers\": [\n        \"production\"\n      ],\n      \"interval\": 10,\n      \"handler\": \"tcp_socket\",\n      \"standalone\": true,\n      \"name\": \"cpu_metrics\",\n      \"issued\": 1525270655,\n      \"executed\": 1525270655,\n      \"duration\": 0.074,\n      \"output\": \"tick.cpu.total.user 738228 1525270655\\n...\",\n      \"status\": 0,\n      \"history\": [\n        0,\n\t\t...\n      ]\n    }\n}\n\n```\n\noutput 就是chcek返回结果。由不同的指标采集插件返回，默认的返回格式是Graphite 格式。\n\n```\nsensu.cpu.user 0.50 1515534170\nsensu.cpu.nice 0.00 1515534170\nsensu.cpu.system 0.00 1515534170\nsensu.cpu.idle 99.50 1515534170\nsensu.cpu.iowait 0.00 1515534170\nsensu.cpu.irq 0.00 1515534170\nsensu.cpu.softirq 0.00 1515534170\nsensu.cpu.steal 0.00 1515534170\nsensu.cpu.guest 0.00 1515534170\n```\n\n\n\n<a href=\"#对比表格\">返回目录</a>\n\n## 数据查询\n\n- Prometheus   HTTP API接口查询，查询结果类型：\"resultType\": \"matrix\" | \"vector\" | \"scalar\" | \"string\"\n\n  matrix ： 返回某个时间段内的指标数据集合\n\n  vector：返回单个时间点的指标数据\n\n  ```\n  # Instant queries\n  curl 'http://192.168.7.176:9090/api/v1/query?query=elasticsearch_node_stats_up&time=1525313513.452&_=1525313461038' -s | python -m json.tool\n\n  # Range queries\n  curl 'http://192.168.7.176:9090/api/v1/query_range?query=prometheus_tsdb_compaction_chunk_range_bucket&start=1525307102.216&end=1525307302.216&step=28&_=1525313461049' -s|python -m json.tool\n\n  ```\n\n  ​\n\n- TICK  HTTP API查询/登陆数据库查询sql\n\n  ```\n  curl -G \"http://192.168.7.176:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\\n  --data-urlencode \"q=SELECT * FROM cpu WHERE host='server01' AND time < now() - 1d\"\n\n  ##==>\n  SELECT * FROM cpu WHERE host='server01' AND time < now() - 1d\n  ```\n\n  ​\n\n- Sensu   HTTP API查询/登陆redis查询sql\n\n  ```\n  curl -s http://127.0.0.1:4567/clients | jq .\n  curl -s http://localhost:4567/events | jq .\n  curl -s http://localhost:4567/results | jq .\n  curl -s http://localhost:4567/checks | jq .\n\n  ###===>\n  redis-cli\n  keys * \n  get result:tick-client:cpu_metrics\n  ```\n\n  ​\n\n- Openfalcon \n\n  从mysql数据库中取数\n\n  ​\n\n<a href=\"#对比表格\">返回目录</a>\n\n## 网管对接\n\n1. 跟云资源采集类似，将上述监控系统作为一个数据采集中心。开发一个转储接口程序，从监控系统中（数据库或者REST API）读取配置、性能数据等，转换数据格式，存入网管系统。\n\n   优点：可以方便对接第三方开源系统，利用其成熟的监控指标和稳定的监控体系。对原有的网管系统也不需要过多的改造，相当于改造重心在转储接口程序。\n\n   ​ 缺点：需要额外维护多套监控系统以及对应的转换程序；对该转换程序尽可能做得通用，因为可以同时对接多套监控系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。\n\n\n\n2. 仅复用监控系统的采集客户端，类似现在的Agent对接开源组件的模式。例如prometheus，可以复用其exporter。即prometheus exporter独立运行并暴露数据至指定监听端口，Agent开发http接口定时扫描读取该端口暴露的指标即可，然后由KM负责解析转换，最终存入网管系统。\n\n   优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM，对这类采集结果做格式解析处理。exporter暴露的数据指标相对统一，处理起来也比较方便。\n\n   缺点：需要额外维护exporter，且需要开通exporter监听端口的访问权限；exporter的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。\n\n\n\n3. 复用监控系统的采集客户端，同时改造网管系统部分功能。例如telegraf，telegraf支持输出结果到influxdb,或者生成本地json文件。如果是本地Json文件，则与prometheus类似，由KM解析即可。如果是influxdb，则需开发程序从influxdb读取解析数据(相当于另一个数据源)。\n\n   优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM或者influxdb读取程序，对这类采集结果做格式解析处理。telegraf暴露的数据指标相对统一，处理起来也比较方便。\n\n   缺点：需要额外维护telegraf进程；telegraf的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要KM、配置表单，这部分是无法避免的。\n\n<a href=\"#对比表格\">返回目录</a>\n\n\n\n## 支持的采集对象\n\n- Prometheus\n\nhttps://prometheus.io/docs/instrumenting/exporters/\n\n\n\n- Telegraf\n\nhttps://github.com/influxdata/telegraf/tree/master/plugins/inputs\n\njmx方式采集：kafka\n\nhttps://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\n\nhttps://docs.confluent.io/current/kafka/monitoring.html\n\n\n\n- Sensu\n\nhttps://github.com/sensu-plugins\n\n\n\n- Openfalcon\n\nhttps://book.open-falcon.org/zh_0_2/usage/\n\n[https://github.com/iambocai/falcon-monit-scripts](https://github.com/iambocai/falcon-monit-scripts)\n\n\n\n- Datadog \n\nhttps://app.datadoghq.com/account/settings#integrations\n\n\n\n## 结论\n\n采用第二种方案，结合开源组件的客户端和采集脚本，有Agent负责调度，解析结果并返回。\n\n被监控对象：ES /kakfa\n\n实现的客户端：telegraf/openfaclon   客户端\n\n目的：从前台配置开始，最终采集入库\n\n\n\njolokia2 采集分为两种模式，一种是jvm代理，由java应用（kafka）启动时修改参数引入jolokia2 包```-javaagent:/usr/hdp/2.6.1.0-129/kafka/libs/jolokia-jvm-1.5.0-agent.jar=port=8778,host=0.0.0.0```\n\n第二种是Proxy模式，由于第一种应用的限制，proxy模式不需要在应用端修改\n\n","source":"_posts/compared.md","raw":"---\ntitle: 开源监控体系对比\ndate: 2018-05-16 23:10:07\ncategories: 技术\n---\n\n## Prometheus、TICK、Sensu、Openfalcon 对比\n\n**目的**\n\n- 研究开源监控系统架构，完善现有的后台采集结构\n- 利用开源监控体系中的采集插件，节省KM研究、开发新监控对象（各类分布式组件）的时间\n- 使用开源监控系统为独立的一套监控系统，作为端到端等分布式应用场景的监控系统\n- 与现有网管后台结合，将开源监控系统作为一类采集数据源\n\n\n\n OpenTSDB、Graphite 偏向数据存储，并无完整的监控体系（采集、存储、告警、展示）。\n\n## 对比表格\n\n以下列出几个重要的关注点\n\n|                              |               Prometheus               |     TICK     |        Sensu         |      Openfalcon      |\n| :--------------------------: | :------------------------------------: | :----------: | :------------------: | :------------------: |\n|             开发语言             |                   Go                   |      Go      |         ruby         |          Go          |\n| <a href=\"#数据收集方式\">数据收集方式</a> |            Pull/Pushgateway            |     Push     |         Push         |         Push         |\n|            采集客户端             |               各种Exporter               |   telegraf   | sensu-client<br>各种脚本 | Falcon-agent<br>各种脚本 |\n|   <a href=\"#数据模型\">数据模型</a>   |                key+tag                 |   key+tag    |         json         |       key+tag        |\n|              存储              | 本地存储 <br>远程数据库(influxDB可读写/OpenTSDB只写) |   influxDB   |        redis         |    mysql/opentsdb    |\n|          agent部署方式           |                   人工                   |      人工      |          人工          |          人工          |\n|            任务更新策略            |                   无                    |      无       |          无           | dashbord可关联主机和pluins |\n|   <a href=\"#数据查询\">数据查询</a>   |                HTTP API                | SQL/HTTP API |  HTTP API/redis-cli  |         sql          |\n\n<!-- more -->\n\n## 数据收集方式\n\nPrometheus 与众不同的采用Pull方式，由服务端主动从被监控机器上面抓取数据。Prometheus 也提供Pushgateway的方式，支持其他数据源主动推送数据到Pushgateway，Pushgateway只做数据缓存，之后仍然是等待服务端抓取。Exporter作为被监控对象暴露指标的客户端，运行在被监控对象上面，并且在Prometheus 服务端配置作为Job，需配置抓取地址端口和间隔。针对各种监控对象，可部署各种Exporter。\n\nPull和Push的主要区别在于Pull方式下，监控系统可以方便的增加删除被监控对象，但是需要被监控对象主动开放端口，这对防火墙/NAT方式下的被监控对象是特殊的要求。而Push模式下，每个采集客户端需要知道服务端的信息，才能上报数据。相比之下，网管后台使用Rabbitmq隔离了服务端的信息，但是仍然需要客户端配置Rabbitmq信息。\n\nTICK使用telegraf作为数据采集端，由telegraf 根据input配置主动采集并发送到output配置的后端，一般是InfluxDB数据库。telegraf还能对采集数据做聚合过滤等处理。telegraf是Go开发的二进制可执行对象，各种对象的采集均打包在一起，通过指定input插件类型，可以指定采集某类指标。相比之下，网管后台使用Java+KM的方式，由Java负责进程调度，KM负责指定采集对象。\n\nSensu 也是采用Push 方式，Sensu由Client发送采集数据到transport，服务端再去transport 读取数据，transport一般使用Rabbitmq。这点跟网管有点类似。Client利用插件采集数据，是ruby脚本，需要额外安装。安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。采集配置较为繁琐。\n\nOpenfalcon 也是采用Push 方式，由Client发送采集数据到transport，与Sensu  不同的是，transport 会做一些数据规整，检查之后，转发到多个后端系统去处理。transfer目前支持的业务后端，有三种，judge、graph、opentsdb。judge是告警判定组件，graph作为高性能数据存储、归档、查询组件，opentsdb主要用作数据存储服务。falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。\n\n\n\n综上，其实介绍了四种主要的采集逻辑。以两种不同对象的采集作为示例说明\n\n- 主机类指标CPU\n- 开源软件Redis\n\n<a href=\"#对比表格\">返回目录</a>\n\n## 数据模型\n\n架构的分层隔离，依赖于各层之间接口的规范。对于采集数据而言，Pull/Push 体现的是传输方式，而数据格式，则是数据组织的规范。以下是各个系统的数据格式。\n\n- openfalcon  采用和OpenTSDB相似的数据格式：metric、endpoint加多组key value tags\n\n```\n{\n    metric: load.1min,\n    endpoint: open-falcon-host,\n    tags: srv=falcon,idc=aws-sgp,group=az1,\n    value: 1.5,\n    timestamp: `date +%s`,\n    counterType: GAUGE,\n    step: 60\n}\n```\n\n其中，metric是监控指标名称，endpoint是监控实体，tags是监控数据的属性标签，counterType是Open-Falcon定义的数据类型(取值为GAUGE、COUNTER)，step为监控数据的上报周期，value和timestamp是有效的监控数据。\n\n- prometheus    <metric name>{<label name>=<label value>, ...}\n\n  prometheus 有四种类型的指标：counter、gauge、[summary、histogram](https://prometheus.io/docs/practices/histograms/) ，[示例](http://192.168.7.176:9090/metrics)\n\n```\n# HELP http_requests_total Total number of HTTP requests made.\n# TYPE http_requests_total counter\nhttp_requests_total{code=\"200\",handler=\"alerts\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"config\",method=\"get\"} 1\nhttp_requests_total{code=\"200\",handler=\"flags\",method=\"get\"} 2\n\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 235\n\n# HELP go_gc_duration_seconds A summary of the GC invocation durations.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 4.5975e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 8.3846e-05\ngo_gc_duration_seconds{quantile=\"0.5\"} 0.000100729\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.000123377\ngo_gc_duration_seconds{quantile=\"1\"} 0.026837959\ngo_gc_duration_seconds_sum 1.990353198\ngo_gc_duration_seconds_count 10956\n\n# HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction\n# TYPE prometheus_tsdb_compaction_chunk_range histogram\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"100\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"400\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1600\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6400\"} 336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"25600\"} 2336\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"102400\"} 269009\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"409600\"} 271929\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1.6384e+06\"} 4.2524554e+07\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6.5536e+06\"} 4.3107242e+07\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"2.62144e+07\"} 4.3107877e+07\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"+Inf\"} 4.3107877e+07\nprometheus_tsdb_compaction_chunk_range_sum 4.4190173791382e+13\nprometheus_tsdb_compaction_chunk_range_count 4.3107877e+07\n```\n\n不同类型的指标，有不同的查询方法，需根据指标含义选择合适的查询方法\n\nhistogram_quantile(0.9, rate(prometheus_tsdb_compaction_chunk_range_bucket[10m]))\n\n- Telegraf 支持多种输入输出格式，重点讲解InfluxDB Line Protocol，另外两种是json/Graphite\n\n```\nweather,location=us-midwest temperature=82 1465839830100400200\n  |    -------------------- --------------  |\n  |             |             |             |\n  |             |             |             |\n+-----------+--------+-+---------+-+---------+\n|measurement|,tag_set| |field_set| |timestamp|\n+-----------+--------+-+---------+-+---------+\n\n> cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000\n> cpu,cpu=cpu-total,host=0336dcb23579    usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000\n```\n\ncpu：measurements ，类似oracle的表名  \n\ncpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；    内部以，分割 \n\nusage_guest_nice=0,usage_idle=100,usage_nice=0... : usage_guest_nice等为field，即被采集的指标字段。\n\n***field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面***\n\n1515338025000000000： time 时间戳\n\n这里顺便提下 influx metric -> graphite 的转换格式\n\n```\ntemplate = \"host.tags.measurement.field\"\n```\n\n```\ncpu,cpu=cpu-total,dc=us-east-1,host=tars usage_idle=98.09,usage_user=0.89 1455320660004257758\n=>\ntars.cpu-total.us-east-1.cpu.usage_user 0.89 1455320690\ntars.cpu-total.us-east-1.cpu.usage_idle 98.09 1455320690\n```\n\n- Sensu 指标数据，实际上是check的返回结果。应该是json字符串\n\n```shell\n{\n    \"client\": \"tick-client\",\n    \"check\": {\n      \"type\": \"metric\",\n      \"command\": \"metrics-cpu.rb\",\n      \"subscribers\": [\n        \"production\"\n      ],\n      \"interval\": 10,\n      \"handler\": \"tcp_socket\",\n      \"standalone\": true,\n      \"name\": \"cpu_metrics\",\n      \"issued\": 1525270655,\n      \"executed\": 1525270655,\n      \"duration\": 0.074,\n      \"output\": \"tick.cpu.total.user 738228 1525270655\\n...\",\n      \"status\": 0,\n      \"history\": [\n        0,\n\t\t...\n      ]\n    }\n}\n\n```\n\noutput 就是chcek返回结果。由不同的指标采集插件返回，默认的返回格式是Graphite 格式。\n\n```\nsensu.cpu.user 0.50 1515534170\nsensu.cpu.nice 0.00 1515534170\nsensu.cpu.system 0.00 1515534170\nsensu.cpu.idle 99.50 1515534170\nsensu.cpu.iowait 0.00 1515534170\nsensu.cpu.irq 0.00 1515534170\nsensu.cpu.softirq 0.00 1515534170\nsensu.cpu.steal 0.00 1515534170\nsensu.cpu.guest 0.00 1515534170\n```\n\n\n\n<a href=\"#对比表格\">返回目录</a>\n\n## 数据查询\n\n- Prometheus   HTTP API接口查询，查询结果类型：\"resultType\": \"matrix\" | \"vector\" | \"scalar\" | \"string\"\n\n  matrix ： 返回某个时间段内的指标数据集合\n\n  vector：返回单个时间点的指标数据\n\n  ```\n  # Instant queries\n  curl 'http://192.168.7.176:9090/api/v1/query?query=elasticsearch_node_stats_up&time=1525313513.452&_=1525313461038' -s | python -m json.tool\n\n  # Range queries\n  curl 'http://192.168.7.176:9090/api/v1/query_range?query=prometheus_tsdb_compaction_chunk_range_bucket&start=1525307102.216&end=1525307302.216&step=28&_=1525313461049' -s|python -m json.tool\n\n  ```\n\n  ​\n\n- TICK  HTTP API查询/登陆数据库查询sql\n\n  ```\n  curl -G \"http://192.168.7.176:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\\n  --data-urlencode \"q=SELECT * FROM cpu WHERE host='server01' AND time < now() - 1d\"\n\n  ##==>\n  SELECT * FROM cpu WHERE host='server01' AND time < now() - 1d\n  ```\n\n  ​\n\n- Sensu   HTTP API查询/登陆redis查询sql\n\n  ```\n  curl -s http://127.0.0.1:4567/clients | jq .\n  curl -s http://localhost:4567/events | jq .\n  curl -s http://localhost:4567/results | jq .\n  curl -s http://localhost:4567/checks | jq .\n\n  ###===>\n  redis-cli\n  keys * \n  get result:tick-client:cpu_metrics\n  ```\n\n  ​\n\n- Openfalcon \n\n  从mysql数据库中取数\n\n  ​\n\n<a href=\"#对比表格\">返回目录</a>\n\n## 网管对接\n\n1. 跟云资源采集类似，将上述监控系统作为一个数据采集中心。开发一个转储接口程序，从监控系统中（数据库或者REST API）读取配置、性能数据等，转换数据格式，存入网管系统。\n\n   优点：可以方便对接第三方开源系统，利用其成熟的监控指标和稳定的监控体系。对原有的网管系统也不需要过多的改造，相当于改造重心在转储接口程序。\n\n   ​ 缺点：需要额外维护多套监控系统以及对应的转换程序；对该转换程序尽可能做得通用，因为可以同时对接多套监控系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。\n\n\n\n2. 仅复用监控系统的采集客户端，类似现在的Agent对接开源组件的模式。例如prometheus，可以复用其exporter。即prometheus exporter独立运行并暴露数据至指定监听端口，Agent开发http接口定时扫描读取该端口暴露的指标即可，然后由KM负责解析转换，最终存入网管系统。\n\n   优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM，对这类采集结果做格式解析处理。exporter暴露的数据指标相对统一，处理起来也比较方便。\n\n   缺点：需要额外维护exporter，且需要开通exporter监听端口的访问权限；exporter的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。\n\n\n\n3. 复用监控系统的采集客户端，同时改造网管系统部分功能。例如telegraf，telegraf支持输出结果到influxdb,或者生成本地json文件。如果是本地Json文件，则与prometheus类似，由KM解析即可。如果是influxdb，则需开发程序从influxdb读取解析数据(相当于另一个数据源)。\n\n   优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM或者influxdb读取程序，对这类采集结果做格式解析处理。telegraf暴露的数据指标相对统一，处理起来也比较方便。\n\n   缺点：需要额外维护telegraf进程；telegraf的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要KM、配置表单，这部分是无法避免的。\n\n<a href=\"#对比表格\">返回目录</a>\n\n\n\n## 支持的采集对象\n\n- Prometheus\n\nhttps://prometheus.io/docs/instrumenting/exporters/\n\n\n\n- Telegraf\n\nhttps://github.com/influxdata/telegraf/tree/master/plugins/inputs\n\njmx方式采集：kafka\n\nhttps://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\n\nhttps://docs.confluent.io/current/kafka/monitoring.html\n\n\n\n- Sensu\n\nhttps://github.com/sensu-plugins\n\n\n\n- Openfalcon\n\nhttps://book.open-falcon.org/zh_0_2/usage/\n\n[https://github.com/iambocai/falcon-monit-scripts](https://github.com/iambocai/falcon-monit-scripts)\n\n\n\n- Datadog \n\nhttps://app.datadoghq.com/account/settings#integrations\n\n\n\n## 结论\n\n采用第二种方案，结合开源组件的客户端和采集脚本，有Agent负责调度，解析结果并返回。\n\n被监控对象：ES /kakfa\n\n实现的客户端：telegraf/openfaclon   客户端\n\n目的：从前台配置开始，最终采集入库\n\n\n\njolokia2 采集分为两种模式，一种是jvm代理，由java应用（kafka）启动时修改参数引入jolokia2 包```-javaagent:/usr/hdp/2.6.1.0-129/kafka/libs/jolokia-jvm-1.5.0-agent.jar=port=8778,host=0.0.0.0```\n\n第二种是Proxy模式，由于第一种应用的限制，proxy模式不需要在应用端修改\n\n","slug":"compared","published":1,"updated":"2018-05-17T12:39:11.808Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczo60004e4rwozbl2dwd","content":"<h2 id=\"Prometheus、TICK、Sensu、Openfalcon-对比\"><a href=\"#Prometheus、TICK、Sensu、Openfalcon-对比\" class=\"headerlink\" title=\"Prometheus、TICK、Sensu、Openfalcon 对比\"></a>Prometheus、TICK、Sensu、Openfalcon 对比</h2><p><strong>目的</strong></p>\n<ul>\n<li>研究开源监控系统架构，完善现有的后台采集结构</li>\n<li>利用开源监控体系中的采集插件，节省KM研究、开发新监控对象（各类分布式组件）的时间</li>\n<li>使用开源监控系统为独立的一套监控系统，作为端到端等分布式应用场景的监控系统</li>\n<li>与现有网管后台结合，将开源监控系统作为一类采集数据源</li>\n</ul>\n<p> OpenTSDB、Graphite 偏向数据存储，并无完整的监控体系（采集、存储、告警、展示）。</p>\n<h2 id=\"对比表格\"><a href=\"#对比表格\" class=\"headerlink\" title=\"对比表格\"></a>对比表格</h2><p>以下列出几个重要的关注点</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">Prometheus</th>\n<th style=\"text-align:center\">TICK</th>\n<th style=\"text-align:center\">Sensu</th>\n<th style=\"text-align:center\">Openfalcon</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">开发语言</td>\n<td style=\"text-align:center\">Go</td>\n<td style=\"text-align:center\">Go</td>\n<td style=\"text-align:center\">ruby</td>\n<td style=\"text-align:center\">Go</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><a href=\"#数据收集方式\">数据收集方式</a></td>\n<td style=\"text-align:center\">Pull/Pushgateway</td>\n<td style=\"text-align:center\">Push</td>\n<td style=\"text-align:center\">Push</td>\n<td style=\"text-align:center\">Push</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">采集客户端</td>\n<td style=\"text-align:center\">各种Exporter</td>\n<td style=\"text-align:center\">telegraf</td>\n<td style=\"text-align:center\">sensu-client<br>各种脚本</td>\n<td style=\"text-align:center\">Falcon-agent<br>各种脚本</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><a href=\"#数据模型\">数据模型</a></td>\n<td style=\"text-align:center\">key+tag</td>\n<td style=\"text-align:center\">key+tag</td>\n<td style=\"text-align:center\">json</td>\n<td style=\"text-align:center\">key+tag</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">存储</td>\n<td style=\"text-align:center\">本地存储 <br>远程数据库(influxDB可读写/OpenTSDB只写)</td>\n<td style=\"text-align:center\">influxDB</td>\n<td style=\"text-align:center\">redis</td>\n<td style=\"text-align:center\">mysql/opentsdb</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">agent部署方式</td>\n<td style=\"text-align:center\">人工</td>\n<td style=\"text-align:center\">人工</td>\n<td style=\"text-align:center\">人工</td>\n<td style=\"text-align:center\">人工</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">任务更新策略</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:center\">dashbord可关联主机和pluins</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><a href=\"#数据查询\">数据查询</a></td>\n<td style=\"text-align:center\">HTTP API</td>\n<td style=\"text-align:center\">SQL/HTTP API</td>\n<td style=\"text-align:center\">HTTP API/redis-cli</td>\n<td style=\"text-align:center\">sql</td>\n</tr>\n</tbody>\n</table>\n<a id=\"more\"></a>\n<h2 id=\"数据收集方式\"><a href=\"#数据收集方式\" class=\"headerlink\" title=\"数据收集方式\"></a>数据收集方式</h2><p>Prometheus 与众不同的采用Pull方式，由服务端主动从被监控机器上面抓取数据。Prometheus 也提供Pushgateway的方式，支持其他数据源主动推送数据到Pushgateway，Pushgateway只做数据缓存，之后仍然是等待服务端抓取。Exporter作为被监控对象暴露指标的客户端，运行在被监控对象上面，并且在Prometheus 服务端配置作为Job，需配置抓取地址端口和间隔。针对各种监控对象，可部署各种Exporter。</p>\n<p>Pull和Push的主要区别在于Pull方式下，监控系统可以方便的增加删除被监控对象，但是需要被监控对象主动开放端口，这对防火墙/NAT方式下的被监控对象是特殊的要求。而Push模式下，每个采集客户端需要知道服务端的信息，才能上报数据。相比之下，网管后台使用Rabbitmq隔离了服务端的信息，但是仍然需要客户端配置Rabbitmq信息。</p>\n<p>TICK使用telegraf作为数据采集端，由telegraf 根据input配置主动采集并发送到output配置的后端，一般是InfluxDB数据库。telegraf还能对采集数据做聚合过滤等处理。telegraf是Go开发的二进制可执行对象，各种对象的采集均打包在一起，通过指定input插件类型，可以指定采集某类指标。相比之下，网管后台使用Java+KM的方式，由Java负责进程调度，KM负责指定采集对象。</p>\n<p>Sensu 也是采用Push 方式，Sensu由Client发送采集数据到transport，服务端再去transport 读取数据，transport一般使用Rabbitmq。这点跟网管有点类似。Client利用插件采集数据，是ruby脚本，需要额外安装。安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。采集配置较为繁琐。</p>\n<p>Openfalcon 也是采用Push 方式，由Client发送采集数据到transport，与Sensu  不同的是，transport 会做一些数据规整，检查之后，转发到多个后端系统去处理。transfer目前支持的业务后端，有三种，judge、graph、opentsdb。judge是告警判定组件，graph作为高性能数据存储、归档、查询组件，opentsdb主要用作数据存储服务。falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。</p>\n<p>综上，其实介绍了四种主要的采集逻辑。以两种不同对象的采集作为示例说明</p>\n<ul>\n<li>主机类指标CPU</li>\n<li>开源软件Redis</li>\n</ul>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h2><p>架构的分层隔离，依赖于各层之间接口的规范。对于采集数据而言，Pull/Push 体现的是传输方式，而数据格式，则是数据组织的规范。以下是各个系统的数据格式。</p>\n<ul>\n<li>openfalcon  采用和OpenTSDB相似的数据格式：metric、endpoint加多组key value tags</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    metric: load.1min,</div><div class=\"line\">    endpoint: open-falcon-host,</div><div class=\"line\">    tags: srv=falcon,idc=aws-sgp,group=az1,</div><div class=\"line\">    value: 1.5,</div><div class=\"line\">    timestamp: `date +%s`,</div><div class=\"line\">    counterType: GAUGE,</div><div class=\"line\">    step: 60</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>其中，metric是监控指标名称，endpoint是监控实体，tags是监控数据的属性标签，counterType是Open-Falcon定义的数据类型(取值为GAUGE、COUNTER)，step为监控数据的上报周期，value和timestamp是有效的监控数据。</p>\n<ul>\n<li><p>prometheus    <metric name=\"\">{<label name=\"\">=<label value=\"\">, …}</label></label></metric></p>\n<p>prometheus 有四种类型的指标：counter、gauge、<a href=\"https://prometheus.io/docs/practices/histograms/\" target=\"_blank\" rel=\"external\">summary、histogram</a> ，<a href=\"http://192.168.7.176:9090/metrics\" target=\"_blank\" rel=\"external\">示例</a></p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP http_requests_total Total number of HTTP requests made.</div><div class=\"line\"># TYPE http_requests_total counter</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;alerts&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;config&quot;,method=&quot;get&quot;&#125; 1</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;flags&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\"></div><div class=\"line\"># HELP go_goroutines Number of goroutines that currently exist.</div><div class=\"line\"># TYPE go_goroutines gauge</div><div class=\"line\">go_goroutines 235</div><div class=\"line\"></div><div class=\"line\"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</div><div class=\"line\"># TYPE go_gc_duration_seconds summary</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0&quot;&#125; 4.5975e-05</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0.25&quot;&#125; 8.3846e-05</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 0.000100729</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0.75&quot;&#125; 0.000123377</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;1&quot;&#125; 0.026837959</div><div class=\"line\">go_gc_duration_seconds_sum 1.990353198</div><div class=\"line\">go_gc_duration_seconds_count 10956</div><div class=\"line\"></div><div class=\"line\"># HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction</div><div class=\"line\"># TYPE prometheus_tsdb_compaction_chunk_range histogram</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;100&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;400&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1600&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6400&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;25600&quot;&#125; 2336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;102400&quot;&#125; 269009</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;409600&quot;&#125; 271929</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1.6384e+06&quot;&#125; 4.2524554e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6.5536e+06&quot;&#125; 4.3107242e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;2.62144e+07&quot;&#125; 4.3107877e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;+Inf&quot;&#125; 4.3107877e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_sum 4.4190173791382e+13</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_count 4.3107877e+07</div></pre></td></tr></table></figure>\n<p>不同类型的指标，有不同的查询方法，需根据指标含义选择合适的查询方法</p>\n<p>histogram_quantile(0.9, rate(prometheus_tsdb_compaction_chunk_range_bucket[10m]))</p>\n<ul>\n<li>Telegraf 支持多种输入输出格式，重点讲解InfluxDB Line Protocol，另外两种是json/Graphite</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">weather,location=us-midwest temperature=82 1465839830100400200</div><div class=\"line\">  |    -------------------- --------------  |</div><div class=\"line\">  |             |             |             |</div><div class=\"line\">  |             |             |             |</div><div class=\"line\">+-----------+--------+-+---------+-+---------+</div><div class=\"line\">|measurement|,tag_set| |field_set| |timestamp|</div><div class=\"line\">+-----------+--------+-+---------+-+---------+</div><div class=\"line\"></div><div class=\"line\">&gt; cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000</div><div class=\"line\">&gt; cpu,cpu=cpu-total,host=0336dcb23579    usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000</div></pre></td></tr></table></figure>\n<p>cpu：measurements ，类似oracle的表名  </p>\n<p>cpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；    内部以，分割 </p>\n<p>usage_guest_nice=0,usage_idle=100,usage_nice=0… : usage_guest_nice等为field，即被采集的指标字段。</p>\n<p><strong><em>field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面</em></strong></p>\n<p>1515338025000000000： time 时间戳</p>\n<p>这里顺便提下 influx metric -&gt; graphite 的转换格式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">template = &quot;host.tags.measurement.field&quot;</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cpu,cpu=cpu-total,dc=us-east-1,host=tars usage_idle=98.09,usage_user=0.89 1455320660004257758</div><div class=\"line\">=&gt;</div><div class=\"line\">tars.cpu-total.us-east-1.cpu.usage_user 0.89 1455320690</div><div class=\"line\">tars.cpu-total.us-east-1.cpu.usage_idle 98.09 1455320690</div></pre></td></tr></table></figure>\n<ul>\n<li>Sensu 指标数据，实际上是check的返回结果。应该是json字符串</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    \"client\": \"tick-client\",</div><div class=\"line\">    \"check\": &#123;</div><div class=\"line\">      \"type\": \"metric\",</div><div class=\"line\">      \"command\": \"metrics-cpu.rb\",</div><div class=\"line\">      \"subscribers\": [</div><div class=\"line\">        \"production\"</div><div class=\"line\">      ],</div><div class=\"line\">      \"interval\": 10,</div><div class=\"line\">      \"handler\": \"tcp_socket\",</div><div class=\"line\">      \"standalone\": true,</div><div class=\"line\">      \"name\": \"cpu_metrics\",</div><div class=\"line\">      \"issued\": 1525270655,</div><div class=\"line\">      \"executed\": 1525270655,</div><div class=\"line\">      \"duration\": 0.074,</div><div class=\"line\">      \"output\": \"tick.cpu.total.user 738228 1525270655\\n...\",</div><div class=\"line\">      \"status\": 0,</div><div class=\"line\">      \"history\": [</div><div class=\"line\">        0,</div><div class=\"line\">\t\t...</div><div class=\"line\">      ]</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>output 就是chcek返回结果。由不同的指标采集插件返回，默认的返回格式是Graphite 格式。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">sensu.cpu.user 0.50 1515534170</div><div class=\"line\">sensu.cpu.nice 0.00 1515534170</div><div class=\"line\">sensu.cpu.system 0.00 1515534170</div><div class=\"line\">sensu.cpu.idle 99.50 1515534170</div><div class=\"line\">sensu.cpu.iowait 0.00 1515534170</div><div class=\"line\">sensu.cpu.irq 0.00 1515534170</div><div class=\"line\">sensu.cpu.softirq 0.00 1515534170</div><div class=\"line\">sensu.cpu.steal 0.00 1515534170</div><div class=\"line\">sensu.cpu.guest 0.00 1515534170</div></pre></td></tr></table></figure>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"数据查询\"><a href=\"#数据查询\" class=\"headerlink\" title=\"数据查询\"></a>数据查询</h2><ul>\n<li><p>Prometheus   HTTP API接口查询，查询结果类型：”resultType”: “matrix” | “vector” | “scalar” | “string”</p>\n<p>matrix ： 返回某个时间段内的指标数据集合</p>\n<p>vector：返回单个时间点的指标数据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Instant queries</div><div class=\"line\">curl &apos;http://192.168.7.176:9090/api/v1/query?query=elasticsearch_node_stats_up&amp;time=1525313513.452&amp;_=1525313461038&apos; -s | python -m json.tool</div><div class=\"line\"></div><div class=\"line\"># Range queries</div><div class=\"line\">curl &apos;http://192.168.7.176:9090/api/v1/query_range?query=prometheus_tsdb_compaction_chunk_range_bucket&amp;start=1525307102.216&amp;end=1525307302.216&amp;step=28&amp;_=1525313461049&apos; -s|python -m json.tool</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p>TICK  HTTP API查询/登陆数据库查询sql</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G &quot;http://192.168.7.176:8086/query?pretty=true&quot; --data-urlencode &quot;db=mydb&quot; \\</div><div class=\"line\">--data-urlencode &quot;q=SELECT * FROM cpu WHERE host=&apos;server01&apos; AND time &lt; now() - 1d&quot;</div><div class=\"line\"></div><div class=\"line\">##==&gt;</div><div class=\"line\">SELECT * FROM cpu WHERE host=&apos;server01&apos; AND time &lt; now() - 1d</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p>Sensu   HTTP API查询/登陆redis查询sql</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -s http://127.0.0.1:4567/clients | jq .</div><div class=\"line\">curl -s http://localhost:4567/events | jq .</div><div class=\"line\">curl -s http://localhost:4567/results | jq .</div><div class=\"line\">curl -s http://localhost:4567/checks | jq .</div><div class=\"line\"></div><div class=\"line\">###===&gt;</div><div class=\"line\">redis-cli</div><div class=\"line\">keys * </div><div class=\"line\">get result:tick-client:cpu_metrics</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p>Openfalcon </p>\n<p>从mysql数据库中取数</p>\n<p>​</p>\n</li>\n</ul>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"网管对接\"><a href=\"#网管对接\" class=\"headerlink\" title=\"网管对接\"></a>网管对接</h2><ol>\n<li><p>跟云资源采集类似，将上述监控系统作为一个数据采集中心。开发一个转储接口程序，从监控系统中（数据库或者REST API）读取配置、性能数据等，转换数据格式，存入网管系统。</p>\n<p>优点：可以方便对接第三方开源系统，利用其成熟的监控指标和稳定的监控体系。对原有的网管系统也不需要过多的改造，相当于改造重心在转储接口程序。</p>\n<p>​ 缺点：需要额外维护多套监控系统以及对应的转换程序；对该转换程序尽可能做得通用，因为可以同时对接多套监控系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。</p>\n</li>\n</ol>\n<ol>\n<li><p>仅复用监控系统的采集客户端，类似现在的Agent对接开源组件的模式。例如prometheus，可以复用其exporter。即prometheus exporter独立运行并暴露数据至指定监听端口，Agent开发http接口定时扫描读取该端口暴露的指标即可，然后由KM负责解析转换，最终存入网管系统。</p>\n<p>优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM，对这类采集结果做格式解析处理。exporter暴露的数据指标相对统一，处理起来也比较方便。</p>\n<p>缺点：需要额外维护exporter，且需要开通exporter监听端口的访问权限；exporter的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。</p>\n</li>\n</ol>\n<ol>\n<li><p>复用监控系统的采集客户端，同时改造网管系统部分功能。例如telegraf，telegraf支持输出结果到influxdb,或者生成本地json文件。如果是本地Json文件，则与prometheus类似，由KM解析即可。如果是influxdb，则需开发程序从influxdb读取解析数据(相当于另一个数据源)。</p>\n<p>优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM或者influxdb读取程序，对这类采集结果做格式解析处理。telegraf暴露的数据指标相对统一，处理起来也比较方便。</p>\n<p>缺点：需要额外维护telegraf进程；telegraf的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要KM、配置表单，这部分是无法避免的。</p>\n</li>\n</ol>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"支持的采集对象\"><a href=\"#支持的采集对象\" class=\"headerlink\" title=\"支持的采集对象\"></a>支持的采集对象</h2><ul>\n<li>Prometheus</li>\n</ul>\n<p><a href=\"https://prometheus.io/docs/instrumenting/exporters/\" target=\"_blank\" rel=\"external\">https://prometheus.io/docs/instrumenting/exporters/</a></p>\n<ul>\n<li>Telegraf</li>\n</ul>\n<p><a href=\"https://github.com/influxdata/telegraf/tree/master/plugins/inputs\" target=\"_blank\" rel=\"external\">https://github.com/influxdata/telegraf/tree/master/plugins/inputs</a></p>\n<p>jmx方式采集：kafka</p>\n<p><a href=\"https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\" target=\"_blank\" rel=\"external\">https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2</a></p>\n<p><a href=\"https://docs.confluent.io/current/kafka/monitoring.html\" target=\"_blank\" rel=\"external\">https://docs.confluent.io/current/kafka/monitoring.html</a></p>\n<ul>\n<li>Sensu</li>\n</ul>\n<p><a href=\"https://github.com/sensu-plugins\" target=\"_blank\" rel=\"external\">https://github.com/sensu-plugins</a></p>\n<ul>\n<li>Openfalcon</li>\n</ul>\n<p><a href=\"https://book.open-falcon.org/zh_0_2/usage/\" target=\"_blank\" rel=\"external\">https://book.open-falcon.org/zh_0_2/usage/</a></p>\n<p><a href=\"https://github.com/iambocai/falcon-monit-scripts\" target=\"_blank\" rel=\"external\">https://github.com/iambocai/falcon-monit-scripts</a></p>\n<ul>\n<li>Datadog </li>\n</ul>\n<p><a href=\"https://app.datadoghq.com/account/settings#integrations\" target=\"_blank\" rel=\"external\">https://app.datadoghq.com/account/settings#integrations</a></p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>采用第二种方案，结合开源组件的客户端和采集脚本，有Agent负责调度，解析结果并返回。</p>\n<p>被监控对象：ES /kakfa</p>\n<p>实现的客户端：telegraf/openfaclon   客户端</p>\n<p>目的：从前台配置开始，最终采集入库</p>\n<p>jolokia2 采集分为两种模式，一种是jvm代理，由java应用（kafka）启动时修改参数引入jolokia2 包<code>-javaagent:/usr/hdp/2.6.1.0-129/kafka/libs/jolokia-jvm-1.5.0-agent.jar=port=8778,host=0.0.0.0</code></p>\n<p>第二种是Proxy模式，由于第一种应用的限制，proxy模式不需要在应用端修改</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"Prometheus、TICK、Sensu、Openfalcon-对比\"><a href=\"#Prometheus、TICK、Sensu、Openfalcon-对比\" class=\"headerlink\" title=\"Prometheus、TICK、Sensu、Openfalcon 对比\"></a>Prometheus、TICK、Sensu、Openfalcon 对比</h2><p><strong>目的</strong></p>\n<ul>\n<li>研究开源监控系统架构，完善现有的后台采集结构</li>\n<li>利用开源监控体系中的采集插件，节省KM研究、开发新监控对象（各类分布式组件）的时间</li>\n<li>使用开源监控系统为独立的一套监控系统，作为端到端等分布式应用场景的监控系统</li>\n<li>与现有网管后台结合，将开源监控系统作为一类采集数据源</li>\n</ul>\n<p> OpenTSDB、Graphite 偏向数据存储，并无完整的监控体系（采集、存储、告警、展示）。</p>\n<h2 id=\"对比表格\"><a href=\"#对比表格\" class=\"headerlink\" title=\"对比表格\"></a>对比表格</h2><p>以下列出几个重要的关注点</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">Prometheus</th>\n<th style=\"text-align:center\">TICK</th>\n<th style=\"text-align:center\">Sensu</th>\n<th style=\"text-align:center\">Openfalcon</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">开发语言</td>\n<td style=\"text-align:center\">Go</td>\n<td style=\"text-align:center\">Go</td>\n<td style=\"text-align:center\">ruby</td>\n<td style=\"text-align:center\">Go</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><a href=\"#数据收集方式\">数据收集方式</a></td>\n<td style=\"text-align:center\">Pull/Pushgateway</td>\n<td style=\"text-align:center\">Push</td>\n<td style=\"text-align:center\">Push</td>\n<td style=\"text-align:center\">Push</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">采集客户端</td>\n<td style=\"text-align:center\">各种Exporter</td>\n<td style=\"text-align:center\">telegraf</td>\n<td style=\"text-align:center\">sensu-client<br>各种脚本</td>\n<td style=\"text-align:center\">Falcon-agent<br>各种脚本</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><a href=\"#数据模型\">数据模型</a></td>\n<td style=\"text-align:center\">key+tag</td>\n<td style=\"text-align:center\">key+tag</td>\n<td style=\"text-align:center\">json</td>\n<td style=\"text-align:center\">key+tag</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">存储</td>\n<td style=\"text-align:center\">本地存储 <br>远程数据库(influxDB可读写/OpenTSDB只写)</td>\n<td style=\"text-align:center\">influxDB</td>\n<td style=\"text-align:center\">redis</td>\n<td style=\"text-align:center\">mysql/opentsdb</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">agent部署方式</td>\n<td style=\"text-align:center\">人工</td>\n<td style=\"text-align:center\">人工</td>\n<td style=\"text-align:center\">人工</td>\n<td style=\"text-align:center\">人工</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">任务更新策略</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:center\">无</td>\n<td style=\"text-align:center\">dashbord可关联主机和pluins</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><a href=\"#数据查询\">数据查询</a></td>\n<td style=\"text-align:center\">HTTP API</td>\n<td style=\"text-align:center\">SQL/HTTP API</td>\n<td style=\"text-align:center\">HTTP API/redis-cli</td>\n<td style=\"text-align:center\">sql</td>\n</tr>\n</tbody>\n</table>","more":"<h2 id=\"数据收集方式\"><a href=\"#数据收集方式\" class=\"headerlink\" title=\"数据收集方式\"></a>数据收集方式</h2><p>Prometheus 与众不同的采用Pull方式，由服务端主动从被监控机器上面抓取数据。Prometheus 也提供Pushgateway的方式，支持其他数据源主动推送数据到Pushgateway，Pushgateway只做数据缓存，之后仍然是等待服务端抓取。Exporter作为被监控对象暴露指标的客户端，运行在被监控对象上面，并且在Prometheus 服务端配置作为Job，需配置抓取地址端口和间隔。针对各种监控对象，可部署各种Exporter。</p>\n<p>Pull和Push的主要区别在于Pull方式下，监控系统可以方便的增加删除被监控对象，但是需要被监控对象主动开放端口，这对防火墙/NAT方式下的被监控对象是特殊的要求。而Push模式下，每个采集客户端需要知道服务端的信息，才能上报数据。相比之下，网管后台使用Rabbitmq隔离了服务端的信息，但是仍然需要客户端配置Rabbitmq信息。</p>\n<p>TICK使用telegraf作为数据采集端，由telegraf 根据input配置主动采集并发送到output配置的后端，一般是InfluxDB数据库。telegraf还能对采集数据做聚合过滤等处理。telegraf是Go开发的二进制可执行对象，各种对象的采集均打包在一起，通过指定input插件类型，可以指定采集某类指标。相比之下，网管后台使用Java+KM的方式，由Java负责进程调度，KM负责指定采集对象。</p>\n<p>Sensu 也是采用Push 方式，Sensu由Client发送采集数据到transport，服务端再去transport 读取数据，transport一般使用Rabbitmq。这点跟网管有点类似。Client利用插件采集数据，是ruby脚本，需要额外安装。安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。采集配置较为繁琐。</p>\n<p>Openfalcon 也是采用Push 方式，由Client发送采集数据到transport，与Sensu  不同的是，transport 会做一些数据规整，检查之后，转发到多个后端系统去处理。transfer目前支持的业务后端，有三种，judge、graph、opentsdb。judge是告警判定组件，graph作为高性能数据存储、归档、查询组件，opentsdb主要用作数据存储服务。falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。</p>\n<p>综上，其实介绍了四种主要的采集逻辑。以两种不同对象的采集作为示例说明</p>\n<ul>\n<li>主机类指标CPU</li>\n<li>开源软件Redis</li>\n</ul>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"数据模型\"><a href=\"#数据模型\" class=\"headerlink\" title=\"数据模型\"></a>数据模型</h2><p>架构的分层隔离，依赖于各层之间接口的规范。对于采集数据而言，Pull/Push 体现的是传输方式，而数据格式，则是数据组织的规范。以下是各个系统的数据格式。</p>\n<ul>\n<li>openfalcon  采用和OpenTSDB相似的数据格式：metric、endpoint加多组key value tags</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    metric: load.1min,</div><div class=\"line\">    endpoint: open-falcon-host,</div><div class=\"line\">    tags: srv=falcon,idc=aws-sgp,group=az1,</div><div class=\"line\">    value: 1.5,</div><div class=\"line\">    timestamp: `date +%s`,</div><div class=\"line\">    counterType: GAUGE,</div><div class=\"line\">    step: 60</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>其中，metric是监控指标名称，endpoint是监控实体，tags是监控数据的属性标签，counterType是Open-Falcon定义的数据类型(取值为GAUGE、COUNTER)，step为监控数据的上报周期，value和timestamp是有效的监控数据。</p>\n<ul>\n<li><p>prometheus    <metric name=\"\">{<label name=\"\">=<label value=\"\">, …}</label></label></metric></p>\n<p>prometheus 有四种类型的指标：counter、gauge、<a href=\"https://prometheus.io/docs/practices/histograms/\" target=\"_blank\" rel=\"external\">summary、histogram</a> ，<a href=\"http://192.168.7.176:9090/metrics\" target=\"_blank\" rel=\"external\">示例</a></p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP http_requests_total Total number of HTTP requests made.</div><div class=\"line\"># TYPE http_requests_total counter</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;alerts&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;config&quot;,method=&quot;get&quot;&#125; 1</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;flags&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\"></div><div class=\"line\"># HELP go_goroutines Number of goroutines that currently exist.</div><div class=\"line\"># TYPE go_goroutines gauge</div><div class=\"line\">go_goroutines 235</div><div class=\"line\"></div><div class=\"line\"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</div><div class=\"line\"># TYPE go_gc_duration_seconds summary</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0&quot;&#125; 4.5975e-05</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0.25&quot;&#125; 8.3846e-05</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 0.000100729</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;0.75&quot;&#125; 0.000123377</div><div class=\"line\">go_gc_duration_seconds&#123;quantile=&quot;1&quot;&#125; 0.026837959</div><div class=\"line\">go_gc_duration_seconds_sum 1.990353198</div><div class=\"line\">go_gc_duration_seconds_count 10956</div><div class=\"line\"></div><div class=\"line\"># HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction</div><div class=\"line\"># TYPE prometheus_tsdb_compaction_chunk_range histogram</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;100&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;400&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1600&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6400&quot;&#125; 336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;25600&quot;&#125; 2336</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;102400&quot;&#125; 269009</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;409600&quot;&#125; 271929</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1.6384e+06&quot;&#125; 4.2524554e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6.5536e+06&quot;&#125; 4.3107242e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;2.62144e+07&quot;&#125; 4.3107877e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;+Inf&quot;&#125; 4.3107877e+07</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_sum 4.4190173791382e+13</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_count 4.3107877e+07</div></pre></td></tr></table></figure>\n<p>不同类型的指标，有不同的查询方法，需根据指标含义选择合适的查询方法</p>\n<p>histogram_quantile(0.9, rate(prometheus_tsdb_compaction_chunk_range_bucket[10m]))</p>\n<ul>\n<li>Telegraf 支持多种输入输出格式，重点讲解InfluxDB Line Protocol，另外两种是json/Graphite</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">weather,location=us-midwest temperature=82 1465839830100400200</div><div class=\"line\">  |    -------------------- --------------  |</div><div class=\"line\">  |             |             |             |</div><div class=\"line\">  |             |             |             |</div><div class=\"line\">+-----------+--------+-+---------+-+---------+</div><div class=\"line\">|measurement|,tag_set| |field_set| |timestamp|</div><div class=\"line\">+-----------+--------+-+---------+-+---------+</div><div class=\"line\"></div><div class=\"line\">&gt; cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000</div><div class=\"line\">&gt; cpu,cpu=cpu-total,host=0336dcb23579    usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000</div></pre></td></tr></table></figure>\n<p>cpu：measurements ，类似oracle的表名  </p>\n<p>cpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；    内部以，分割 </p>\n<p>usage_guest_nice=0,usage_idle=100,usage_nice=0… : usage_guest_nice等为field，即被采集的指标字段。</p>\n<p><strong><em>field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面</em></strong></p>\n<p>1515338025000000000： time 时间戳</p>\n<p>这里顺便提下 influx metric -&gt; graphite 的转换格式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">template = &quot;host.tags.measurement.field&quot;</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">cpu,cpu=cpu-total,dc=us-east-1,host=tars usage_idle=98.09,usage_user=0.89 1455320660004257758</div><div class=\"line\">=&gt;</div><div class=\"line\">tars.cpu-total.us-east-1.cpu.usage_user 0.89 1455320690</div><div class=\"line\">tars.cpu-total.us-east-1.cpu.usage_idle 98.09 1455320690</div></pre></td></tr></table></figure>\n<ul>\n<li>Sensu 指标数据，实际上是check的返回结果。应该是json字符串</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">    \"client\": \"tick-client\",</div><div class=\"line\">    \"check\": &#123;</div><div class=\"line\">      \"type\": \"metric\",</div><div class=\"line\">      \"command\": \"metrics-cpu.rb\",</div><div class=\"line\">      \"subscribers\": [</div><div class=\"line\">        \"production\"</div><div class=\"line\">      ],</div><div class=\"line\">      \"interval\": 10,</div><div class=\"line\">      \"handler\": \"tcp_socket\",</div><div class=\"line\">      \"standalone\": true,</div><div class=\"line\">      \"name\": \"cpu_metrics\",</div><div class=\"line\">      \"issued\": 1525270655,</div><div class=\"line\">      \"executed\": 1525270655,</div><div class=\"line\">      \"duration\": 0.074,</div><div class=\"line\">      \"output\": \"tick.cpu.total.user 738228 1525270655\\n...\",</div><div class=\"line\">      \"status\": 0,</div><div class=\"line\">      \"history\": [</div><div class=\"line\">        0,</div><div class=\"line\">\t\t...</div><div class=\"line\">      ]</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>output 就是chcek返回结果。由不同的指标采集插件返回，默认的返回格式是Graphite 格式。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">sensu.cpu.user 0.50 1515534170</div><div class=\"line\">sensu.cpu.nice 0.00 1515534170</div><div class=\"line\">sensu.cpu.system 0.00 1515534170</div><div class=\"line\">sensu.cpu.idle 99.50 1515534170</div><div class=\"line\">sensu.cpu.iowait 0.00 1515534170</div><div class=\"line\">sensu.cpu.irq 0.00 1515534170</div><div class=\"line\">sensu.cpu.softirq 0.00 1515534170</div><div class=\"line\">sensu.cpu.steal 0.00 1515534170</div><div class=\"line\">sensu.cpu.guest 0.00 1515534170</div></pre></td></tr></table></figure>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"数据查询\"><a href=\"#数据查询\" class=\"headerlink\" title=\"数据查询\"></a>数据查询</h2><ul>\n<li><p>Prometheus   HTTP API接口查询，查询结果类型：”resultType”: “matrix” | “vector” | “scalar” | “string”</p>\n<p>matrix ： 返回某个时间段内的指标数据集合</p>\n<p>vector：返回单个时间点的指标数据</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Instant queries</div><div class=\"line\">curl &apos;http://192.168.7.176:9090/api/v1/query?query=elasticsearch_node_stats_up&amp;time=1525313513.452&amp;_=1525313461038&apos; -s | python -m json.tool</div><div class=\"line\"></div><div class=\"line\"># Range queries</div><div class=\"line\">curl &apos;http://192.168.7.176:9090/api/v1/query_range?query=prometheus_tsdb_compaction_chunk_range_bucket&amp;start=1525307102.216&amp;end=1525307302.216&amp;step=28&amp;_=1525313461049&apos; -s|python -m json.tool</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p>TICK  HTTP API查询/登陆数据库查询sql</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G &quot;http://192.168.7.176:8086/query?pretty=true&quot; --data-urlencode &quot;db=mydb&quot; \\</div><div class=\"line\">--data-urlencode &quot;q=SELECT * FROM cpu WHERE host=&apos;server01&apos; AND time &lt; now() - 1d&quot;</div><div class=\"line\"></div><div class=\"line\">##==&gt;</div><div class=\"line\">SELECT * FROM cpu WHERE host=&apos;server01&apos; AND time &lt; now() - 1d</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p>Sensu   HTTP API查询/登陆redis查询sql</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -s http://127.0.0.1:4567/clients | jq .</div><div class=\"line\">curl -s http://localhost:4567/events | jq .</div><div class=\"line\">curl -s http://localhost:4567/results | jq .</div><div class=\"line\">curl -s http://localhost:4567/checks | jq .</div><div class=\"line\"></div><div class=\"line\">###===&gt;</div><div class=\"line\">redis-cli</div><div class=\"line\">keys * </div><div class=\"line\">get result:tick-client:cpu_metrics</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n<li><p>Openfalcon </p>\n<p>从mysql数据库中取数</p>\n<p>​</p>\n</li>\n</ul>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"网管对接\"><a href=\"#网管对接\" class=\"headerlink\" title=\"网管对接\"></a>网管对接</h2><ol>\n<li><p>跟云资源采集类似，将上述监控系统作为一个数据采集中心。开发一个转储接口程序，从监控系统中（数据库或者REST API）读取配置、性能数据等，转换数据格式，存入网管系统。</p>\n<p>优点：可以方便对接第三方开源系统，利用其成熟的监控指标和稳定的监控体系。对原有的网管系统也不需要过多的改造，相当于改造重心在转储接口程序。</p>\n<p>​ 缺点：需要额外维护多套监控系统以及对应的转换程序；对该转换程序尽可能做得通用，因为可以同时对接多套监控系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。</p>\n</li>\n</ol>\n<ol>\n<li><p>仅复用监控系统的采集客户端，类似现在的Agent对接开源组件的模式。例如prometheus，可以复用其exporter。即prometheus exporter独立运行并暴露数据至指定监听端口，Agent开发http接口定时扫描读取该端口暴露的指标即可，然后由KM负责解析转换，最终存入网管系统。</p>\n<p>优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM，对这类采集结果做格式解析处理。exporter暴露的数据指标相对统一，处理起来也比较方便。</p>\n<p>缺点：需要额外维护exporter，且需要开通exporter监听端口的访问权限；exporter的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要开发KM、配置表单，这部分是无法避免的。</p>\n</li>\n</ol>\n<ol>\n<li><p>复用监控系统的采集客户端，同时改造网管系统部分功能。例如telegraf，telegraf支持输出结果到influxdb,或者生成本地json文件。如果是本地Json文件，则与prometheus类似，由KM解析即可。如果是influxdb，则需开发程序从influxdb读取解析数据(相当于另一个数据源)。</p>\n<p>优点：仅仅用到第三方开源系统的采集客户端，抓取我们想要的数据。对原有的网管系统也不需要过多的改造，仅需要新增KM或者influxdb读取程序，对这类采集结果做格式解析处理。telegraf暴露的数据指标相对统一，处理起来也比较方便。</p>\n<p>缺点：需要额外维护telegraf进程；telegraf的定义配置如何通知给网管系统；对于指标的定义、配置，仍然需要沿用原来的方法，即还要KM、配置表单，这部分是无法避免的。</p>\n</li>\n</ol>\n<p><a href=\"#对比表格\">返回目录</a></p>\n<h2 id=\"支持的采集对象\"><a href=\"#支持的采集对象\" class=\"headerlink\" title=\"支持的采集对象\"></a>支持的采集对象</h2><ul>\n<li>Prometheus</li>\n</ul>\n<p><a href=\"https://prometheus.io/docs/instrumenting/exporters/\" target=\"_blank\" rel=\"external\">https://prometheus.io/docs/instrumenting/exporters/</a></p>\n<ul>\n<li>Telegraf</li>\n</ul>\n<p><a href=\"https://github.com/influxdata/telegraf/tree/master/plugins/inputs\" target=\"_blank\" rel=\"external\">https://github.com/influxdata/telegraf/tree/master/plugins/inputs</a></p>\n<p>jmx方式采集：kafka</p>\n<p><a href=\"https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\" target=\"_blank\" rel=\"external\">https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2</a></p>\n<p><a href=\"https://docs.confluent.io/current/kafka/monitoring.html\" target=\"_blank\" rel=\"external\">https://docs.confluent.io/current/kafka/monitoring.html</a></p>\n<ul>\n<li>Sensu</li>\n</ul>\n<p><a href=\"https://github.com/sensu-plugins\" target=\"_blank\" rel=\"external\">https://github.com/sensu-plugins</a></p>\n<ul>\n<li>Openfalcon</li>\n</ul>\n<p><a href=\"https://book.open-falcon.org/zh_0_2/usage/\" target=\"_blank\" rel=\"external\">https://book.open-falcon.org/zh_0_2/usage/</a></p>\n<p><a href=\"https://github.com/iambocai/falcon-monit-scripts\" target=\"_blank\" rel=\"external\">https://github.com/iambocai/falcon-monit-scripts</a></p>\n<ul>\n<li>Datadog </li>\n</ul>\n<p><a href=\"https://app.datadoghq.com/account/settings#integrations\" target=\"_blank\" rel=\"external\">https://app.datadoghq.com/account/settings#integrations</a></p>\n<h2 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h2><p>采用第二种方案，结合开源组件的客户端和采集脚本，有Agent负责调度，解析结果并返回。</p>\n<p>被监控对象：ES /kakfa</p>\n<p>实现的客户端：telegraf/openfaclon   客户端</p>\n<p>目的：从前台配置开始，最终采集入库</p>\n<p>jolokia2 采集分为两种模式，一种是jvm代理，由java应用（kafka）启动时修改参数引入jolokia2 包<code>-javaagent:/usr/hdp/2.6.1.0-129/kafka/libs/jolokia-jvm-1.5.0-agent.jar=port=8778,host=0.0.0.0</code></p>\n<p>第二种是Proxy模式，由于第一种应用的限制，proxy模式不需要在应用端修改</p>"},{"title":"代码整洁之道","date":"2014-08-20T12:54:30.000Z","_content":"\n这是一本关于如何写好代码，如何当好一名优秀的程序员的书籍。在本书中，作者引用IT牛人的话，阐述了什么是简洁的代码，然后提出了自己的看法。正如作者一直强调的，光看书是远远不够的，要勤于练习，不断改正，才能有所收获。下面就让我们来一探究竟。\n\n# 整洁的代码\n在这章里面，作者探讨了整洁的代码的重要性，以及何为简洁的代码。\n# 有意义的命名\n>名副其实，而且一旦发现有更好的名字，立即换掉旧的。\n避免误导\n有意义的区分,Variable一词永远不应当出现在变量名中，table一词也不应当出现在表名中。\n使用读得出来的名称\n使用可搜索的名称\n避免使用编码\n类名：类名和对象名应该是名词或者名词短语，而不应该是动词。\n方法名：方法名应当是动词或者动词短语。    \n每个概念对应一个词，不要使用双关语。\n不要添加没用的语境：不要添加重复相同的前缀。只要短名称足够清除，就要比长名称好。对于Address类的实体来说，accountAddress和customerAddress都是不错的对象名称，但是用在类名上就不好了。Address是个好类名，如果需要与MAC地址，端口地址，WEB地址做区别，我会考虑使用PostalAddress、MAC和URI。这样的名称更为精确，而精确正是命名的要点。\n\n<!-- more -->\n# 函数 \n通过函数名，可以读出来它是干什么的\n短小，只做一件事情，每个函数一个抽象层次：如果函数只是做了该函数名下同一抽象层上的步骤，则函数还是只是做了一件事。编写函数，毕竟是为了把大一些的概念（换言之，函数的名称）拆分成另一抽象层级的一系列处理步骤。\n避免重复。\n如何写出好的函数：刚开始写函数时，有太多的缩进和嵌套循环，有过长的参数列表，名称是随意取的，也会有重复的代码。不过会配上一套测试单元，覆盖每行丑陋的代码。然后再打磨这些代码，分解函数，修改名称，消除重复，缩短和重新安置方法。有时，还拆散类，保持测试通过。\n# 注释\n少用注释，有些日志注释交给版本管理工具\n\n# 代码格式\n变量声明，应尽可能的靠近其使用位置。\n实体变量应该在类的顶部声明。\n相关函数，应该放在一起。\n探索了各种缩进和空格的使用。最重要的是良好的书写代码的习惯和风格，并且保持一致。记住，代码被阅读的时间远远超过写的时间。所以，写好每一段代码。就像讲好每一个故事一样。\n\n# 对象和数据结构\n对象把数据隐藏于抽象之后，暴露操作数据的函数。数据结构暴露其数据，没有提供有意义的函数。过程式代码（使用数据结构的代码）便于在不改动既有数据结构的前提下添加新的函数，而面向对象代码便于在不改动既有函数的前提下添加新类。反过来讲也说得通，过程式代码难以添加新数据结构，因为必须修改所有函数，面向对象的代码难以修改函数，因为必须修改所有类。\n# 错误处理\n将错误处理隔离看待，独立于主要的程序逻辑，就能写出强固而简洁的代码。\n# 边界\n# 单元测试\n# 类\n类应当短小：应该能够用大概25个单词描述一个类，而且不能用“if”,\"and\",\"or\",\"but\"等词汇。\n单一职权原则：只有一个修改的理由\n内聚：类应该只有少量的实体变量。类中的每个方法都应该操作一个或者多个这种变量。\n\n# 系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\n工厂\n控制反转\nAOP   \n# 迭进    \n软件项目的主要成本在于长期维护。\n# 并发编程\n对象是过程的抽象，线程是调度的抽象。\n第一要诀还是遵守单一权责原则，了解并发问题的可能原因，学习类库，了解基本算法，学习如何找到必须锁定的区域并锁定之。\n# 逐步改进\n对一个命令行参数解析程序的案例研究\n要编写整洁的代码，必须先写肮脏代码，然后再清理它。\n\n# Junit内幕\n# 重构SerialDate\n# 味道与启发\n\n\n\n","source":"_posts/clean-code.md","raw":"---\ntitle: 代码整洁之道\ndate: 2014-08-20 20:54:30\ntags: 随笔\n---\n\n这是一本关于如何写好代码，如何当好一名优秀的程序员的书籍。在本书中，作者引用IT牛人的话，阐述了什么是简洁的代码，然后提出了自己的看法。正如作者一直强调的，光看书是远远不够的，要勤于练习，不断改正，才能有所收获。下面就让我们来一探究竟。\n\n# 整洁的代码\n在这章里面，作者探讨了整洁的代码的重要性，以及何为简洁的代码。\n# 有意义的命名\n>名副其实，而且一旦发现有更好的名字，立即换掉旧的。\n避免误导\n有意义的区分,Variable一词永远不应当出现在变量名中，table一词也不应当出现在表名中。\n使用读得出来的名称\n使用可搜索的名称\n避免使用编码\n类名：类名和对象名应该是名词或者名词短语，而不应该是动词。\n方法名：方法名应当是动词或者动词短语。    \n每个概念对应一个词，不要使用双关语。\n不要添加没用的语境：不要添加重复相同的前缀。只要短名称足够清除，就要比长名称好。对于Address类的实体来说，accountAddress和customerAddress都是不错的对象名称，但是用在类名上就不好了。Address是个好类名，如果需要与MAC地址，端口地址，WEB地址做区别，我会考虑使用PostalAddress、MAC和URI。这样的名称更为精确，而精确正是命名的要点。\n\n<!-- more -->\n# 函数 \n通过函数名，可以读出来它是干什么的\n短小，只做一件事情，每个函数一个抽象层次：如果函数只是做了该函数名下同一抽象层上的步骤，则函数还是只是做了一件事。编写函数，毕竟是为了把大一些的概念（换言之，函数的名称）拆分成另一抽象层级的一系列处理步骤。\n避免重复。\n如何写出好的函数：刚开始写函数时，有太多的缩进和嵌套循环，有过长的参数列表，名称是随意取的，也会有重复的代码。不过会配上一套测试单元，覆盖每行丑陋的代码。然后再打磨这些代码，分解函数，修改名称，消除重复，缩短和重新安置方法。有时，还拆散类，保持测试通过。\n# 注释\n少用注释，有些日志注释交给版本管理工具\n\n# 代码格式\n变量声明，应尽可能的靠近其使用位置。\n实体变量应该在类的顶部声明。\n相关函数，应该放在一起。\n探索了各种缩进和空格的使用。最重要的是良好的书写代码的习惯和风格，并且保持一致。记住，代码被阅读的时间远远超过写的时间。所以，写好每一段代码。就像讲好每一个故事一样。\n\n# 对象和数据结构\n对象把数据隐藏于抽象之后，暴露操作数据的函数。数据结构暴露其数据，没有提供有意义的函数。过程式代码（使用数据结构的代码）便于在不改动既有数据结构的前提下添加新的函数，而面向对象代码便于在不改动既有函数的前提下添加新类。反过来讲也说得通，过程式代码难以添加新数据结构，因为必须修改所有函数，面向对象的代码难以修改函数，因为必须修改所有类。\n# 错误处理\n将错误处理隔离看待，独立于主要的程序逻辑，就能写出强固而简洁的代码。\n# 边界\n# 单元测试\n# 类\n类应当短小：应该能够用大概25个单词描述一个类，而且不能用“if”,\"and\",\"or\",\"but\"等词汇。\n单一职权原则：只有一个修改的理由\n内聚：类应该只有少量的实体变量。类中的每个方法都应该操作一个或者多个这种变量。\n\n# 系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\n工厂\n控制反转\nAOP   \n# 迭进    \n软件项目的主要成本在于长期维护。\n# 并发编程\n对象是过程的抽象，线程是调度的抽象。\n第一要诀还是遵守单一权责原则，了解并发问题的可能原因，学习类库，了解基本算法，学习如何找到必须锁定的区域并锁定之。\n# 逐步改进\n对一个命令行参数解析程序的案例研究\n要编写整洁的代码，必须先写肮脏代码，然后再清理它。\n\n# Junit内幕\n# 重构SerialDate\n# 味道与启发\n\n\n\n","slug":"clean-code","published":1,"updated":"2018-04-27T04:11:03.330Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczo80005e4rw9po13kw9","content":"<p>这是一本关于如何写好代码，如何当好一名优秀的程序员的书籍。在本书中，作者引用IT牛人的话，阐述了什么是简洁的代码，然后提出了自己的看法。正如作者一直强调的，光看书是远远不够的，要勤于练习，不断改正，才能有所收获。下面就让我们来一探究竟。</p>\n<h1 id=\"整洁的代码\"><a href=\"#整洁的代码\" class=\"headerlink\" title=\"整洁的代码\"></a>整洁的代码</h1><p>在这章里面，作者探讨了整洁的代码的重要性，以及何为简洁的代码。</p>\n<h1 id=\"有意义的命名\"><a href=\"#有意义的命名\" class=\"headerlink\" title=\"有意义的命名\"></a>有意义的命名</h1><blockquote>\n<p>名副其实，而且一旦发现有更好的名字，立即换掉旧的。<br>避免误导<br>有意义的区分,Variable一词永远不应当出现在变量名中，table一词也不应当出现在表名中。<br>使用读得出来的名称<br>使用可搜索的名称<br>避免使用编码<br>类名：类名和对象名应该是名词或者名词短语，而不应该是动词。<br>方法名：方法名应当是动词或者动词短语。<br>每个概念对应一个词，不要使用双关语。<br>不要添加没用的语境：不要添加重复相同的前缀。只要短名称足够清除，就要比长名称好。对于Address类的实体来说，accountAddress和customerAddress都是不错的对象名称，但是用在类名上就不好了。Address是个好类名，如果需要与MAC地址，端口地址，WEB地址做区别，我会考虑使用PostalAddress、MAC和URI。这样的名称更为精确，而精确正是命名的要点。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h1><p>通过函数名，可以读出来它是干什么的<br>短小，只做一件事情，每个函数一个抽象层次：如果函数只是做了该函数名下同一抽象层上的步骤，则函数还是只是做了一件事。编写函数，毕竟是为了把大一些的概念（换言之，函数的名称）拆分成另一抽象层级的一系列处理步骤。<br>避免重复。<br>如何写出好的函数：刚开始写函数时，有太多的缩进和嵌套循环，有过长的参数列表，名称是随意取的，也会有重复的代码。不过会配上一套测试单元，覆盖每行丑陋的代码。然后再打磨这些代码，分解函数，修改名称，消除重复，缩短和重新安置方法。有时，还拆散类，保持测试通过。</p>\n<h1 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h1><p>少用注释，有些日志注释交给版本管理工具</p>\n<h1 id=\"代码格式\"><a href=\"#代码格式\" class=\"headerlink\" title=\"代码格式\"></a>代码格式</h1><p>变量声明，应尽可能的靠近其使用位置。<br>实体变量应该在类的顶部声明。<br>相关函数，应该放在一起。<br>探索了各种缩进和空格的使用。最重要的是良好的书写代码的习惯和风格，并且保持一致。记住，代码被阅读的时间远远超过写的时间。所以，写好每一段代码。就像讲好每一个故事一样。</p>\n<h1 id=\"对象和数据结构\"><a href=\"#对象和数据结构\" class=\"headerlink\" title=\"对象和数据结构\"></a>对象和数据结构</h1><p>对象把数据隐藏于抽象之后，暴露操作数据的函数。数据结构暴露其数据，没有提供有意义的函数。过程式代码（使用数据结构的代码）便于在不改动既有数据结构的前提下添加新的函数，而面向对象代码便于在不改动既有函数的前提下添加新类。反过来讲也说得通，过程式代码难以添加新数据结构，因为必须修改所有函数，面向对象的代码难以修改函数，因为必须修改所有类。</p>\n<h1 id=\"错误处理\"><a href=\"#错误处理\" class=\"headerlink\" title=\"错误处理\"></a>错误处理</h1><p>将错误处理隔离看待，独立于主要的程序逻辑，就能写出强固而简洁的代码。</p>\n<h1 id=\"边界\"><a href=\"#边界\" class=\"headerlink\" title=\"边界\"></a>边界</h1><h1 id=\"单元测试\"><a href=\"#单元测试\" class=\"headerlink\" title=\"单元测试\"></a>单元测试</h1><h1 id=\"类\"><a href=\"#类\" class=\"headerlink\" title=\"类\"></a>类</h1><p>类应当短小：应该能够用大概25个单词描述一个类，而且不能用“if”,”and”,”or”,”but”等词汇。<br>单一职权原则：只有一个修改的理由<br>内聚：类应该只有少量的实体变量。类中的每个方法都应该操作一个或者多个这种变量。</p>\n<h1 id=\"系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\"><a href=\"#系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\" class=\"headerlink\" title=\"系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\"></a>系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。</h1><p>工厂<br>控制反转<br>AOP   </p>\n<h1 id=\"迭进\"><a href=\"#迭进\" class=\"headerlink\" title=\"迭进\"></a>迭进</h1><p>软件项目的主要成本在于长期维护。</p>\n<h1 id=\"并发编程\"><a href=\"#并发编程\" class=\"headerlink\" title=\"并发编程\"></a>并发编程</h1><p>对象是过程的抽象，线程是调度的抽象。<br>第一要诀还是遵守单一权责原则，了解并发问题的可能原因，学习类库，了解基本算法，学习如何找到必须锁定的区域并锁定之。</p>\n<h1 id=\"逐步改进\"><a href=\"#逐步改进\" class=\"headerlink\" title=\"逐步改进\"></a>逐步改进</h1><p>对一个命令行参数解析程序的案例研究<br>要编写整洁的代码，必须先写肮脏代码，然后再清理它。</p>\n<h1 id=\"Junit内幕\"><a href=\"#Junit内幕\" class=\"headerlink\" title=\"Junit内幕\"></a>Junit内幕</h1><h1 id=\"重构SerialDate\"><a href=\"#重构SerialDate\" class=\"headerlink\" title=\"重构SerialDate\"></a>重构SerialDate</h1><h1 id=\"味道与启发\"><a href=\"#味道与启发\" class=\"headerlink\" title=\"味道与启发\"></a>味道与启发</h1>","site":{"data":{}},"excerpt":"<p>这是一本关于如何写好代码，如何当好一名优秀的程序员的书籍。在本书中，作者引用IT牛人的话，阐述了什么是简洁的代码，然后提出了自己的看法。正如作者一直强调的，光看书是远远不够的，要勤于练习，不断改正，才能有所收获。下面就让我们来一探究竟。</p>\n<h1 id=\"整洁的代码\"><a href=\"#整洁的代码\" class=\"headerlink\" title=\"整洁的代码\"></a>整洁的代码</h1><p>在这章里面，作者探讨了整洁的代码的重要性，以及何为简洁的代码。</p>\n<h1 id=\"有意义的命名\"><a href=\"#有意义的命名\" class=\"headerlink\" title=\"有意义的命名\"></a>有意义的命名</h1><blockquote>\n<p>名副其实，而且一旦发现有更好的名字，立即换掉旧的。<br>避免误导<br>有意义的区分,Variable一词永远不应当出现在变量名中，table一词也不应当出现在表名中。<br>使用读得出来的名称<br>使用可搜索的名称<br>避免使用编码<br>类名：类名和对象名应该是名词或者名词短语，而不应该是动词。<br>方法名：方法名应当是动词或者动词短语。<br>每个概念对应一个词，不要使用双关语。<br>不要添加没用的语境：不要添加重复相同的前缀。只要短名称足够清除，就要比长名称好。对于Address类的实体来说，accountAddress和customerAddress都是不错的对象名称，但是用在类名上就不好了。Address是个好类名，如果需要与MAC地址，端口地址，WEB地址做区别，我会考虑使用PostalAddress、MAC和URI。这样的名称更为精确，而精确正是命名的要点。</p>\n</blockquote>","more":"<h1 id=\"函数\"><a href=\"#函数\" class=\"headerlink\" title=\"函数\"></a>函数</h1><p>通过函数名，可以读出来它是干什么的<br>短小，只做一件事情，每个函数一个抽象层次：如果函数只是做了该函数名下同一抽象层上的步骤，则函数还是只是做了一件事。编写函数，毕竟是为了把大一些的概念（换言之，函数的名称）拆分成另一抽象层级的一系列处理步骤。<br>避免重复。<br>如何写出好的函数：刚开始写函数时，有太多的缩进和嵌套循环，有过长的参数列表，名称是随意取的，也会有重复的代码。不过会配上一套测试单元，覆盖每行丑陋的代码。然后再打磨这些代码，分解函数，修改名称，消除重复，缩短和重新安置方法。有时，还拆散类，保持测试通过。</p>\n<h1 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h1><p>少用注释，有些日志注释交给版本管理工具</p>\n<h1 id=\"代码格式\"><a href=\"#代码格式\" class=\"headerlink\" title=\"代码格式\"></a>代码格式</h1><p>变量声明，应尽可能的靠近其使用位置。<br>实体变量应该在类的顶部声明。<br>相关函数，应该放在一起。<br>探索了各种缩进和空格的使用。最重要的是良好的书写代码的习惯和风格，并且保持一致。记住，代码被阅读的时间远远超过写的时间。所以，写好每一段代码。就像讲好每一个故事一样。</p>\n<h1 id=\"对象和数据结构\"><a href=\"#对象和数据结构\" class=\"headerlink\" title=\"对象和数据结构\"></a>对象和数据结构</h1><p>对象把数据隐藏于抽象之后，暴露操作数据的函数。数据结构暴露其数据，没有提供有意义的函数。过程式代码（使用数据结构的代码）便于在不改动既有数据结构的前提下添加新的函数，而面向对象代码便于在不改动既有函数的前提下添加新类。反过来讲也说得通，过程式代码难以添加新数据结构，因为必须修改所有函数，面向对象的代码难以修改函数，因为必须修改所有类。</p>\n<h1 id=\"错误处理\"><a href=\"#错误处理\" class=\"headerlink\" title=\"错误处理\"></a>错误处理</h1><p>将错误处理隔离看待，独立于主要的程序逻辑，就能写出强固而简洁的代码。</p>\n<h1 id=\"边界\"><a href=\"#边界\" class=\"headerlink\" title=\"边界\"></a>边界</h1><h1 id=\"单元测试\"><a href=\"#单元测试\" class=\"headerlink\" title=\"单元测试\"></a>单元测试</h1><h1 id=\"类\"><a href=\"#类\" class=\"headerlink\" title=\"类\"></a>类</h1><p>类应当短小：应该能够用大概25个单词描述一个类，而且不能用“if”,”and”,”or”,”but”等词汇。<br>单一职权原则：只有一个修改的理由<br>内聚：类应该只有少量的实体变量。类中的每个方法都应该操作一个或者多个这种变量。</p>\n<h1 id=\"系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\"><a href=\"#系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\" class=\"headerlink\" title=\"系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。\"></a>系统：将构造与使用分开的方法之一就是将全部构造过程搬迁至Main模块中，设计系统的其余部分是，假设所有的对象都已正确构造和设置。</h1><p>工厂<br>控制反转<br>AOP   </p>\n<h1 id=\"迭进\"><a href=\"#迭进\" class=\"headerlink\" title=\"迭进\"></a>迭进</h1><p>软件项目的主要成本在于长期维护。</p>\n<h1 id=\"并发编程\"><a href=\"#并发编程\" class=\"headerlink\" title=\"并发编程\"></a>并发编程</h1><p>对象是过程的抽象，线程是调度的抽象。<br>第一要诀还是遵守单一权责原则，了解并发问题的可能原因，学习类库，了解基本算法，学习如何找到必须锁定的区域并锁定之。</p>\n<h1 id=\"逐步改进\"><a href=\"#逐步改进\" class=\"headerlink\" title=\"逐步改进\"></a>逐步改进</h1><p>对一个命令行参数解析程序的案例研究<br>要编写整洁的代码，必须先写肮脏代码，然后再清理它。</p>\n<h1 id=\"Junit内幕\"><a href=\"#Junit内幕\" class=\"headerlink\" title=\"Junit内幕\"></a>Junit内幕</h1><h1 id=\"重构SerialDate\"><a href=\"#重构SerialDate\" class=\"headerlink\" title=\"重构SerialDate\"></a>重构SerialDate</h1><h1 id=\"味道与启发\"><a href=\"#味道与启发\" class=\"headerlink\" title=\"味道与启发\"></a>味道与启发</h1>"},{"title":"Elasticsearch 监控","date":"2017-08-17T12:30:45.000Z","_content":"ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。\n\n# Elasticsearch集群状态监控\n集群状态\n`curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2>/dev/null|grep \"status\"|awk -F: '{print $2}'|awk -F \\\" '{print $2}'`\n\n<!-- more -->\n\n# Elasticsearch集群节点数目\n`curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2>/dev/null|grep \"number_of_nodes\"|awk -F: '{print $2}'|awk -F\\, '{print $1}'`\n","source":"_posts/elasticsearch-monitor.md","raw":"---\ntitle: Elasticsearch 监控\ndate: 2017-08-17 20:30:45\ntags: \n - Elasticsearch\n - Monitor \ncategory: 技术 \n---\nElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。\n\n# Elasticsearch集群状态监控\n集群状态\n`curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2>/dev/null|grep \"status\"|awk -F: '{print $2}'|awk -F \\\" '{print $2}'`\n\n<!-- more -->\n\n# Elasticsearch集群节点数目\n`curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2>/dev/null|grep \"number_of_nodes\"|awk -F: '{print $2}'|awk -F\\, '{print $1}'`\n","slug":"elasticsearch-monitor","published":1,"updated":"2018-04-27T04:11:03.334Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczod0009e4rwm9mn90tf","content":"<p>ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。</p>\n<h1 id=\"Elasticsearch集群状态监控\"><a href=\"#Elasticsearch集群状态监控\" class=\"headerlink\" title=\"Elasticsearch集群状态监控\"></a>Elasticsearch集群状态监控</h1><p>集群状态<br><code>curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2&gt;/dev/null|grep &quot;status&quot;|awk -F: &#39;{print $2}&#39;|awk -F \\&quot; &#39;{print $2}&#39;</code></p>\n<a id=\"more\"></a>\n<h1 id=\"Elasticsearch集群节点数目\"><a href=\"#Elasticsearch集群节点数目\" class=\"headerlink\" title=\"Elasticsearch集群节点数目\"></a>Elasticsearch集群节点数目</h1><p><code>curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2&gt;/dev/null|grep &quot;number_of_nodes&quot;|awk -F: &#39;{print $2}&#39;|awk -F\\, &#39;{print $1}&#39;</code></p>\n","site":{"data":{}},"excerpt":"<p>ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。</p>\n<h1 id=\"Elasticsearch集群状态监控\"><a href=\"#Elasticsearch集群状态监控\" class=\"headerlink\" title=\"Elasticsearch集群状态监控\"></a>Elasticsearch集群状态监控</h1><p>集群状态<br><code>curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2&gt;/dev/null|grep &quot;status&quot;|awk -F: &#39;{print $2}&#39;|awk -F \\&quot; &#39;{print $2}&#39;</code></p>","more":"<h1 id=\"Elasticsearch集群节点数目\"><a href=\"#Elasticsearch集群节点数目\" class=\"headerlink\" title=\"Elasticsearch集群节点数目\"></a>Elasticsearch集群节点数目</h1><p><code>curl -XGET http://192.168.17.201:9200/_cluster/health?pretty 2&gt;/dev/null|grep &quot;number_of_nodes&quot;|awk -F: &#39;{print $2}&#39;|awk -F\\, &#39;{print $1}&#39;</code></p>"},{"title":"Git/Github","date":"2015-05-20T12:07:50.000Z","_content":"\n# Git \n* win7+   \n在wind7下搭建git环境。需下载windows 版本的git工具。见附件。选择完整安装。安装目录 D:\\Program Files (x86)\\Git\\\n并将该路径添加至PATH环境。之后在cmd 环境下就可以使用了。后续如何使用git 就参考git 使用手册了，跟linux环境下的使用方法类似。\n在windows 下生成id_rsa ，免密码连接github。使用 进入D:\\Program Files (x86)\\Git\\git-bash.exe 命令，进入控制台窗口后，输入\n`ssh-keygen -t rsa -b 4096 -C \"zhoujinl@126.com\"`\n然后一直按回车默认，直至完成。\n最后可以在C:\\Users\\zhoujl\\.ssh 目录下生成ssh 密钥和公钥。 \n然后到.ssh目录中，将生成的id_rsa.pub里面的内容，复制到github网站中的 SSH KEYs 设置中。\ngit 全局设置\n>git config --global user.name zhoujinl\ngit config --global user.email zhoujinl@126.com  \n\n在公司内部，有时需要通过设置代理才能连接上外网。\n设置代理\n`git config --global http.proxy http://user:pwd@server.com:port`\n取消代理\n`git config --global (or --system or --local)  --unset  http.proxy `\n* Unix  \n这里主要介绍linux版本。其余的类linux应该类似。以CentOs环境为例，通过yum命令即可快速安装。\n`yum install git`\n\n<!-- more -->\n\n# GitHub\nGitHub是一个以git作为版本控制器的代码托管社区。我们可以在上面创建项目，然后通过git来进行开发维护和协作。具体的使用方法，可参考网站：http://www.worldhello.net/gotgithub/index.html 有详细介绍。\nPS:在设置完user.name和user.email之后，通过命令生成id_ras.pub，\n`ssh-keygen -t rsa -b 4096 -C \"zhoujinl@126.com\"`\n并且上传到github 官网中。然后通过ssh 方式，从github上面clone项目到本地。由于已经将id_ras.pub上传到到github中，因此可以免密码登陆下载。\n验证是否创建成功，如出现以下结果则说明ssh免密码设置成功。\n>$  ssh -T git@github.com\nHi zhoujinl! You've successfully authenticated, but GitHub does not provide shell access.\n\n然后即可从github上面clone项目下来\n`git clone git@github.com:zhoujinl/zhoujinl.github.io.git`\n注：Are you sure you want to continue connecting (yes/no)?  会要求你是否确认连接，输入yes\n\n另外也可以使用https的方式。从github上克隆项目下来，并且push的时候，要求每次都输入用户名密码\n`git clone https://github.com/zhoujinl/zhoujinl.github.io.git`\n\n\n# Git使用技巧：\n>git pull <远程主机名> <远程分支名>:<本地分支名>\n比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。\ngit pull origin next:master\ngit push <远程主机名> <本地分支名>:<远程分支名>\n本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建\ngit push origin master\n注意，分支推送顺序的写法是<来源地>:<目的地>，所以git pull是<远程分支>:<本地分支>，而git push是<本地分支>:<远程分支>。\n\n* Git撤销操作：\n    HEAD 最近一个提交\n    HEAD^ 上一次\n1. 处于add之后，未commit之前  \ngit reset HAED <file>  \n2. commit之后，还未push之前  \n>a.先看日志 git log ,找到要回退之前的版本的commit-id\nλ git log\ncommit 992de5dde4f29aa35eb642b8fd55089838572c2d   ###此次错误提交的版本\nAuthor: zhoujl <zhoujl@ffcs.cn>\nDate:   Wed Aug 9 16:40:59 2017 +0800\nLocal change\ncommit 931c4a4e7678b760faa6849e16c849d7c679ac9c       ##上一个版本，应该使用该id\nAuthor: arganzheng <arganzheng@gmail.com>\nDate:   Thu Jun 18 20:21:51 2015 +0800\nsmall modify\nb.执行撤销操作\n`git reset --hard 931c4a4e7678b760faa6849e16c849d7c679ac9c `    \n**注意：**工 作区和暂存区的内容都会被重置到指定提交的时候，如果不加--hard则只移动HEAD的指针，不影响工作区和暂存区的内容。\n3. push之后，如何回退：--待确认\n\t在步骤2的基础上，执行   git push origin HEAD --force\n","source":"_posts/git-github.md","raw":"---\ntitle: Git/Github\ndate: 2015-05-20 20:07:50\ntags: \n - Git\n - GitHub \ncategory: 技术 \n---\n\n# Git \n* win7+   \n在wind7下搭建git环境。需下载windows 版本的git工具。见附件。选择完整安装。安装目录 D:\\Program Files (x86)\\Git\\\n并将该路径添加至PATH环境。之后在cmd 环境下就可以使用了。后续如何使用git 就参考git 使用手册了，跟linux环境下的使用方法类似。\n在windows 下生成id_rsa ，免密码连接github。使用 进入D:\\Program Files (x86)\\Git\\git-bash.exe 命令，进入控制台窗口后，输入\n`ssh-keygen -t rsa -b 4096 -C \"zhoujinl@126.com\"`\n然后一直按回车默认，直至完成。\n最后可以在C:\\Users\\zhoujl\\.ssh 目录下生成ssh 密钥和公钥。 \n然后到.ssh目录中，将生成的id_rsa.pub里面的内容，复制到github网站中的 SSH KEYs 设置中。\ngit 全局设置\n>git config --global user.name zhoujinl\ngit config --global user.email zhoujinl@126.com  \n\n在公司内部，有时需要通过设置代理才能连接上外网。\n设置代理\n`git config --global http.proxy http://user:pwd@server.com:port`\n取消代理\n`git config --global (or --system or --local)  --unset  http.proxy `\n* Unix  \n这里主要介绍linux版本。其余的类linux应该类似。以CentOs环境为例，通过yum命令即可快速安装。\n`yum install git`\n\n<!-- more -->\n\n# GitHub\nGitHub是一个以git作为版本控制器的代码托管社区。我们可以在上面创建项目，然后通过git来进行开发维护和协作。具体的使用方法，可参考网站：http://www.worldhello.net/gotgithub/index.html 有详细介绍。\nPS:在设置完user.name和user.email之后，通过命令生成id_ras.pub，\n`ssh-keygen -t rsa -b 4096 -C \"zhoujinl@126.com\"`\n并且上传到github 官网中。然后通过ssh 方式，从github上面clone项目到本地。由于已经将id_ras.pub上传到到github中，因此可以免密码登陆下载。\n验证是否创建成功，如出现以下结果则说明ssh免密码设置成功。\n>$  ssh -T git@github.com\nHi zhoujinl! You've successfully authenticated, but GitHub does not provide shell access.\n\n然后即可从github上面clone项目下来\n`git clone git@github.com:zhoujinl/zhoujinl.github.io.git`\n注：Are you sure you want to continue connecting (yes/no)?  会要求你是否确认连接，输入yes\n\n另外也可以使用https的方式。从github上克隆项目下来，并且push的时候，要求每次都输入用户名密码\n`git clone https://github.com/zhoujinl/zhoujinl.github.io.git`\n\n\n# Git使用技巧：\n>git pull <远程主机名> <远程分支名>:<本地分支名>\n比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。\ngit pull origin next:master\ngit push <远程主机名> <本地分支名>:<远程分支名>\n本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建\ngit push origin master\n注意，分支推送顺序的写法是<来源地>:<目的地>，所以git pull是<远程分支>:<本地分支>，而git push是<本地分支>:<远程分支>。\n\n* Git撤销操作：\n    HEAD 最近一个提交\n    HEAD^ 上一次\n1. 处于add之后，未commit之前  \ngit reset HAED <file>  \n2. commit之后，还未push之前  \n>a.先看日志 git log ,找到要回退之前的版本的commit-id\nλ git log\ncommit 992de5dde4f29aa35eb642b8fd55089838572c2d   ###此次错误提交的版本\nAuthor: zhoujl <zhoujl@ffcs.cn>\nDate:   Wed Aug 9 16:40:59 2017 +0800\nLocal change\ncommit 931c4a4e7678b760faa6849e16c849d7c679ac9c       ##上一个版本，应该使用该id\nAuthor: arganzheng <arganzheng@gmail.com>\nDate:   Thu Jun 18 20:21:51 2015 +0800\nsmall modify\nb.执行撤销操作\n`git reset --hard 931c4a4e7678b760faa6849e16c849d7c679ac9c `    \n**注意：**工 作区和暂存区的内容都会被重置到指定提交的时候，如果不加--hard则只移动HEAD的指针，不影响工作区和暂存区的内容。\n3. push之后，如何回退：--待确认\n\t在步骤2的基础上，执行   git push origin HEAD --force\n","slug":"git-github","published":1,"updated":"2018-04-27T04:11:03.341Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczof000be4rww9peqwrt","content":"<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1><ul>\n<li>win7+<br>在wind7下搭建git环境。需下载windows 版本的git工具。见附件。选择完整安装。安装目录 D:\\Program Files (x86)\\Git\\<br>并将该路径添加至PATH环境。之后在cmd 环境下就可以使用了。后续如何使用git 就参考git 使用手册了，跟linux环境下的使用方法类似。<br>在windows 下生成id_rsa ，免密码连接github。使用 进入D:\\Program Files (x86)\\Git\\git-bash.exe 命令，进入控制台窗口后，输入<br><code>ssh-keygen -t rsa -b 4096 -C &quot;zhoujinl@126.com&quot;</code><br>然后一直按回车默认，直至完成。<br>最后可以在C:\\Users\\zhoujl.ssh 目录下生成ssh 密钥和公钥。<br>然后到.ssh目录中，将生成的id_rsa.pub里面的内容，复制到github网站中的 SSH KEYs 设置中。<br>git 全局设置<blockquote>\n<p>git config –global user.name zhoujinl<br>git config –global user.email zhoujinl@126.com  </p>\n</blockquote>\n</li>\n</ul>\n<p>在公司内部，有时需要通过设置代理才能连接上外网。<br>设置代理<br><code>git config --global http.proxy http://user:pwd@server.com:port</code><br>取消代理<br><code>git config --global (or --system or --local)  --unset  http.proxy</code></p>\n<ul>\n<li>Unix<br>这里主要介绍linux版本。其余的类linux应该类似。以CentOs环境为例，通过yum命令即可快速安装。<br><code>yum install git</code></li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"GitHub\"><a href=\"#GitHub\" class=\"headerlink\" title=\"GitHub\"></a>GitHub</h1><p>GitHub是一个以git作为版本控制器的代码托管社区。我们可以在上面创建项目，然后通过git来进行开发维护和协作。具体的使用方法，可参考网站：<a href=\"http://www.worldhello.net/gotgithub/index.html\" target=\"_blank\" rel=\"external\">http://www.worldhello.net/gotgithub/index.html</a> 有详细介绍。<br>PS:在设置完user.name和user.email之后，通过命令生成id_ras.pub，<br><code>ssh-keygen -t rsa -b 4096 -C &quot;zhoujinl@126.com&quot;</code><br>并且上传到github 官网中。然后通过ssh 方式，从github上面clone项目到本地。由于已经将id_ras.pub上传到到github中，因此可以免密码登陆下载。<br>验证是否创建成功，如出现以下结果则说明ssh免密码设置成功。</p>\n<blockquote>\n<p>$  ssh -T git@github.com<br>Hi zhoujinl! You’ve successfully authenticated, but GitHub does not provide shell access.</p>\n</blockquote>\n<p>然后即可从github上面clone项目下来<br><code>git clone git@github.com:zhoujinl/zhoujinl.github.io.git</code><br>注：Are you sure you want to continue connecting (yes/no)?  会要求你是否确认连接，输入yes</p>\n<p>另外也可以使用https的方式。从github上克隆项目下来，并且push的时候，要求每次都输入用户名密码<br><code>git clone https://github.com/zhoujinl/zhoujinl.github.io.git</code></p>\n<h1 id=\"Git使用技巧：\"><a href=\"#Git使用技巧：\" class=\"headerlink\" title=\"Git使用技巧：\"></a>Git使用技巧：</h1><blockquote>\n<p>git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;<br>比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。<br>git pull origin next:master<br>git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;<br>本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建<br>git push origin master<br>注意，分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;。</p>\n</blockquote>\n<ul>\n<li>Git撤销操作：<br>  HEAD 最近一个提交<br>  HEAD^ 上一次</li>\n</ul>\n<ol>\n<li>处于add之后，未commit之前<br>git reset HAED <file>  </file></li>\n<li>commit之后，还未push之前  <blockquote>\n<p>a.先看日志 git log ,找到要回退之前的版本的commit-id<br>λ git log<br>commit 992de5dde4f29aa35eb642b8fd55089838572c2d   ###此次错误提交的版本<br>Author: zhoujl <a href=\"&#109;&#x61;&#x69;&#x6c;&#x74;&#111;&#58;&#122;&#x68;&#x6f;&#x75;&#x6a;&#x6c;&#64;&#102;&#102;&#x63;&#115;&#x2e;&#x63;&#x6e;\">&#122;&#x68;&#x6f;&#x75;&#x6a;&#x6c;&#64;&#102;&#102;&#x63;&#115;&#x2e;&#x63;&#x6e;</a><br>Date:   Wed Aug 9 16:40:59 2017 +0800<br>Local change<br>commit 931c4a4e7678b760faa6849e16c849d7c679ac9c       ##上一个版本，应该使用该id<br>Author: arganzheng <a href=\"&#x6d;&#x61;&#105;&#108;&#x74;&#111;&#x3a;&#97;&#x72;&#x67;&#97;&#x6e;&#122;&#x68;&#x65;&#110;&#x67;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#x6d;\">&#97;&#x72;&#x67;&#97;&#x6e;&#122;&#x68;&#x65;&#110;&#x67;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#x6d;</a><br>Date:   Thu Jun 18 20:21:51 2015 +0800<br>small modify<br>b.执行撤销操作<br><code>git reset --hard 931c4a4e7678b760faa6849e16c849d7c679ac9c</code><br><strong>注意：</strong>工 作区和暂存区的内容都会被重置到指定提交的时候，如果不加–hard则只移动HEAD的指针，不影响工作区和暂存区的内容。</p>\n</blockquote>\n</li>\n<li>push之后，如何回退：–待确认<br> 在步骤2的基础上，执行   git push origin HEAD –force</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h1 id=\"Git\"><a href=\"#Git\" class=\"headerlink\" title=\"Git\"></a>Git</h1><ul>\n<li>win7+<br>在wind7下搭建git环境。需下载windows 版本的git工具。见附件。选择完整安装。安装目录 D:\\Program Files (x86)\\Git\\<br>并将该路径添加至PATH环境。之后在cmd 环境下就可以使用了。后续如何使用git 就参考git 使用手册了，跟linux环境下的使用方法类似。<br>在windows 下生成id_rsa ，免密码连接github。使用 进入D:\\Program Files (x86)\\Git\\git-bash.exe 命令，进入控制台窗口后，输入<br><code>ssh-keygen -t rsa -b 4096 -C &quot;zhoujinl@126.com&quot;</code><br>然后一直按回车默认，直至完成。<br>最后可以在C:\\Users\\zhoujl.ssh 目录下生成ssh 密钥和公钥。<br>然后到.ssh目录中，将生成的id_rsa.pub里面的内容，复制到github网站中的 SSH KEYs 设置中。<br>git 全局设置<blockquote>\n<p>git config –global user.name zhoujinl<br>git config –global user.email zhoujinl@126.com  </p>\n</blockquote>\n</li>\n</ul>\n<p>在公司内部，有时需要通过设置代理才能连接上外网。<br>设置代理<br><code>git config --global http.proxy http://user:pwd@server.com:port</code><br>取消代理<br><code>git config --global (or --system or --local)  --unset  http.proxy</code></p>\n<ul>\n<li>Unix<br>这里主要介绍linux版本。其余的类linux应该类似。以CentOs环境为例，通过yum命令即可快速安装。<br><code>yum install git</code></li>\n</ul>","more":"<h1 id=\"GitHub\"><a href=\"#GitHub\" class=\"headerlink\" title=\"GitHub\"></a>GitHub</h1><p>GitHub是一个以git作为版本控制器的代码托管社区。我们可以在上面创建项目，然后通过git来进行开发维护和协作。具体的使用方法，可参考网站：<a href=\"http://www.worldhello.net/gotgithub/index.html\" target=\"_blank\" rel=\"external\">http://www.worldhello.net/gotgithub/index.html</a> 有详细介绍。<br>PS:在设置完user.name和user.email之后，通过命令生成id_ras.pub，<br><code>ssh-keygen -t rsa -b 4096 -C &quot;zhoujinl@126.com&quot;</code><br>并且上传到github 官网中。然后通过ssh 方式，从github上面clone项目到本地。由于已经将id_ras.pub上传到到github中，因此可以免密码登陆下载。<br>验证是否创建成功，如出现以下结果则说明ssh免密码设置成功。</p>\n<blockquote>\n<p>$  ssh -T git@github.com<br>Hi zhoujinl! You’ve successfully authenticated, but GitHub does not provide shell access.</p>\n</blockquote>\n<p>然后即可从github上面clone项目下来<br><code>git clone git@github.com:zhoujinl/zhoujinl.github.io.git</code><br>注：Are you sure you want to continue connecting (yes/no)?  会要求你是否确认连接，输入yes</p>\n<p>另外也可以使用https的方式。从github上克隆项目下来，并且push的时候，要求每次都输入用户名密码<br><code>git clone https://github.com/zhoujinl/zhoujinl.github.io.git</code></p>\n<h1 id=\"Git使用技巧：\"><a href=\"#Git使用技巧：\" class=\"headerlink\" title=\"Git使用技巧：\"></a>Git使用技巧：</h1><blockquote>\n<p>git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;<br>比如，取回origin主机的next分支，与本地的master分支合并，需要写成下面这样。<br>git pull origin next:master<br>git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;<br>本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建<br>git push origin master<br>注意，分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;。</p>\n</blockquote>\n<ul>\n<li>Git撤销操作：<br>  HEAD 最近一个提交<br>  HEAD^ 上一次</li>\n</ul>\n<ol>\n<li>处于add之后，未commit之前<br>git reset HAED <file>  </file></li>\n<li>commit之后，还未push之前  <blockquote>\n<p>a.先看日志 git log ,找到要回退之前的版本的commit-id<br>λ git log<br>commit 992de5dde4f29aa35eb642b8fd55089838572c2d   ###此次错误提交的版本<br>Author: zhoujl <a href=\"&#109;&#x61;&#x69;&#x6c;&#x74;&#111;&#58;&#122;&#x68;&#x6f;&#x75;&#x6a;&#x6c;&#64;&#102;&#102;&#x63;&#115;&#x2e;&#x63;&#x6e;\">&#122;&#x68;&#x6f;&#x75;&#x6a;&#x6c;&#64;&#102;&#102;&#x63;&#115;&#x2e;&#x63;&#x6e;</a><br>Date:   Wed Aug 9 16:40:59 2017 +0800<br>Local change<br>commit 931c4a4e7678b760faa6849e16c849d7c679ac9c       ##上一个版本，应该使用该id<br>Author: arganzheng <a href=\"&#x6d;&#x61;&#105;&#108;&#x74;&#111;&#x3a;&#97;&#x72;&#x67;&#97;&#x6e;&#122;&#x68;&#x65;&#110;&#x67;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#x6d;\">&#97;&#x72;&#x67;&#97;&#x6e;&#122;&#x68;&#x65;&#110;&#x67;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#x6d;</a><br>Date:   Thu Jun 18 20:21:51 2015 +0800<br>small modify<br>b.执行撤销操作<br><code>git reset --hard 931c4a4e7678b760faa6849e16c849d7c679ac9c</code><br><strong>注意：</strong>工 作区和暂存区的内容都会被重置到指定提交的时候，如果不加–hard则只移动HEAD的指针，不影响工作区和暂存区的内容。</p>\n</blockquote>\n</li>\n<li>push之后，如何回退：–待确认<br> 在步骤2的基础上，执行   git push origin HEAD –force</li>\n</ol>"},{"title":"Hello World","date":"2013-06-15T14:10:30.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2013-06-15 22:10:30\ntag: Hexo\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"updated":"2018-04-27T04:11:03.345Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczoj000ee4rwob7rym5n","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n"},{"title":"软件随想录-卷1（上）","date":"2015-06-20T03:18:18.000Z","_content":"joel Spolsky著  杨帆译   \n[Gitbook 电子书](https://wizardforcel.gitbooks.io/joel-on-software/content/index.html  \"软件随想录\")\n\n# 软件开发的五个世界\n了解你的世界 \n>1.盒装(Shrinkwrap)软件（产品软件）\n2.内部用的软件\n3.嵌入式软件\n4.游戏软件\n5.用后即丢的软件\n\n# 二元文化差异   \n| 文化类型  | 核心区别 | 区别举例1   | 区别举例1   | 区别举例1   |\n| :-------: | :----: | :---: |  :---: |  :---: |\n| unix文化 | 重视为程序员提供有用的程序 | 重视命令行 | 一项程序结束如果没有产生任何输出信息，就说明程序执行正确 | 文档应该写的简洁而完整，读者可以推导出未写出的结论并且信任自己的推导，一件事很少会讲两遍.|\n| windows文化    | 重视对非程序员提供有用的程序 | 重视图形化界面  | 程序执行后如果没有任何提示你就搞不清楚是因为出错了而没有输出还是没出错只是不输出。| 了解一般使用者一般不读文档，因此一件事情会多次提醒 |\n\n<!-- more -->\n\n# 千万不要做的事情\n读代码比写代码还要难\n>不要重写代码，不要重写代码，不要重写代码  \n因为旧代码里面，包含的某个你看似无用丑陋的代码，可能是前人花很长时间改正过来的BUG。\n请在保证单元测试无误的情况下，重构代码，而不是想着重头开始做一套。\n\n# 如何编写技术文档\n>1.要幽默，最简单的搞笑方法就是在没有必要写得具体的时候写得具体一点\n2.像编写用大脑执行的代码一样编写文档\n3.写的尽可能的简单\n4.重读并修改几遍\n5.尽量不要套用模版\n\n# Unicode和字符集知识 \nUnicode实际上只是一个规范，它规定每个字符独一无二的码点。\n>在Unicode中，一个字母映射为一个理论概念：码点。至于如何在内存或者硬盘中表示码点，\n就是另一件事情了（注:不同编码方式有不同的存储形式）。字母A（U+0645）是一个柏拉图的理想型（platnonic  ideal）。它漂浮在天上，有些抽象。\n而字符集编码呢，表示码点的是所谓的编码。例如常见的UTF-8,UTF-16等,都是Unicode家族的编码方式。  \n举例：字符串hello的Unicode表示为 U+0048 U+0065 U+006C U+006C U+006F,那么它用UTF-8编码的存储形式为 48 65 6C 6C 6F (注意！) 这和它在ASCII、ANSI以及\n其他的所有的OEM字符集中的表示都完全一致，而其他语言（如中文、日文等），则需要几个字节来存储一个码点。\n\n# 乔尔测试\n> 1.你们使用版本控制系统吗？\n2.有一键部署吗？\n3.有每日构建吗？\n4.有Bug数据库吗？\n5.你们是否在写新代码前保证Bug都修复完了？\n6.有最新的开发计划吗？\n7.有需求文档吗？\n8.程序员们有安静的工作环境吗？\n9.你们使用能买到的最好的工具吗？\n10.有测试团队吗？\n11.应聘者在面试时写代码吗？\n12.你们进行目标用户随机可用性测试吗？\n\n\n\n# 轻松掌握软件开发进度\n>1.使用excel\n2.保持简单\n3.每个功能点应该分成几个子任务\n4.只有程序员才能准确的预估时间\n5.细分任务，每个任务以小时为单位。\n6.记录原始和当前的时间估计，训练自己的时间估计准度。\n7.每天更新实际用时。\n8.把休假考虑在内\n9.把调试代码的时间也考虑在内\n10.把集成时间考虑在内\n11.预留缓冲时间\n12.不要压缩程序员的预估时间\n13.缩减功能以减少开发时间\n\n# 干扰射击  \n>微软频繁推出的历代数据库连接技术（ODBC,RDO,DAO,ADO,OLEDB,ADO.NET...），目的火力压制，迫使竞争者们用尽全部精力来跟上未然的节拍，移植现有的功能，从而没有时间研发新功能。因此必须抓紧时间，把开发的主动权掌握在自己的手里，二是必须每天进步。\n\n# 修复bug\n* 尽可能收集bug的所有信息\n* 衡量bug的成本与收益\n* 算出修复所有bug的价值  \n   \n# 错误报告\n* 建立bug数据库(小项目可以用记事本)\n* 每个好的错误报告都要包括以下三个步骤：\n1.重现的步骤\n2.期望看到的  \n3.实际看到的\n好的测试员会把重现的步骤缩减到最短。只有一开始测出问题的人才能关闭这个bug。\n要解决错误可以有很多种办法，解决理由有：不予修正，暂缓，无法重现，重复的问题，设计限制。\n","source":"_posts/joel-on-software-1-1.md","raw":"---\ntitle: 软件随想录-卷1（上） \ndate: 2015-06-20 11:18:18\ntags: 随笔\n---\njoel Spolsky著  杨帆译   \n[Gitbook 电子书](https://wizardforcel.gitbooks.io/joel-on-software/content/index.html  \"软件随想录\")\n\n# 软件开发的五个世界\n了解你的世界 \n>1.盒装(Shrinkwrap)软件（产品软件）\n2.内部用的软件\n3.嵌入式软件\n4.游戏软件\n5.用后即丢的软件\n\n# 二元文化差异   \n| 文化类型  | 核心区别 | 区别举例1   | 区别举例1   | 区别举例1   |\n| :-------: | :----: | :---: |  :---: |  :---: |\n| unix文化 | 重视为程序员提供有用的程序 | 重视命令行 | 一项程序结束如果没有产生任何输出信息，就说明程序执行正确 | 文档应该写的简洁而完整，读者可以推导出未写出的结论并且信任自己的推导，一件事很少会讲两遍.|\n| windows文化    | 重视对非程序员提供有用的程序 | 重视图形化界面  | 程序执行后如果没有任何提示你就搞不清楚是因为出错了而没有输出还是没出错只是不输出。| 了解一般使用者一般不读文档，因此一件事情会多次提醒 |\n\n<!-- more -->\n\n# 千万不要做的事情\n读代码比写代码还要难\n>不要重写代码，不要重写代码，不要重写代码  \n因为旧代码里面，包含的某个你看似无用丑陋的代码，可能是前人花很长时间改正过来的BUG。\n请在保证单元测试无误的情况下，重构代码，而不是想着重头开始做一套。\n\n# 如何编写技术文档\n>1.要幽默，最简单的搞笑方法就是在没有必要写得具体的时候写得具体一点\n2.像编写用大脑执行的代码一样编写文档\n3.写的尽可能的简单\n4.重读并修改几遍\n5.尽量不要套用模版\n\n# Unicode和字符集知识 \nUnicode实际上只是一个规范，它规定每个字符独一无二的码点。\n>在Unicode中，一个字母映射为一个理论概念：码点。至于如何在内存或者硬盘中表示码点，\n就是另一件事情了（注:不同编码方式有不同的存储形式）。字母A（U+0645）是一个柏拉图的理想型（platnonic  ideal）。它漂浮在天上，有些抽象。\n而字符集编码呢，表示码点的是所谓的编码。例如常见的UTF-8,UTF-16等,都是Unicode家族的编码方式。  \n举例：字符串hello的Unicode表示为 U+0048 U+0065 U+006C U+006C U+006F,那么它用UTF-8编码的存储形式为 48 65 6C 6C 6F (注意！) 这和它在ASCII、ANSI以及\n其他的所有的OEM字符集中的表示都完全一致，而其他语言（如中文、日文等），则需要几个字节来存储一个码点。\n\n# 乔尔测试\n> 1.你们使用版本控制系统吗？\n2.有一键部署吗？\n3.有每日构建吗？\n4.有Bug数据库吗？\n5.你们是否在写新代码前保证Bug都修复完了？\n6.有最新的开发计划吗？\n7.有需求文档吗？\n8.程序员们有安静的工作环境吗？\n9.你们使用能买到的最好的工具吗？\n10.有测试团队吗？\n11.应聘者在面试时写代码吗？\n12.你们进行目标用户随机可用性测试吗？\n\n\n\n# 轻松掌握软件开发进度\n>1.使用excel\n2.保持简单\n3.每个功能点应该分成几个子任务\n4.只有程序员才能准确的预估时间\n5.细分任务，每个任务以小时为单位。\n6.记录原始和当前的时间估计，训练自己的时间估计准度。\n7.每天更新实际用时。\n8.把休假考虑在内\n9.把调试代码的时间也考虑在内\n10.把集成时间考虑在内\n11.预留缓冲时间\n12.不要压缩程序员的预估时间\n13.缩减功能以减少开发时间\n\n# 干扰射击  \n>微软频繁推出的历代数据库连接技术（ODBC,RDO,DAO,ADO,OLEDB,ADO.NET...），目的火力压制，迫使竞争者们用尽全部精力来跟上未然的节拍，移植现有的功能，从而没有时间研发新功能。因此必须抓紧时间，把开发的主动权掌握在自己的手里，二是必须每天进步。\n\n# 修复bug\n* 尽可能收集bug的所有信息\n* 衡量bug的成本与收益\n* 算出修复所有bug的价值  \n   \n# 错误报告\n* 建立bug数据库(小项目可以用记事本)\n* 每个好的错误报告都要包括以下三个步骤：\n1.重现的步骤\n2.期望看到的  \n3.实际看到的\n好的测试员会把重现的步骤缩减到最短。只有一开始测出问题的人才能关闭这个bug。\n要解决错误可以有很多种办法，解决理由有：不予修正，暂缓，无法重现，重复的问题，设计限制。\n","slug":"joel-on-software-1-1","published":1,"updated":"2018-04-27T04:11:03.348Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczon000ge4rw29ef8d1k","content":"<p>joel Spolsky著  杨帆译<br><a href=\"https://wizardforcel.gitbooks.io/joel-on-software/content/index.html\" title=\"软件随想录\" target=\"_blank\" rel=\"external\">Gitbook 电子书</a></p>\n<h1 id=\"软件开发的五个世界\"><a href=\"#软件开发的五个世界\" class=\"headerlink\" title=\"软件开发的五个世界\"></a>软件开发的五个世界</h1><p>了解你的世界 </p>\n<blockquote>\n<p>1.盒装(Shrinkwrap)软件（产品软件）<br>2.内部用的软件<br>3.嵌入式软件<br>4.游戏软件<br>5.用后即丢的软件</p>\n</blockquote>\n<h1 id=\"二元文化差异\"><a href=\"#二元文化差异\" class=\"headerlink\" title=\"二元文化差异\"></a>二元文化差异</h1><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">文化类型</th>\n<th style=\"text-align:center\">核心区别</th>\n<th style=\"text-align:center\">区别举例1</th>\n<th style=\"text-align:center\">区别举例1</th>\n<th style=\"text-align:center\">区别举例1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">unix文化</td>\n<td style=\"text-align:center\">重视为程序员提供有用的程序</td>\n<td style=\"text-align:center\">重视命令行</td>\n<td style=\"text-align:center\">一项程序结束如果没有产生任何输出信息，就说明程序执行正确</td>\n<td style=\"text-align:center\">文档应该写的简洁而完整，读者可以推导出未写出的结论并且信任自己的推导，一件事很少会讲两遍.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">windows文化</td>\n<td style=\"text-align:center\">重视对非程序员提供有用的程序</td>\n<td style=\"text-align:center\">重视图形化界面</td>\n<td style=\"text-align:center\">程序执行后如果没有任何提示你就搞不清楚是因为出错了而没有输出还是没出错只是不输出。</td>\n<td style=\"text-align:center\">了解一般使用者一般不读文档，因此一件事情会多次提醒</td>\n</tr>\n</tbody>\n</table>\n<a id=\"more\"></a>\n<h1 id=\"千万不要做的事情\"><a href=\"#千万不要做的事情\" class=\"headerlink\" title=\"千万不要做的事情\"></a>千万不要做的事情</h1><p>读代码比写代码还要难</p>\n<blockquote>\n<p>不要重写代码，不要重写代码，不要重写代码<br>因为旧代码里面，包含的某个你看似无用丑陋的代码，可能是前人花很长时间改正过来的BUG。<br>请在保证单元测试无误的情况下，重构代码，而不是想着重头开始做一套。</p>\n</blockquote>\n<h1 id=\"如何编写技术文档\"><a href=\"#如何编写技术文档\" class=\"headerlink\" title=\"如何编写技术文档\"></a>如何编写技术文档</h1><blockquote>\n<p>1.要幽默，最简单的搞笑方法就是在没有必要写得具体的时候写得具体一点<br>2.像编写用大脑执行的代码一样编写文档<br>3.写的尽可能的简单<br>4.重读并修改几遍<br>5.尽量不要套用模版</p>\n</blockquote>\n<h1 id=\"Unicode和字符集知识\"><a href=\"#Unicode和字符集知识\" class=\"headerlink\" title=\"Unicode和字符集知识\"></a>Unicode和字符集知识</h1><p>Unicode实际上只是一个规范，它规定每个字符独一无二的码点。</p>\n<blockquote>\n<p>在Unicode中，一个字母映射为一个理论概念：码点。至于如何在内存或者硬盘中表示码点，<br>就是另一件事情了（注:不同编码方式有不同的存储形式）。字母A（U+0645）是一个柏拉图的理想型（platnonic  ideal）。它漂浮在天上，有些抽象。<br>而字符集编码呢，表示码点的是所谓的编码。例如常见的UTF-8,UTF-16等,都是Unicode家族的编码方式。<br>举例：字符串hello的Unicode表示为 U+0048 U+0065 U+006C U+006C U+006F,那么它用UTF-8编码的存储形式为 48 65 6C 6C 6F (注意！) 这和它在ASCII、ANSI以及<br>其他的所有的OEM字符集中的表示都完全一致，而其他语言（如中文、日文等），则需要几个字节来存储一个码点。</p>\n</blockquote>\n<h1 id=\"乔尔测试\"><a href=\"#乔尔测试\" class=\"headerlink\" title=\"乔尔测试\"></a>乔尔测试</h1><blockquote>\n<p>1.你们使用版本控制系统吗？<br>2.有一键部署吗？<br>3.有每日构建吗？<br>4.有Bug数据库吗？<br>5.你们是否在写新代码前保证Bug都修复完了？<br>6.有最新的开发计划吗？<br>7.有需求文档吗？<br>8.程序员们有安静的工作环境吗？<br>9.你们使用能买到的最好的工具吗？<br>10.有测试团队吗？<br>11.应聘者在面试时写代码吗？<br>12.你们进行目标用户随机可用性测试吗？</p>\n</blockquote>\n<h1 id=\"轻松掌握软件开发进度\"><a href=\"#轻松掌握软件开发进度\" class=\"headerlink\" title=\"轻松掌握软件开发进度\"></a>轻松掌握软件开发进度</h1><blockquote>\n<p>1.使用excel<br>2.保持简单<br>3.每个功能点应该分成几个子任务<br>4.只有程序员才能准确的预估时间<br>5.细分任务，每个任务以小时为单位。<br>6.记录原始和当前的时间估计，训练自己的时间估计准度。<br>7.每天更新实际用时。<br>8.把休假考虑在内<br>9.把调试代码的时间也考虑在内<br>10.把集成时间考虑在内<br>11.预留缓冲时间<br>12.不要压缩程序员的预估时间<br>13.缩减功能以减少开发时间</p>\n</blockquote>\n<h1 id=\"干扰射击\"><a href=\"#干扰射击\" class=\"headerlink\" title=\"干扰射击\"></a>干扰射击</h1><blockquote>\n<p>微软频繁推出的历代数据库连接技术（ODBC,RDO,DAO,ADO,OLEDB,ADO.NET…），目的火力压制，迫使竞争者们用尽全部精力来跟上未然的节拍，移植现有的功能，从而没有时间研发新功能。因此必须抓紧时间，把开发的主动权掌握在自己的手里，二是必须每天进步。</p>\n</blockquote>\n<h1 id=\"修复bug\"><a href=\"#修复bug\" class=\"headerlink\" title=\"修复bug\"></a>修复bug</h1><ul>\n<li>尽可能收集bug的所有信息</li>\n<li>衡量bug的成本与收益</li>\n<li>算出修复所有bug的价值  </li>\n</ul>\n<h1 id=\"错误报告\"><a href=\"#错误报告\" class=\"headerlink\" title=\"错误报告\"></a>错误报告</h1><ul>\n<li>建立bug数据库(小项目可以用记事本)</li>\n<li>每个好的错误报告都要包括以下三个步骤：<br>1.重现的步骤<br>2.期望看到的<br>3.实际看到的<br>好的测试员会把重现的步骤缩减到最短。只有一开始测出问题的人才能关闭这个bug。<br>要解决错误可以有很多种办法，解决理由有：不予修正，暂缓，无法重现，重复的问题，设计限制。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>joel Spolsky著  杨帆译<br><a href=\"https://wizardforcel.gitbooks.io/joel-on-software/content/index.html\" title=\"软件随想录\" target=\"_blank\" rel=\"external\">Gitbook 电子书</a></p>\n<h1 id=\"软件开发的五个世界\"><a href=\"#软件开发的五个世界\" class=\"headerlink\" title=\"软件开发的五个世界\"></a>软件开发的五个世界</h1><p>了解你的世界 </p>\n<blockquote>\n<p>1.盒装(Shrinkwrap)软件（产品软件）<br>2.内部用的软件<br>3.嵌入式软件<br>4.游戏软件<br>5.用后即丢的软件</p>\n</blockquote>\n<h1 id=\"二元文化差异\"><a href=\"#二元文化差异\" class=\"headerlink\" title=\"二元文化差异\"></a>二元文化差异</h1><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">文化类型</th>\n<th style=\"text-align:center\">核心区别</th>\n<th style=\"text-align:center\">区别举例1</th>\n<th style=\"text-align:center\">区别举例1</th>\n<th style=\"text-align:center\">区别举例1</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">unix文化</td>\n<td style=\"text-align:center\">重视为程序员提供有用的程序</td>\n<td style=\"text-align:center\">重视命令行</td>\n<td style=\"text-align:center\">一项程序结束如果没有产生任何输出信息，就说明程序执行正确</td>\n<td style=\"text-align:center\">文档应该写的简洁而完整，读者可以推导出未写出的结论并且信任自己的推导，一件事很少会讲两遍.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">windows文化</td>\n<td style=\"text-align:center\">重视对非程序员提供有用的程序</td>\n<td style=\"text-align:center\">重视图形化界面</td>\n<td style=\"text-align:center\">程序执行后如果没有任何提示你就搞不清楚是因为出错了而没有输出还是没出错只是不输出。</td>\n<td style=\"text-align:center\">了解一般使用者一般不读文档，因此一件事情会多次提醒</td>\n</tr>\n</tbody>\n</table>","more":"<h1 id=\"千万不要做的事情\"><a href=\"#千万不要做的事情\" class=\"headerlink\" title=\"千万不要做的事情\"></a>千万不要做的事情</h1><p>读代码比写代码还要难</p>\n<blockquote>\n<p>不要重写代码，不要重写代码，不要重写代码<br>因为旧代码里面，包含的某个你看似无用丑陋的代码，可能是前人花很长时间改正过来的BUG。<br>请在保证单元测试无误的情况下，重构代码，而不是想着重头开始做一套。</p>\n</blockquote>\n<h1 id=\"如何编写技术文档\"><a href=\"#如何编写技术文档\" class=\"headerlink\" title=\"如何编写技术文档\"></a>如何编写技术文档</h1><blockquote>\n<p>1.要幽默，最简单的搞笑方法就是在没有必要写得具体的时候写得具体一点<br>2.像编写用大脑执行的代码一样编写文档<br>3.写的尽可能的简单<br>4.重读并修改几遍<br>5.尽量不要套用模版</p>\n</blockquote>\n<h1 id=\"Unicode和字符集知识\"><a href=\"#Unicode和字符集知识\" class=\"headerlink\" title=\"Unicode和字符集知识\"></a>Unicode和字符集知识</h1><p>Unicode实际上只是一个规范，它规定每个字符独一无二的码点。</p>\n<blockquote>\n<p>在Unicode中，一个字母映射为一个理论概念：码点。至于如何在内存或者硬盘中表示码点，<br>就是另一件事情了（注:不同编码方式有不同的存储形式）。字母A（U+0645）是一个柏拉图的理想型（platnonic  ideal）。它漂浮在天上，有些抽象。<br>而字符集编码呢，表示码点的是所谓的编码。例如常见的UTF-8,UTF-16等,都是Unicode家族的编码方式。<br>举例：字符串hello的Unicode表示为 U+0048 U+0065 U+006C U+006C U+006F,那么它用UTF-8编码的存储形式为 48 65 6C 6C 6F (注意！) 这和它在ASCII、ANSI以及<br>其他的所有的OEM字符集中的表示都完全一致，而其他语言（如中文、日文等），则需要几个字节来存储一个码点。</p>\n</blockquote>\n<h1 id=\"乔尔测试\"><a href=\"#乔尔测试\" class=\"headerlink\" title=\"乔尔测试\"></a>乔尔测试</h1><blockquote>\n<p>1.你们使用版本控制系统吗？<br>2.有一键部署吗？<br>3.有每日构建吗？<br>4.有Bug数据库吗？<br>5.你们是否在写新代码前保证Bug都修复完了？<br>6.有最新的开发计划吗？<br>7.有需求文档吗？<br>8.程序员们有安静的工作环境吗？<br>9.你们使用能买到的最好的工具吗？<br>10.有测试团队吗？<br>11.应聘者在面试时写代码吗？<br>12.你们进行目标用户随机可用性测试吗？</p>\n</blockquote>\n<h1 id=\"轻松掌握软件开发进度\"><a href=\"#轻松掌握软件开发进度\" class=\"headerlink\" title=\"轻松掌握软件开发进度\"></a>轻松掌握软件开发进度</h1><blockquote>\n<p>1.使用excel<br>2.保持简单<br>3.每个功能点应该分成几个子任务<br>4.只有程序员才能准确的预估时间<br>5.细分任务，每个任务以小时为单位。<br>6.记录原始和当前的时间估计，训练自己的时间估计准度。<br>7.每天更新实际用时。<br>8.把休假考虑在内<br>9.把调试代码的时间也考虑在内<br>10.把集成时间考虑在内<br>11.预留缓冲时间<br>12.不要压缩程序员的预估时间<br>13.缩减功能以减少开发时间</p>\n</blockquote>\n<h1 id=\"干扰射击\"><a href=\"#干扰射击\" class=\"headerlink\" title=\"干扰射击\"></a>干扰射击</h1><blockquote>\n<p>微软频繁推出的历代数据库连接技术（ODBC,RDO,DAO,ADO,OLEDB,ADO.NET…），目的火力压制，迫使竞争者们用尽全部精力来跟上未然的节拍，移植现有的功能，从而没有时间研发新功能。因此必须抓紧时间，把开发的主动权掌握在自己的手里，二是必须每天进步。</p>\n</blockquote>\n<h1 id=\"修复bug\"><a href=\"#修复bug\" class=\"headerlink\" title=\"修复bug\"></a>修复bug</h1><ul>\n<li>尽可能收集bug的所有信息</li>\n<li>衡量bug的成本与收益</li>\n<li>算出修复所有bug的价值  </li>\n</ul>\n<h1 id=\"错误报告\"><a href=\"#错误报告\" class=\"headerlink\" title=\"错误报告\"></a>错误报告</h1><ul>\n<li>建立bug数据库(小项目可以用记事本)</li>\n<li>每个好的错误报告都要包括以下三个步骤：<br>1.重现的步骤<br>2.期望看到的<br>3.实际看到的<br>好的测试员会把重现的步骤缩减到最短。只有一开始测出问题的人才能关闭这个bug。<br>要解决错误可以有很多种办法，解决理由有：不予修正，暂缓，无法重现，重复的问题，设计限制。</li>\n</ul>"},{"title":"软件随想录-卷1（下）","date":"2016-06-21T03:18:18.000Z","_content":"joel Spolsky著  杨帆译   \n[Gitbook 电子书](https://wizardforcel.gitbooks.io/joel-on-software/content/index.html  \"软件随想录\")\n\n# 开发人员的管理 \n* 面试游击指南\n面试官有时候会故意刁难你，看你能否坚持自己的正确的观点。好的面试者会坚持自己的观点，然后试图说服面试官。\n* 重金激励害多利少\n原因是绩效考核的不正确，负面评价对士气伤害很大，而正面评价对士气的激励也不如想象的那么好(会让他们觉得自己是为了拿到好成绩才好好工作的，就像巴普洛夫的狗)。\n大多数人都认为自己把事情做得很好(即使不是)。评价机制的不合理：比如某人是团队的粘合剂，总是能够在士气低落的时候激励大家，某人总喜欢研究新技术，别人有问题总要靠他解决，但是他写的代码量很少，这两种人可能得到的评价很低，但是不可否认他们的作用很大。\n绩效考评会使团队产生间隙。\n\n<!-- more -->\n\n# 冰山理论 \n程序员和非技术人员的思考语言不一样。客户不知道他们要什么，别再期望客户知道他们要什么。原型图上漂亮的接口只占10%的工作，而真正的90%的程序设计都是看不到的。\n>推论1：把使用接口的画面展示给非程序人员看时，如果这个接口很不好，对方会以为你整个程序也是很不好的。\n推论2：相反，如果这个接口很漂亮，对方会以为这个程序几乎已经完工。\n推论3：展示时唯一重要的就是外观。一定要让它美得冒泡\n推论4：**当公司规定不会编程的管理人员或客户要对项目\"签字验收\"的时候,提供多个版本的图形设计方案，供他们选择。微调页面的排版方式、视觉样式、字体等，把产品标识\n改大或改小一点，给他们一些决定无关痛痒事情的权力,让他们觉得自己的意见举足轻重。**\n推论5：做产品演示的时候，唯一起作用的就是产品截图，一定要让截图100%完美。\n\n如何绕过冰山：任何在幻灯片展示的产品都只是*一堆像素*而已。如果可以的话，在demo的用户界面中，把那些为完成的部分画成未完成的燕子。比如在工具栏图标\n对应的功能完成之前，把它画成潦草的手绘风格。在构建网络服务的时候，可以先不把为完成的功能展示在网站首页。这样随着开发的进展，人们就能看到首页的\n功能按键从3项逐渐增加到20项。**更重要的是**，要掌控人们对于开发进度的预期。用Excel文件的形式提供一份详细的开发进度规划表。\n\n# 漏洞抽象定律\n>可靠的tcp建立在不可靠的ip协议之上。   \n所有重大的抽象机制在某种程序上都是有漏洞的，所以我们有一天遇到了这些漏洞，不得不去学习它的底层实现。 \n比如二维数组的访问(内存分页)，sql语句查询的快慢(逻辑上等义的sql语句查询起来速度完全不一样)，c++的字符串处理。\n\n# 凡事没有看上去那么简单\n凡事没有看上去那么简单、尽量降低风险 => 先做好设计，再去实现\n\n# 普通程序员如何改善团队工作方式\n* 放手去做\n* 借助病毒营销的方式\n* 营造以防优秀的小天地\n* 干掉害群之马\n* 屏蔽干扰 \n* 提升自身对团队的价值\n\n\n# 企业发展战略\n关于创业的想法,需要时请再重点阅读，分清楚两种不同的公司发展道路。\n>亚马逊和本杰瑞\n先有鸡还是先有蛋\n让我回到过去\n膨件和二八法则\n开源软件经济学\n\n","source":"_posts/joel-on-software-1-2.md","raw":"---\ntitle: 软件随想录-卷1（下） \ndate: 2016-06-21 11:18:18\ntags: 随笔\n---\njoel Spolsky著  杨帆译   \n[Gitbook 电子书](https://wizardforcel.gitbooks.io/joel-on-software/content/index.html  \"软件随想录\")\n\n# 开发人员的管理 \n* 面试游击指南\n面试官有时候会故意刁难你，看你能否坚持自己的正确的观点。好的面试者会坚持自己的观点，然后试图说服面试官。\n* 重金激励害多利少\n原因是绩效考核的不正确，负面评价对士气伤害很大，而正面评价对士气的激励也不如想象的那么好(会让他们觉得自己是为了拿到好成绩才好好工作的，就像巴普洛夫的狗)。\n大多数人都认为自己把事情做得很好(即使不是)。评价机制的不合理：比如某人是团队的粘合剂，总是能够在士气低落的时候激励大家，某人总喜欢研究新技术，别人有问题总要靠他解决，但是他写的代码量很少，这两种人可能得到的评价很低，但是不可否认他们的作用很大。\n绩效考评会使团队产生间隙。\n\n<!-- more -->\n\n# 冰山理论 \n程序员和非技术人员的思考语言不一样。客户不知道他们要什么，别再期望客户知道他们要什么。原型图上漂亮的接口只占10%的工作，而真正的90%的程序设计都是看不到的。\n>推论1：把使用接口的画面展示给非程序人员看时，如果这个接口很不好，对方会以为你整个程序也是很不好的。\n推论2：相反，如果这个接口很漂亮，对方会以为这个程序几乎已经完工。\n推论3：展示时唯一重要的就是外观。一定要让它美得冒泡\n推论4：**当公司规定不会编程的管理人员或客户要对项目\"签字验收\"的时候,提供多个版本的图形设计方案，供他们选择。微调页面的排版方式、视觉样式、字体等，把产品标识\n改大或改小一点，给他们一些决定无关痛痒事情的权力,让他们觉得自己的意见举足轻重。**\n推论5：做产品演示的时候，唯一起作用的就是产品截图，一定要让截图100%完美。\n\n如何绕过冰山：任何在幻灯片展示的产品都只是*一堆像素*而已。如果可以的话，在demo的用户界面中，把那些为完成的部分画成未完成的燕子。比如在工具栏图标\n对应的功能完成之前，把它画成潦草的手绘风格。在构建网络服务的时候，可以先不把为完成的功能展示在网站首页。这样随着开发的进展，人们就能看到首页的\n功能按键从3项逐渐增加到20项。**更重要的是**，要掌控人们对于开发进度的预期。用Excel文件的形式提供一份详细的开发进度规划表。\n\n# 漏洞抽象定律\n>可靠的tcp建立在不可靠的ip协议之上。   \n所有重大的抽象机制在某种程序上都是有漏洞的，所以我们有一天遇到了这些漏洞，不得不去学习它的底层实现。 \n比如二维数组的访问(内存分页)，sql语句查询的快慢(逻辑上等义的sql语句查询起来速度完全不一样)，c++的字符串处理。\n\n# 凡事没有看上去那么简单\n凡事没有看上去那么简单、尽量降低风险 => 先做好设计，再去实现\n\n# 普通程序员如何改善团队工作方式\n* 放手去做\n* 借助病毒营销的方式\n* 营造以防优秀的小天地\n* 干掉害群之马\n* 屏蔽干扰 \n* 提升自身对团队的价值\n\n\n# 企业发展战略\n关于创业的想法,需要时请再重点阅读，分清楚两种不同的公司发展道路。\n>亚马逊和本杰瑞\n先有鸡还是先有蛋\n让我回到过去\n膨件和二八法则\n开源软件经济学\n\n","slug":"joel-on-software-1-2","published":1,"updated":"2018-04-27T04:11:03.352Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczoq000je4rw5qye8mqf","content":"<p>joel Spolsky著  杨帆译<br><a href=\"https://wizardforcel.gitbooks.io/joel-on-software/content/index.html\" title=\"软件随想录\" target=\"_blank\" rel=\"external\">Gitbook 电子书</a></p>\n<h1 id=\"开发人员的管理\"><a href=\"#开发人员的管理\" class=\"headerlink\" title=\"开发人员的管理\"></a>开发人员的管理</h1><ul>\n<li>面试游击指南<br>面试官有时候会故意刁难你，看你能否坚持自己的正确的观点。好的面试者会坚持自己的观点，然后试图说服面试官。</li>\n<li>重金激励害多利少<br>原因是绩效考核的不正确，负面评价对士气伤害很大，而正面评价对士气的激励也不如想象的那么好(会让他们觉得自己是为了拿到好成绩才好好工作的，就像巴普洛夫的狗)。<br>大多数人都认为自己把事情做得很好(即使不是)。评价机制的不合理：比如某人是团队的粘合剂，总是能够在士气低落的时候激励大家，某人总喜欢研究新技术，别人有问题总要靠他解决，但是他写的代码量很少，这两种人可能得到的评价很低，但是不可否认他们的作用很大。<br>绩效考评会使团队产生间隙。</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"冰山理论\"><a href=\"#冰山理论\" class=\"headerlink\" title=\"冰山理论\"></a>冰山理论</h1><p>程序员和非技术人员的思考语言不一样。客户不知道他们要什么，别再期望客户知道他们要什么。原型图上漂亮的接口只占10%的工作，而真正的90%的程序设计都是看不到的。</p>\n<blockquote>\n<p>推论1：把使用接口的画面展示给非程序人员看时，如果这个接口很不好，对方会以为你整个程序也是很不好的。<br>推论2：相反，如果这个接口很漂亮，对方会以为这个程序几乎已经完工。<br>推论3：展示时唯一重要的就是外观。一定要让它美得冒泡<br>推论4：<strong>当公司规定不会编程的管理人员或客户要对项目”签字验收”的时候,提供多个版本的图形设计方案，供他们选择。微调页面的排版方式、视觉样式、字体等，把产品标识<br>改大或改小一点，给他们一些决定无关痛痒事情的权力,让他们觉得自己的意见举足轻重。</strong><br>推论5：做产品演示的时候，唯一起作用的就是产品截图，一定要让截图100%完美。</p>\n</blockquote>\n<p>如何绕过冰山：任何在幻灯片展示的产品都只是<em>一堆像素</em>而已。如果可以的话，在demo的用户界面中，把那些为完成的部分画成未完成的燕子。比如在工具栏图标<br>对应的功能完成之前，把它画成潦草的手绘风格。在构建网络服务的时候，可以先不把为完成的功能展示在网站首页。这样随着开发的进展，人们就能看到首页的<br>功能按键从3项逐渐增加到20项。<strong>更重要的是</strong>，要掌控人们对于开发进度的预期。用Excel文件的形式提供一份详细的开发进度规划表。</p>\n<h1 id=\"漏洞抽象定律\"><a href=\"#漏洞抽象定律\" class=\"headerlink\" title=\"漏洞抽象定律\"></a>漏洞抽象定律</h1><blockquote>\n<p>可靠的tcp建立在不可靠的ip协议之上。<br>所有重大的抽象机制在某种程序上都是有漏洞的，所以我们有一天遇到了这些漏洞，不得不去学习它的底层实现。<br>比如二维数组的访问(内存分页)，sql语句查询的快慢(逻辑上等义的sql语句查询起来速度完全不一样)，c++的字符串处理。</p>\n</blockquote>\n<h1 id=\"凡事没有看上去那么简单\"><a href=\"#凡事没有看上去那么简单\" class=\"headerlink\" title=\"凡事没有看上去那么简单\"></a>凡事没有看上去那么简单</h1><p>凡事没有看上去那么简单、尽量降低风险 =&gt; 先做好设计，再去实现</p>\n<h1 id=\"普通程序员如何改善团队工作方式\"><a href=\"#普通程序员如何改善团队工作方式\" class=\"headerlink\" title=\"普通程序员如何改善团队工作方式\"></a>普通程序员如何改善团队工作方式</h1><ul>\n<li>放手去做</li>\n<li>借助病毒营销的方式</li>\n<li>营造以防优秀的小天地</li>\n<li>干掉害群之马</li>\n<li>屏蔽干扰 </li>\n<li>提升自身对团队的价值</li>\n</ul>\n<h1 id=\"企业发展战略\"><a href=\"#企业发展战略\" class=\"headerlink\" title=\"企业发展战略\"></a>企业发展战略</h1><p>关于创业的想法,需要时请再重点阅读，分清楚两种不同的公司发展道路。</p>\n<blockquote>\n<p>亚马逊和本杰瑞<br>先有鸡还是先有蛋<br>让我回到过去<br>膨件和二八法则<br>开源软件经济学</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>joel Spolsky著  杨帆译<br><a href=\"https://wizardforcel.gitbooks.io/joel-on-software/content/index.html\" title=\"软件随想录\" target=\"_blank\" rel=\"external\">Gitbook 电子书</a></p>\n<h1 id=\"开发人员的管理\"><a href=\"#开发人员的管理\" class=\"headerlink\" title=\"开发人员的管理\"></a>开发人员的管理</h1><ul>\n<li>面试游击指南<br>面试官有时候会故意刁难你，看你能否坚持自己的正确的观点。好的面试者会坚持自己的观点，然后试图说服面试官。</li>\n<li>重金激励害多利少<br>原因是绩效考核的不正确，负面评价对士气伤害很大，而正面评价对士气的激励也不如想象的那么好(会让他们觉得自己是为了拿到好成绩才好好工作的，就像巴普洛夫的狗)。<br>大多数人都认为自己把事情做得很好(即使不是)。评价机制的不合理：比如某人是团队的粘合剂，总是能够在士气低落的时候激励大家，某人总喜欢研究新技术，别人有问题总要靠他解决，但是他写的代码量很少，这两种人可能得到的评价很低，但是不可否认他们的作用很大。<br>绩效考评会使团队产生间隙。</li>\n</ul>","more":"<h1 id=\"冰山理论\"><a href=\"#冰山理论\" class=\"headerlink\" title=\"冰山理论\"></a>冰山理论</h1><p>程序员和非技术人员的思考语言不一样。客户不知道他们要什么，别再期望客户知道他们要什么。原型图上漂亮的接口只占10%的工作，而真正的90%的程序设计都是看不到的。</p>\n<blockquote>\n<p>推论1：把使用接口的画面展示给非程序人员看时，如果这个接口很不好，对方会以为你整个程序也是很不好的。<br>推论2：相反，如果这个接口很漂亮，对方会以为这个程序几乎已经完工。<br>推论3：展示时唯一重要的就是外观。一定要让它美得冒泡<br>推论4：<strong>当公司规定不会编程的管理人员或客户要对项目”签字验收”的时候,提供多个版本的图形设计方案，供他们选择。微调页面的排版方式、视觉样式、字体等，把产品标识<br>改大或改小一点，给他们一些决定无关痛痒事情的权力,让他们觉得自己的意见举足轻重。</strong><br>推论5：做产品演示的时候，唯一起作用的就是产品截图，一定要让截图100%完美。</p>\n</blockquote>\n<p>如何绕过冰山：任何在幻灯片展示的产品都只是<em>一堆像素</em>而已。如果可以的话，在demo的用户界面中，把那些为完成的部分画成未完成的燕子。比如在工具栏图标<br>对应的功能完成之前，把它画成潦草的手绘风格。在构建网络服务的时候，可以先不把为完成的功能展示在网站首页。这样随着开发的进展，人们就能看到首页的<br>功能按键从3项逐渐增加到20项。<strong>更重要的是</strong>，要掌控人们对于开发进度的预期。用Excel文件的形式提供一份详细的开发进度规划表。</p>\n<h1 id=\"漏洞抽象定律\"><a href=\"#漏洞抽象定律\" class=\"headerlink\" title=\"漏洞抽象定律\"></a>漏洞抽象定律</h1><blockquote>\n<p>可靠的tcp建立在不可靠的ip协议之上。<br>所有重大的抽象机制在某种程序上都是有漏洞的，所以我们有一天遇到了这些漏洞，不得不去学习它的底层实现。<br>比如二维数组的访问(内存分页)，sql语句查询的快慢(逻辑上等义的sql语句查询起来速度完全不一样)，c++的字符串处理。</p>\n</blockquote>\n<h1 id=\"凡事没有看上去那么简单\"><a href=\"#凡事没有看上去那么简单\" class=\"headerlink\" title=\"凡事没有看上去那么简单\"></a>凡事没有看上去那么简单</h1><p>凡事没有看上去那么简单、尽量降低风险 =&gt; 先做好设计，再去实现</p>\n<h1 id=\"普通程序员如何改善团队工作方式\"><a href=\"#普通程序员如何改善团队工作方式\" class=\"headerlink\" title=\"普通程序员如何改善团队工作方式\"></a>普通程序员如何改善团队工作方式</h1><ul>\n<li>放手去做</li>\n<li>借助病毒营销的方式</li>\n<li>营造以防优秀的小天地</li>\n<li>干掉害群之马</li>\n<li>屏蔽干扰 </li>\n<li>提升自身对团队的价值</li>\n</ul>\n<h1 id=\"企业发展战略\"><a href=\"#企业发展战略\" class=\"headerlink\" title=\"企业发展战略\"></a>企业发展战略</h1><p>关于创业的想法,需要时请再重点阅读，分清楚两种不同的公司发展道路。</p>\n<blockquote>\n<p>亚马逊和本杰瑞<br>先有鸡还是先有蛋<br>让我回到过去<br>膨件和二八法则<br>开源软件经济学</p>\n</blockquote>"},{"title":"LAMP站点搭建过程分析","date":"2017-03-20T11:34:19.000Z","_content":"LAMP 即 LINUX + APACHE + MYSQL +PHP 搭建网站的四大组件。下面详细介绍其普通的安装方法和配置。\n\n# LINUX \n咳，操作系统安装，可以使用VirtualBox创建虚拟机即可。这个就不细说了。推荐使用Centos6+\n\n# Apache httpd  \n1. 安装\n`yum install httpd`\n2. 配置\n查找出Httpd相关配置文件 `rpm -ql httpd|grep '/etc'`\n根据上述命令，查询主要的配置文件有/etc/httpd/conf/httpd.conf。 logs是日志链接目录。modules是支持的模块库目录。run是进程pid文件。\n3. 可执行文件\n>/usr/sbin/apachectl  #这个就是 Apache 的主要执行档，这个执行档其实是 shell script 而已， 他可以主动的侦测系统上面的一些设定值，好让你启动 Apache 时更简单！\n/usr/sbin/httpd     #这个才是主要的 Apache 二进制执行文件啦！\n/usr/bin/htpasswd   #(Apache 密码保护) 在某些网页当你想要登入时你需要输入账号与密码对吧！那 Apache 本身就提供一个最基本的密码保护方式， 该密码的产生就是透过这个指令来达成的！相关的设定方式我们会在 WWW 进阶设定当中说明的。\n4. 网页数据\n/var/www 目录下，html是放置网页内容的目录，error是错误信息的内容，icons是自带的一些图标目录，cgi-bin是默认网页可执行程序放置的地方。\n\n<!-- more -->\n\n# MYSQL   \n1. 安装 \n`yum install mysql mysql-server`\n2. 配置 \n查找配置文件与Apache Httpd 类似的，这里就不赘述了。主要配置文件是/etc/my.cnf 通过查看该文件，可看到日志的信息等。\n`cat /etc/my.cnf `\n>[mysqld]\ndatadir=/var/lib/mysql\nsocket=/var/lib/mysql/mysql.sock\nuser=mysql\n#Disabling symbolic-links is recommended to prevent assorted security risks\nsymbolic-links=0\n[mysqld_safe]\nlog-error=/var/log/mysqld.log\npid-file=/var/run/mysqld/mysqld.pid\n\n# PHP \n1. 安装 \n`yum install php php-mysql`\n2. 配置\n/etc/php.ini\n>/etc/php.ini #就是 PHP 的主要配置文件，包括你的 PHP 能不能允许使用者上传档案？能不能允许某些低安全性的标志等等， 都在这个配置文件当中设定的啦！\n/usr/lib64/httpd/modules/libphp5.so # PHP 这个软件提供给 Apache 使用的模块！这也是我们能否Apache 网页上面设计 PHP 程序语言的最重要的咚咚！ 务必要存在才行！\n/etc/php.d/mysql.ini, /usr/lib64/php/modules/mysql.so #你的 PHP 是否可以支持 MySQL 接口呢？就看这两个东西啦！这两个咚咚是由php-mysql 软件提供的呢！\n/usr/bin/phpize, /usr/include/php/ #如果你未来想要安装类似 PHP 加速器以让浏览速度加快的话，那么这个档案与目录就得要存在， 否则加速器软件可无法编译成功喔！这两个数据也是php-devel 软件所提供的啦！\n\n>[root@jinqiu mysql]# rpm -ql php\n/etc/httpd/conf.d/php.conf\n/usr/lib64/httpd/modules/libphp5.so\n/var/lib/php/session\n/var/www/icons/php.gif  \n\n/etc/httpd/conf.d/php.conf 是与apache相关联的配置文件，不需要手动写入/etc/httpd/conf/httpd.conf文件中，httpd服务会自动到/etc/httpd/conf.d 目录下读取该文件。\n\n以上就是基本的LAMP的搭建过程。具体的httpd.conf要再去查阅相关文档。建议安装http-manual软件，提供操作手册,可查询。\n同时为支持其他脚本语言，也可安装mrtg画图软件，mod-perl ,mod-python,mod-ssl。\n\n# 初试网站搭建\n当上述四个步骤都操作完成之后，接下来就是验证功能咯。各位请看\n* 静态网页   \n\n在/var/www/html 目录下新建php文件，演示如下。并通过浏览器查询界面。\n>[root@jinqiu html]# pwd\n/var/www/html\n[root@jinqiu html]# ls\nhello  index.html  phpinfo.php\n[root@jinqiu html]# cat phpinfo.php \n<?php phpinfo(); ?>\n\n`<?php ... ?> `是嵌入在 HTML 档案内的 PHP 程序语法，在这两个标签内的就是 PHP 的程序代码。那么 phpinfo(); 就是 PHP 程序提供的一个函式库，这个函式库可 以显示出你 WWW 服务器内的相关服务信息， 包括主要的 Apache 信息与 PHP 信息等等  \n* 简单动态网页\n修改配置执行perl 脚本。\n>vi /etc/httpd/conf/httpd.conf\nAddHandler cgi-script .cgi .pl\n<Directory \"/var/www/html/cgi\">\n        Options +ExecCGI\n        AllowOverride None\n        Order allow,deny\n        Allow from all\n</Directory>\n\n\n在/var/www/html/cgi 目录下新建perl文件\n>[root@www ~]# mkdir /var/www/html/cgi  \n[root@www ~]# vim /var/www/html/cgi/helloworld.pl\n#!/usr/bin/perl\nprint \"Content-type: text/html\\r\\n\\r\\n\";\nprint \"Hello, World.\";\n[root@www ~]# chmod a+x /var/www/html/cgi/helloworld.pl  #赋权 非常重要\n\n\n\n# phpBB3 搭建论坛  \n首先到官网上下载zip安装包，和汉化包。然后将安装包解压到/var/www/html apache网站目录下，重命名解压后的文件夹名称phpBB3。然后通过浏览器url: http://localhost:80/phpBB3/install/index.php 安装界面进行安装。 \n在新建论坛之后，要记得对论坛赋权限。然后还有把网站下的install文件删除或者重命名。否则看不见论坛，处于关闭状态。\n\n# Wordpress 搭建个人博客\n首先到官网上下载zip安装包。与phpBB3一样，将其解压后的文件夹复制到/var/www/html/目录下，重命名为wordpress。然后到通过浏览器访问http://localhost:80/wordpress/ 访问，即可自动跳转至配置界面，进行数据库的配置，最后会在/wordpress目录下生成wp_config.php配置文件，然后进入安装界面。配置用户名密码即可完成安装。\nps:在配置过程中，如果出现没有权限生成wp_config.php。手动复制文件内容自己创建也可。我在安装过程中出现问题，就是配置完文件后，并且生成wp_config.php后，一直又重复回到配置界面。仿佛就像他没有检测到生成的wp_config.php文件一样，及时我重启httpd服务也是如此。后来我把/wordpress 目录下的文件全部删除，重新配置一把就可以了。\n","source":"_posts/lamp-build.md","raw":"---\ntitle: LAMP站点搭建过程分析\ndate: 2017-03-20 19:34:19\ntags: LAMP\ncategory: 技术 \n---\nLAMP 即 LINUX + APACHE + MYSQL +PHP 搭建网站的四大组件。下面详细介绍其普通的安装方法和配置。\n\n# LINUX \n咳，操作系统安装，可以使用VirtualBox创建虚拟机即可。这个就不细说了。推荐使用Centos6+\n\n# Apache httpd  \n1. 安装\n`yum install httpd`\n2. 配置\n查找出Httpd相关配置文件 `rpm -ql httpd|grep '/etc'`\n根据上述命令，查询主要的配置文件有/etc/httpd/conf/httpd.conf。 logs是日志链接目录。modules是支持的模块库目录。run是进程pid文件。\n3. 可执行文件\n>/usr/sbin/apachectl  #这个就是 Apache 的主要执行档，这个执行档其实是 shell script 而已， 他可以主动的侦测系统上面的一些设定值，好让你启动 Apache 时更简单！\n/usr/sbin/httpd     #这个才是主要的 Apache 二进制执行文件啦！\n/usr/bin/htpasswd   #(Apache 密码保护) 在某些网页当你想要登入时你需要输入账号与密码对吧！那 Apache 本身就提供一个最基本的密码保护方式， 该密码的产生就是透过这个指令来达成的！相关的设定方式我们会在 WWW 进阶设定当中说明的。\n4. 网页数据\n/var/www 目录下，html是放置网页内容的目录，error是错误信息的内容，icons是自带的一些图标目录，cgi-bin是默认网页可执行程序放置的地方。\n\n<!-- more -->\n\n# MYSQL   \n1. 安装 \n`yum install mysql mysql-server`\n2. 配置 \n查找配置文件与Apache Httpd 类似的，这里就不赘述了。主要配置文件是/etc/my.cnf 通过查看该文件，可看到日志的信息等。\n`cat /etc/my.cnf `\n>[mysqld]\ndatadir=/var/lib/mysql\nsocket=/var/lib/mysql/mysql.sock\nuser=mysql\n#Disabling symbolic-links is recommended to prevent assorted security risks\nsymbolic-links=0\n[mysqld_safe]\nlog-error=/var/log/mysqld.log\npid-file=/var/run/mysqld/mysqld.pid\n\n# PHP \n1. 安装 \n`yum install php php-mysql`\n2. 配置\n/etc/php.ini\n>/etc/php.ini #就是 PHP 的主要配置文件，包括你的 PHP 能不能允许使用者上传档案？能不能允许某些低安全性的标志等等， 都在这个配置文件当中设定的啦！\n/usr/lib64/httpd/modules/libphp5.so # PHP 这个软件提供给 Apache 使用的模块！这也是我们能否Apache 网页上面设计 PHP 程序语言的最重要的咚咚！ 务必要存在才行！\n/etc/php.d/mysql.ini, /usr/lib64/php/modules/mysql.so #你的 PHP 是否可以支持 MySQL 接口呢？就看这两个东西啦！这两个咚咚是由php-mysql 软件提供的呢！\n/usr/bin/phpize, /usr/include/php/ #如果你未来想要安装类似 PHP 加速器以让浏览速度加快的话，那么这个档案与目录就得要存在， 否则加速器软件可无法编译成功喔！这两个数据也是php-devel 软件所提供的啦！\n\n>[root@jinqiu mysql]# rpm -ql php\n/etc/httpd/conf.d/php.conf\n/usr/lib64/httpd/modules/libphp5.so\n/var/lib/php/session\n/var/www/icons/php.gif  \n\n/etc/httpd/conf.d/php.conf 是与apache相关联的配置文件，不需要手动写入/etc/httpd/conf/httpd.conf文件中，httpd服务会自动到/etc/httpd/conf.d 目录下读取该文件。\n\n以上就是基本的LAMP的搭建过程。具体的httpd.conf要再去查阅相关文档。建议安装http-manual软件，提供操作手册,可查询。\n同时为支持其他脚本语言，也可安装mrtg画图软件，mod-perl ,mod-python,mod-ssl。\n\n# 初试网站搭建\n当上述四个步骤都操作完成之后，接下来就是验证功能咯。各位请看\n* 静态网页   \n\n在/var/www/html 目录下新建php文件，演示如下。并通过浏览器查询界面。\n>[root@jinqiu html]# pwd\n/var/www/html\n[root@jinqiu html]# ls\nhello  index.html  phpinfo.php\n[root@jinqiu html]# cat phpinfo.php \n<?php phpinfo(); ?>\n\n`<?php ... ?> `是嵌入在 HTML 档案内的 PHP 程序语法，在这两个标签内的就是 PHP 的程序代码。那么 phpinfo(); 就是 PHP 程序提供的一个函式库，这个函式库可 以显示出你 WWW 服务器内的相关服务信息， 包括主要的 Apache 信息与 PHP 信息等等  \n* 简单动态网页\n修改配置执行perl 脚本。\n>vi /etc/httpd/conf/httpd.conf\nAddHandler cgi-script .cgi .pl\n<Directory \"/var/www/html/cgi\">\n        Options +ExecCGI\n        AllowOverride None\n        Order allow,deny\n        Allow from all\n</Directory>\n\n\n在/var/www/html/cgi 目录下新建perl文件\n>[root@www ~]# mkdir /var/www/html/cgi  \n[root@www ~]# vim /var/www/html/cgi/helloworld.pl\n#!/usr/bin/perl\nprint \"Content-type: text/html\\r\\n\\r\\n\";\nprint \"Hello, World.\";\n[root@www ~]# chmod a+x /var/www/html/cgi/helloworld.pl  #赋权 非常重要\n\n\n\n# phpBB3 搭建论坛  \n首先到官网上下载zip安装包，和汉化包。然后将安装包解压到/var/www/html apache网站目录下，重命名解压后的文件夹名称phpBB3。然后通过浏览器url: http://localhost:80/phpBB3/install/index.php 安装界面进行安装。 \n在新建论坛之后，要记得对论坛赋权限。然后还有把网站下的install文件删除或者重命名。否则看不见论坛，处于关闭状态。\n\n# Wordpress 搭建个人博客\n首先到官网上下载zip安装包。与phpBB3一样，将其解压后的文件夹复制到/var/www/html/目录下，重命名为wordpress。然后到通过浏览器访问http://localhost:80/wordpress/ 访问，即可自动跳转至配置界面，进行数据库的配置，最后会在/wordpress目录下生成wp_config.php配置文件，然后进入安装界面。配置用户名密码即可完成安装。\nps:在配置过程中，如果出现没有权限生成wp_config.php。手动复制文件内容自己创建也可。我在安装过程中出现问题，就是配置完文件后，并且生成wp_config.php后，一直又重复回到配置界面。仿佛就像他没有检测到生成的wp_config.php文件一样，及时我重启httpd服务也是如此。后来我把/wordpress 目录下的文件全部删除，重新配置一把就可以了。\n","slug":"lamp-build","published":1,"updated":"2018-04-27T04:11:03.356Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczos000me4rwfi9ljy1r","content":"<p>LAMP 即 LINUX + APACHE + MYSQL +PHP 搭建网站的四大组件。下面详细介绍其普通的安装方法和配置。</p>\n<h1 id=\"LINUX\"><a href=\"#LINUX\" class=\"headerlink\" title=\"LINUX\"></a>LINUX</h1><p>咳，操作系统安装，可以使用VirtualBox创建虚拟机即可。这个就不细说了。推荐使用Centos6+</p>\n<h1 id=\"Apache-httpd\"><a href=\"#Apache-httpd\" class=\"headerlink\" title=\"Apache httpd\"></a>Apache httpd</h1><ol>\n<li>安装<br><code>yum install httpd</code></li>\n<li>配置<br>查找出Httpd相关配置文件 <code>rpm -ql httpd|grep &#39;/etc&#39;</code><br>根据上述命令，查询主要的配置文件有/etc/httpd/conf/httpd.conf。 logs是日志链接目录。modules是支持的模块库目录。run是进程pid文件。</li>\n<li>可执行文件<blockquote>\n<p>/usr/sbin/apachectl  #这个就是 Apache 的主要执行档，这个执行档其实是 shell script 而已， 他可以主动的侦测系统上面的一些设定值，好让你启动 Apache 时更简单！<br>/usr/sbin/httpd     #这个才是主要的 Apache 二进制执行文件啦！<br>/usr/bin/htpasswd   #(Apache 密码保护) 在某些网页当你想要登入时你需要输入账号与密码对吧！那 Apache 本身就提供一个最基本的密码保护方式， 该密码的产生就是透过这个指令来达成的！相关的设定方式我们会在 WWW 进阶设定当中说明的。</p>\n</blockquote>\n</li>\n<li>网页数据<br>/var/www 目录下，html是放置网页内容的目录，error是错误信息的内容，icons是自带的一些图标目录，cgi-bin是默认网页可执行程序放置的地方。</li>\n</ol>\n<a id=\"more\"></a>\n<h1 id=\"MYSQL\"><a href=\"#MYSQL\" class=\"headerlink\" title=\"MYSQL\"></a>MYSQL</h1><ol>\n<li>安装<br><code>yum install mysql mysql-server</code></li>\n<li>配置<br>查找配置文件与Apache Httpd 类似的，这里就不赘述了。主要配置文件是/etc/my.cnf 通过查看该文件，可看到日志的信息等。<br><code>cat /etc/my.cnf</code><blockquote>\n<p>[mysqld]<br>datadir=/var/lib/mysql<br>socket=/var/lib/mysql/mysql.sock<br>user=mysql<br>#Disabling symbolic-links is recommended to prevent assorted security risks<br>symbolic-links=0<br>[mysqld_safe]<br>log-error=/var/log/mysqld.log<br>pid-file=/var/run/mysqld/mysqld.pid</p>\n</blockquote>\n</li>\n</ol>\n<h1 id=\"PHP\"><a href=\"#PHP\" class=\"headerlink\" title=\"PHP\"></a>PHP</h1><ol>\n<li>安装<br><code>yum install php php-mysql</code></li>\n<li>配置<br>/etc/php.ini<blockquote>\n<p>/etc/php.ini #就是 PHP 的主要配置文件，包括你的 PHP 能不能允许使用者上传档案？能不能允许某些低安全性的标志等等， 都在这个配置文件当中设定的啦！<br>/usr/lib64/httpd/modules/libphp5.so # PHP 这个软件提供给 Apache 使用的模块！这也是我们能否Apache 网页上面设计 PHP 程序语言的最重要的咚咚！ 务必要存在才行！<br>/etc/php.d/mysql.ini, /usr/lib64/php/modules/mysql.so #你的 PHP 是否可以支持 MySQL 接口呢？就看这两个东西啦！这两个咚咚是由php-mysql 软件提供的呢！<br>/usr/bin/phpize, /usr/include/php/ #如果你未来想要安装类似 PHP 加速器以让浏览速度加快的话，那么这个档案与目录就得要存在， 否则加速器软件可无法编译成功喔！这两个数据也是php-devel 软件所提供的啦！</p>\n</blockquote>\n</li>\n</ol>\n<blockquote>\n<p>[root@jinqiu mysql]# rpm -ql php<br>/etc/httpd/conf.d/php.conf<br>/usr/lib64/httpd/modules/libphp5.so<br>/var/lib/php/session<br>/var/www/icons/php.gif  </p>\n</blockquote>\n<p>/etc/httpd/conf.d/php.conf 是与apache相关联的配置文件，不需要手动写入/etc/httpd/conf/httpd.conf文件中，httpd服务会自动到/etc/httpd/conf.d 目录下读取该文件。</p>\n<p>以上就是基本的LAMP的搭建过程。具体的httpd.conf要再去查阅相关文档。建议安装http-manual软件，提供操作手册,可查询。<br>同时为支持其他脚本语言，也可安装mrtg画图软件，mod-perl ,mod-python,mod-ssl。</p>\n<h1 id=\"初试网站搭建\"><a href=\"#初试网站搭建\" class=\"headerlink\" title=\"初试网站搭建\"></a>初试网站搭建</h1><p>当上述四个步骤都操作完成之后，接下来就是验证功能咯。各位请看</p>\n<ul>\n<li>静态网页   </li>\n</ul>\n<p>在/var/www/html 目录下新建php文件，演示如下。并通过浏览器查询界面。</p>\n<blockquote>\n<p>[root@jinqiu html]# pwd<br>/var/www/html<br>[root@jinqiu html]# ls<br>hello  index.html  phpinfo.php<br>[root@jinqiu html]# cat phpinfo.php<br>&lt;?php phpinfo(); ?&gt;</p>\n</blockquote>\n<p><code>&lt;?php ... ?&gt;</code>是嵌入在 HTML 档案内的 PHP 程序语法，在这两个标签内的就是 PHP 的程序代码。那么 phpinfo(); 就是 PHP 程序提供的一个函式库，这个函式库可 以显示出你 WWW 服务器内的相关服务信息， 包括主要的 Apache 信息与 PHP 信息等等  </p>\n<ul>\n<li>简单动态网页<br>修改配置执行perl 脚本。<blockquote>\n<p>vi /etc/httpd/conf/httpd.conf<br>AddHandler cgi-script .cgi .pl</p>\n<directory \"=\"\" var=\"\" www=\"\" html=\"\" cgi\"=\"\"><br>      Options +ExecCGI<br>      AllowOverride None<br>      Order allow,deny<br>      Allow from all<br></directory>\n\n\n</blockquote>\n</li>\n</ul>\n<p>在/var/www/html/cgi 目录下新建perl文件</p>\n<blockquote>\n<p>[root@www ~]# mkdir /var/www/html/cgi<br>[root@www ~]# vim /var/www/html/cgi/helloworld.pl</p>\n<p>#!/usr/bin/perl<br>print “Content-type: text/html\\r\\n\\r\\n”;<br>print “Hello, World.”;<br>[root@www ~]# chmod a+x /var/www/html/cgi/helloworld.pl  #赋权 非常重要</p>\n</blockquote>\n<h1 id=\"phpBB3-搭建论坛\"><a href=\"#phpBB3-搭建论坛\" class=\"headerlink\" title=\"phpBB3 搭建论坛\"></a>phpBB3 搭建论坛</h1><p>首先到官网上下载zip安装包，和汉化包。然后将安装包解压到/var/www/html apache网站目录下，重命名解压后的文件夹名称phpBB3。然后通过浏览器url: <a href=\"http://localhost:80/phpBB3/install/index.php\" target=\"_blank\" rel=\"external\">http://localhost:80/phpBB3/install/index.php</a> 安装界面进行安装。<br>在新建论坛之后，要记得对论坛赋权限。然后还有把网站下的install文件删除或者重命名。否则看不见论坛，处于关闭状态。</p>\n<h1 id=\"Wordpress-搭建个人博客\"><a href=\"#Wordpress-搭建个人博客\" class=\"headerlink\" title=\"Wordpress 搭建个人博客\"></a>Wordpress 搭建个人博客</h1><p>首先到官网上下载zip安装包。与phpBB3一样，将其解压后的文件夹复制到/var/www/html/目录下，重命名为wordpress。然后到通过浏览器访问<a href=\"http://localhost:80/wordpress/\" target=\"_blank\" rel=\"external\">http://localhost:80/wordpress/</a> 访问，即可自动跳转至配置界面，进行数据库的配置，最后会在/wordpress目录下生成wp_config.php配置文件，然后进入安装界面。配置用户名密码即可完成安装。<br>ps:在配置过程中，如果出现没有权限生成wp_config.php。手动复制文件内容自己创建也可。我在安装过程中出现问题，就是配置完文件后，并且生成wp_config.php后，一直又重复回到配置界面。仿佛就像他没有检测到生成的wp_config.php文件一样，及时我重启httpd服务也是如此。后来我把/wordpress 目录下的文件全部删除，重新配置一把就可以了。</p>\n","site":{"data":{}},"excerpt":"<p>LAMP 即 LINUX + APACHE + MYSQL +PHP 搭建网站的四大组件。下面详细介绍其普通的安装方法和配置。</p>\n<h1 id=\"LINUX\"><a href=\"#LINUX\" class=\"headerlink\" title=\"LINUX\"></a>LINUX</h1><p>咳，操作系统安装，可以使用VirtualBox创建虚拟机即可。这个就不细说了。推荐使用Centos6+</p>\n<h1 id=\"Apache-httpd\"><a href=\"#Apache-httpd\" class=\"headerlink\" title=\"Apache httpd\"></a>Apache httpd</h1><ol>\n<li>安装<br><code>yum install httpd</code></li>\n<li>配置<br>查找出Httpd相关配置文件 <code>rpm -ql httpd|grep &#39;/etc&#39;</code><br>根据上述命令，查询主要的配置文件有/etc/httpd/conf/httpd.conf。 logs是日志链接目录。modules是支持的模块库目录。run是进程pid文件。</li>\n<li>可执行文件<blockquote>\n<p>/usr/sbin/apachectl  #这个就是 Apache 的主要执行档，这个执行档其实是 shell script 而已， 他可以主动的侦测系统上面的一些设定值，好让你启动 Apache 时更简单！<br>/usr/sbin/httpd     #这个才是主要的 Apache 二进制执行文件啦！<br>/usr/bin/htpasswd   #(Apache 密码保护) 在某些网页当你想要登入时你需要输入账号与密码对吧！那 Apache 本身就提供一个最基本的密码保护方式， 该密码的产生就是透过这个指令来达成的！相关的设定方式我们会在 WWW 进阶设定当中说明的。</p>\n</blockquote>\n</li>\n<li>网页数据<br>/var/www 目录下，html是放置网页内容的目录，error是错误信息的内容，icons是自带的一些图标目录，cgi-bin是默认网页可执行程序放置的地方。</li>\n</ol>","more":"<h1 id=\"MYSQL\"><a href=\"#MYSQL\" class=\"headerlink\" title=\"MYSQL\"></a>MYSQL</h1><ol>\n<li>安装<br><code>yum install mysql mysql-server</code></li>\n<li>配置<br>查找配置文件与Apache Httpd 类似的，这里就不赘述了。主要配置文件是/etc/my.cnf 通过查看该文件，可看到日志的信息等。<br><code>cat /etc/my.cnf</code><blockquote>\n<p>[mysqld]<br>datadir=/var/lib/mysql<br>socket=/var/lib/mysql/mysql.sock<br>user=mysql<br>#Disabling symbolic-links is recommended to prevent assorted security risks<br>symbolic-links=0<br>[mysqld_safe]<br>log-error=/var/log/mysqld.log<br>pid-file=/var/run/mysqld/mysqld.pid</p>\n</blockquote>\n</li>\n</ol>\n<h1 id=\"PHP\"><a href=\"#PHP\" class=\"headerlink\" title=\"PHP\"></a>PHP</h1><ol>\n<li>安装<br><code>yum install php php-mysql</code></li>\n<li>配置<br>/etc/php.ini<blockquote>\n<p>/etc/php.ini #就是 PHP 的主要配置文件，包括你的 PHP 能不能允许使用者上传档案？能不能允许某些低安全性的标志等等， 都在这个配置文件当中设定的啦！<br>/usr/lib64/httpd/modules/libphp5.so # PHP 这个软件提供给 Apache 使用的模块！这也是我们能否Apache 网页上面设计 PHP 程序语言的最重要的咚咚！ 务必要存在才行！<br>/etc/php.d/mysql.ini, /usr/lib64/php/modules/mysql.so #你的 PHP 是否可以支持 MySQL 接口呢？就看这两个东西啦！这两个咚咚是由php-mysql 软件提供的呢！<br>/usr/bin/phpize, /usr/include/php/ #如果你未来想要安装类似 PHP 加速器以让浏览速度加快的话，那么这个档案与目录就得要存在， 否则加速器软件可无法编译成功喔！这两个数据也是php-devel 软件所提供的啦！</p>\n</blockquote>\n</li>\n</ol>\n<blockquote>\n<p>[root@jinqiu mysql]# rpm -ql php<br>/etc/httpd/conf.d/php.conf<br>/usr/lib64/httpd/modules/libphp5.so<br>/var/lib/php/session<br>/var/www/icons/php.gif  </p>\n</blockquote>\n<p>/etc/httpd/conf.d/php.conf 是与apache相关联的配置文件，不需要手动写入/etc/httpd/conf/httpd.conf文件中，httpd服务会自动到/etc/httpd/conf.d 目录下读取该文件。</p>\n<p>以上就是基本的LAMP的搭建过程。具体的httpd.conf要再去查阅相关文档。建议安装http-manual软件，提供操作手册,可查询。<br>同时为支持其他脚本语言，也可安装mrtg画图软件，mod-perl ,mod-python,mod-ssl。</p>\n<h1 id=\"初试网站搭建\"><a href=\"#初试网站搭建\" class=\"headerlink\" title=\"初试网站搭建\"></a>初试网站搭建</h1><p>当上述四个步骤都操作完成之后，接下来就是验证功能咯。各位请看</p>\n<ul>\n<li>静态网页   </li>\n</ul>\n<p>在/var/www/html 目录下新建php文件，演示如下。并通过浏览器查询界面。</p>\n<blockquote>\n<p>[root@jinqiu html]# pwd<br>/var/www/html<br>[root@jinqiu html]# ls<br>hello  index.html  phpinfo.php<br>[root@jinqiu html]# cat phpinfo.php<br>&lt;?php phpinfo(); ?&gt;</p>\n</blockquote>\n<p><code>&lt;?php ... ?&gt;</code>是嵌入在 HTML 档案内的 PHP 程序语法，在这两个标签内的就是 PHP 的程序代码。那么 phpinfo(); 就是 PHP 程序提供的一个函式库，这个函式库可 以显示出你 WWW 服务器内的相关服务信息， 包括主要的 Apache 信息与 PHP 信息等等  </p>\n<ul>\n<li>简单动态网页<br>修改配置执行perl 脚本。<blockquote>\n<p>vi /etc/httpd/conf/httpd.conf<br>AddHandler cgi-script .cgi .pl</p>\n<directory \"=\"\" var=\"\" www=\"\" html=\"\" cgi\"=\"\"><br>      Options +ExecCGI<br>      AllowOverride None<br>      Order allow,deny<br>      Allow from all<br></directory>\n\n\n</blockquote>\n</li>\n</ul>\n<p>在/var/www/html/cgi 目录下新建perl文件</p>\n<blockquote>\n<p>[root@www ~]# mkdir /var/www/html/cgi<br>[root@www ~]# vim /var/www/html/cgi/helloworld.pl</p>\n<p>#!/usr/bin/perl<br>print “Content-type: text/html\\r\\n\\r\\n”;<br>print “Hello, World.”;<br>[root@www ~]# chmod a+x /var/www/html/cgi/helloworld.pl  #赋权 非常重要</p>\n</blockquote>\n<h1 id=\"phpBB3-搭建论坛\"><a href=\"#phpBB3-搭建论坛\" class=\"headerlink\" title=\"phpBB3 搭建论坛\"></a>phpBB3 搭建论坛</h1><p>首先到官网上下载zip安装包，和汉化包。然后将安装包解压到/var/www/html apache网站目录下，重命名解压后的文件夹名称phpBB3。然后通过浏览器url: <a href=\"http://localhost:80/phpBB3/install/index.php\" target=\"_blank\" rel=\"external\">http://localhost:80/phpBB3/install/index.php</a> 安装界面进行安装。<br>在新建论坛之后，要记得对论坛赋权限。然后还有把网站下的install文件删除或者重命名。否则看不见论坛，处于关闭状态。</p>\n<h1 id=\"Wordpress-搭建个人博客\"><a href=\"#Wordpress-搭建个人博客\" class=\"headerlink\" title=\"Wordpress 搭建个人博客\"></a>Wordpress 搭建个人博客</h1><p>首先到官网上下载zip安装包。与phpBB3一样，将其解压后的文件夹复制到/var/www/html/目录下，重命名为wordpress。然后到通过浏览器访问<a href=\"http://localhost:80/wordpress/\" target=\"_blank\" rel=\"external\">http://localhost:80/wordpress/</a> 访问，即可自动跳转至配置界面，进行数据库的配置，最后会在/wordpress目录下生成wp_config.php配置文件，然后进入安装界面。配置用户名密码即可完成安装。<br>ps:在配置过程中，如果出现没有权限生成wp_config.php。手动复制文件内容自己创建也可。我在安装过程中出现问题，就是配置完文件后，并且生成wp_config.php后，一直又重复回到配置界面。仿佛就像他没有检测到生成的wp_config.php文件一样，及时我重启httpd服务也是如此。后来我把/wordpress 目录下的文件全部删除，重新配置一把就可以了。</p>"},{"title":"软件随想录-卷2","date":"2017-02-20T09:36:29.000Z","_content":"\njoel Spolsky著 阮一峰译  \n[Gitbook 电子书](https://wizardforcel.gitbooks.io/joel-on-software/content/index.html  \"软件随想录\")\n\n# 寻找优秀程序员的三种办法\n>社招(简历)不靠谱，员工推荐不太靠谱\n走出去，参加开发者大会\n找实习生。\n创造自己的知名社区网站。\n\n# 写给程序员的建议\n任何时刻不要想着推倒重来，重构而不是重新做一遍\n不添加任何新功能\n无论任何时刻向源码库添加代码，都要保证程序能够正常运行\n所要做的只是一些合乎逻辑的变换，几乎都是机械性的，而且能够立刻确定不会改变代码行为\n并不是每个人都适合当程序员\n\n<!-- more -->\n\n# 为什么做一个内部程序员就槽糕透了呢\n1. 你永远无法用正确的事情做事情，总是被迫用最保险的方法做事。\n2. 一旦你的程序可以用了，你就不得不停止项目，转而开发其他项目。\n3. 如果你在专业的软件公司中编程，你的工作与公司的主营业务是直接相关，是能够为公司直接带来收入的，这至少意味着一件事情，就是管理层会想到你。\n\n# 程序员管理的三种方法\n| 方法   | 说明 |  缺点   |\n| :-------: | :----: | :---: |\n| 军事化管理法 | 军队可以让士兵绝对服从命令 |  1.会使团队人员不爽 2.不可能管理到所有细节 3.对于技术问题，程序员才是做决策的最佳人选，因为他们知道更多的技术细节。    |\n| 经济利益驱动法 | 假设每个人的行为动机都是钱| 1.会降低团队人员的内部驱动力，当你停止付钱或者他们不再需要钱，他们的驱动力就会消失。2.员工会追求局部利益最大化，最终为了自己的利益可能做出对公司不好的行为。3.会鼓励员工与制度博弈，寻找制度的缺失之处来为自己谋利。经济利益驱动法更像是管理的退位，表面上简化了管理，但实际上却是管理的缺失。   |\n| 认同法     | 方法：1.培养认同感。设定积极的目标和价值观。2.培养凝聚力和归属感。团队的人要一起吃饭，多组织集体活动。3.信息共享。和员工要做到信息共享，以便员工更好的工作。  |  实施起来不容易。|\n\n推荐做法：***认同法***\n\n# 设计的作用\n> 字体平滑、反锯齿和次像素渲染\n苹果公司的设计有利于频幕界面和印刷一致\n微软公司的设计有利于屏幕阅读\n苹果的字体放到微软的系统上面会有一点模糊，比如在mac上面装windows系统，字体会变模糊。 \n寸土必争\n随便找一个东西，如果你找不到它的缺点，那就说明你的转型还没有成功。\n大构想的陷阱\n阅读的时候，眼镜只会盯住一个点，而其它地方像素很低，但是由于眼镜的注意力快速移动，让你产生了你已经看到了所有细节的错觉。软件设计中，你以为你可以做出来，看上去大体流程很清楚，但是一旦你考虑细节的时候你才会知道，你少考虑了很多东西。\n\n# 别让用户做太多选择   \n微软的关机选项有7种，再加上电源键(点击和长按)或者一些电脑上有快捷键关机或者重启，合下屏幕也可以睡眠或者关机。这样给用户的选择就有10种左右，而过多的选择会让用户产生选择困难而失去幸福感。\n如何改进？\n>Switch User之前肯定要Lock，这两个按钮可以合并。\nLog Off就是为了退出当前运行的所有程序，可以和ShutDown按钮合并。\nRestart和shutdown是一样的，只需要按两次shutdown按钮即可(假设关机速度很快，而且不是远程操控(一般远程操控是命令行操作))\nSleep和Hibernate说实话我不太懂他们的区别。\n现在我们只剩下 switch user/lock     log off/shutdown     hibernate/sleep三个按钮。\n考虑switch user/lock     hibernate/sleep这两个按钮的合并，当我按下这一个复合按钮的时候，会弹出一个切换用户的对话框，然后30秒内没有切换用户会进入休眠状态，而这个过程中计算机是一直锁定的。\n现在计算机只剩两个按钮了，就是这两种状态：\n1、我要离开电脑一会儿\n2、我要离开电脑很久，需要拔下电源   \n现在考虑能不能合并这两个按钮，现在的电源管理系统已经能够做到你在睡眠状态下不关闭电脑也只耗很低的电源，即使你拔掉电源也能够保存你的数据，不会损失你的任何数据，所以这两个按钮完全可以合并。\n\n# 管理大型项目\n火星人的耳机：这一部分主要讲述了为什么现在的web标准如此复杂。\n>* 一对多模式：假设你在火星上发现火星人还在使用录音机，你发现了商机，你决定卖mp3给他们，为此你要制造一种耳机，于是你写了一份规格书，让其他厂商制造耳机，但是你的规格书里误写了电压的参数，结果厂商做出来的耳机总是爆炸，然后经过调整声音的赫兹终于能正常使用了，就这样你让火星人大量买了你的耳机，然后你想让你的耳机拥有打电话的功能，就是加一个麦克风，然后你重新设计了一个适配器，这个适配器考虑了以后的升级问题，但是推出以后火星人根本没人买，他们只在乎家里收藏了一衣柜的耳机，根本不在乎什么麦克风功能。然后你只有在耳机的接口处扩展功能，把耳机的金属轴接口分成三份，其中一份可以用来做麦克风功能，你又设计了一份协议，在接口处发射一个信号，当mp3找到这个信号的时候，就开启麦克风模式，否则就开启向后兼容的耳机模式，现在，整个市场就变成了一对多模式，同一个耳机有多个版本了。  \n\n\n>* 多对多模式：由于你不停的给mp3增加功能，每个生产耳机的厂商都要把耳机在每一个mp3型号测试一遍，由于规格书的繁琐难读，有些产品出现了不兼容的现象，然后为了降低成本，厂商不得不只让耳机适配最流行的mp3播放器，这样，当耳机插入其他mp3的时候，会播放不出来或者更严重的会爆炸。原因是规格书有一个功能写得不清楚，比如，如果下雨，电压会升高，如果不下雨，电压不变。但是关于下雪，规格书没有讲，有的地方把下雪当成了下雨的一种，原因是都要用到雨刮器。有的地方从不下雪，所以就不是下雨。\n\n\n>* 然后有一个无聊的家伙，发表了一篇文章，利用漏洞可以解决兼容问题，比如用程序把下雪也误判成下雨，于是市场上就出现了多个版本的耳机和mp3，这就是多对多。\n\n微软的ie8就是类似上面的流程\n* 为什么微软office的文件格式如此复杂\n* 要挣钱就别嫌脏\n\n# 编程建议\n* 询证式日程规划\n完后速率 = 估计用时/实际用时\n蒙特卡洛方法估计值：\n![about time](/img/about_time.jpg )\n* 让错误的代码显而易见\n网站中，用户输入的字符串必须经过编码后才能使用，否则有可能会受到攻击。\n怎样才能尽量避免这种出错方式呢？\n>第一种办法：当用户的数据一传进来，就对数据进行编码。但是当需要直接存到数据库的时候实际上是要存储原来的字符的，所以不行。\n第二种办法：制定一种规范，只有输出字符串的时候才进行编码，但是有个问题，有些要输出的字符串是不可以进行编码的，比如包含html语句的(换行等)。\n第三种方法：设置中间变量，所有用户输入的字符串都必须赋给以us开头的变量，所有已知安全的字符串和包含html的字符换，都赋给s开头的变量。\n![judge code](/img/judge_code.jpg)\n\n* 把相同的代码放在一起\n把相同的代码尽量放到一起，将有助于帮你发现你程序的错误。比如：`i = j*5` c语言可以一眼看出这句代码的意思，但是c++中必须要考虑到i和j的数据类型，以防进行了运算符重载，还要考虑继承和多态的问题。所以在c++中这样抽象不是好的行为\n\n# 开办软件公司\n软件个体户\n乔尔创建Fog Creek的真正目的：那就是创造一家我们愿意为之工作的软件公司。\n优秀的程序员和平庸的程序员差距非常大。\n\n# 经营软件公司\n* 仿生学办公室\n* 他山之石，不可攻玉\n* 简化性\n* 揉一揉，搓一搓\n* 组织beta测试的十二个最高秘诀\n* 建立优质客户服务的7个步骤\n>1.每件事都有两种做法：a.表面的、快速的解决方法;b.思考、防止类似的问题再次发生\n2.建议吹掉灰尘：客户忘记插好接口，可以以其他委婉的方式提醒客户\n3.让客户迷上你\n4.承受责备\n5.学会说软话\n6.学会做木偶\n7.贪婪让你一无所获\n\n# 发布软件\n* 挑选发布日期\n>1.确定发布日期，这个日期可以根据可观情况也可根据主管愿望进行选择\n2.列出软件要实现的功能，然后按照优先级排序\n3.每当你落后于预定进度时，就把排在最后的功能砍掉\n\n* 如何为软件定价：招无定式\n\n# 修订软件\n* 五个为什么\n* 确定优先顺序\n\n\n","source":"_posts/more-joel-on-software.md","raw":"---\ntitle: 软件随想录-卷2\ndate: 2017-02-20 17:36:29\ntags: 随笔\n---\n\njoel Spolsky著 阮一峰译  \n[Gitbook 电子书](https://wizardforcel.gitbooks.io/joel-on-software/content/index.html  \"软件随想录\")\n\n# 寻找优秀程序员的三种办法\n>社招(简历)不靠谱，员工推荐不太靠谱\n走出去，参加开发者大会\n找实习生。\n创造自己的知名社区网站。\n\n# 写给程序员的建议\n任何时刻不要想着推倒重来，重构而不是重新做一遍\n不添加任何新功能\n无论任何时刻向源码库添加代码，都要保证程序能够正常运行\n所要做的只是一些合乎逻辑的变换，几乎都是机械性的，而且能够立刻确定不会改变代码行为\n并不是每个人都适合当程序员\n\n<!-- more -->\n\n# 为什么做一个内部程序员就槽糕透了呢\n1. 你永远无法用正确的事情做事情，总是被迫用最保险的方法做事。\n2. 一旦你的程序可以用了，你就不得不停止项目，转而开发其他项目。\n3. 如果你在专业的软件公司中编程，你的工作与公司的主营业务是直接相关，是能够为公司直接带来收入的，这至少意味着一件事情，就是管理层会想到你。\n\n# 程序员管理的三种方法\n| 方法   | 说明 |  缺点   |\n| :-------: | :----: | :---: |\n| 军事化管理法 | 军队可以让士兵绝对服从命令 |  1.会使团队人员不爽 2.不可能管理到所有细节 3.对于技术问题，程序员才是做决策的最佳人选，因为他们知道更多的技术细节。    |\n| 经济利益驱动法 | 假设每个人的行为动机都是钱| 1.会降低团队人员的内部驱动力，当你停止付钱或者他们不再需要钱，他们的驱动力就会消失。2.员工会追求局部利益最大化，最终为了自己的利益可能做出对公司不好的行为。3.会鼓励员工与制度博弈，寻找制度的缺失之处来为自己谋利。经济利益驱动法更像是管理的退位，表面上简化了管理，但实际上却是管理的缺失。   |\n| 认同法     | 方法：1.培养认同感。设定积极的目标和价值观。2.培养凝聚力和归属感。团队的人要一起吃饭，多组织集体活动。3.信息共享。和员工要做到信息共享，以便员工更好的工作。  |  实施起来不容易。|\n\n推荐做法：***认同法***\n\n# 设计的作用\n> 字体平滑、反锯齿和次像素渲染\n苹果公司的设计有利于频幕界面和印刷一致\n微软公司的设计有利于屏幕阅读\n苹果的字体放到微软的系统上面会有一点模糊，比如在mac上面装windows系统，字体会变模糊。 \n寸土必争\n随便找一个东西，如果你找不到它的缺点，那就说明你的转型还没有成功。\n大构想的陷阱\n阅读的时候，眼镜只会盯住一个点，而其它地方像素很低，但是由于眼镜的注意力快速移动，让你产生了你已经看到了所有细节的错觉。软件设计中，你以为你可以做出来，看上去大体流程很清楚，但是一旦你考虑细节的时候你才会知道，你少考虑了很多东西。\n\n# 别让用户做太多选择   \n微软的关机选项有7种，再加上电源键(点击和长按)或者一些电脑上有快捷键关机或者重启，合下屏幕也可以睡眠或者关机。这样给用户的选择就有10种左右，而过多的选择会让用户产生选择困难而失去幸福感。\n如何改进？\n>Switch User之前肯定要Lock，这两个按钮可以合并。\nLog Off就是为了退出当前运行的所有程序，可以和ShutDown按钮合并。\nRestart和shutdown是一样的，只需要按两次shutdown按钮即可(假设关机速度很快，而且不是远程操控(一般远程操控是命令行操作))\nSleep和Hibernate说实话我不太懂他们的区别。\n现在我们只剩下 switch user/lock     log off/shutdown     hibernate/sleep三个按钮。\n考虑switch user/lock     hibernate/sleep这两个按钮的合并，当我按下这一个复合按钮的时候，会弹出一个切换用户的对话框，然后30秒内没有切换用户会进入休眠状态，而这个过程中计算机是一直锁定的。\n现在计算机只剩两个按钮了，就是这两种状态：\n1、我要离开电脑一会儿\n2、我要离开电脑很久，需要拔下电源   \n现在考虑能不能合并这两个按钮，现在的电源管理系统已经能够做到你在睡眠状态下不关闭电脑也只耗很低的电源，即使你拔掉电源也能够保存你的数据，不会损失你的任何数据，所以这两个按钮完全可以合并。\n\n# 管理大型项目\n火星人的耳机：这一部分主要讲述了为什么现在的web标准如此复杂。\n>* 一对多模式：假设你在火星上发现火星人还在使用录音机，你发现了商机，你决定卖mp3给他们，为此你要制造一种耳机，于是你写了一份规格书，让其他厂商制造耳机，但是你的规格书里误写了电压的参数，结果厂商做出来的耳机总是爆炸，然后经过调整声音的赫兹终于能正常使用了，就这样你让火星人大量买了你的耳机，然后你想让你的耳机拥有打电话的功能，就是加一个麦克风，然后你重新设计了一个适配器，这个适配器考虑了以后的升级问题，但是推出以后火星人根本没人买，他们只在乎家里收藏了一衣柜的耳机，根本不在乎什么麦克风功能。然后你只有在耳机的接口处扩展功能，把耳机的金属轴接口分成三份，其中一份可以用来做麦克风功能，你又设计了一份协议，在接口处发射一个信号，当mp3找到这个信号的时候，就开启麦克风模式，否则就开启向后兼容的耳机模式，现在，整个市场就变成了一对多模式，同一个耳机有多个版本了。  \n\n\n>* 多对多模式：由于你不停的给mp3增加功能，每个生产耳机的厂商都要把耳机在每一个mp3型号测试一遍，由于规格书的繁琐难读，有些产品出现了不兼容的现象，然后为了降低成本，厂商不得不只让耳机适配最流行的mp3播放器，这样，当耳机插入其他mp3的时候，会播放不出来或者更严重的会爆炸。原因是规格书有一个功能写得不清楚，比如，如果下雨，电压会升高，如果不下雨，电压不变。但是关于下雪，规格书没有讲，有的地方把下雪当成了下雨的一种，原因是都要用到雨刮器。有的地方从不下雪，所以就不是下雨。\n\n\n>* 然后有一个无聊的家伙，发表了一篇文章，利用漏洞可以解决兼容问题，比如用程序把下雪也误判成下雨，于是市场上就出现了多个版本的耳机和mp3，这就是多对多。\n\n微软的ie8就是类似上面的流程\n* 为什么微软office的文件格式如此复杂\n* 要挣钱就别嫌脏\n\n# 编程建议\n* 询证式日程规划\n完后速率 = 估计用时/实际用时\n蒙特卡洛方法估计值：\n![about time](/img/about_time.jpg )\n* 让错误的代码显而易见\n网站中，用户输入的字符串必须经过编码后才能使用，否则有可能会受到攻击。\n怎样才能尽量避免这种出错方式呢？\n>第一种办法：当用户的数据一传进来，就对数据进行编码。但是当需要直接存到数据库的时候实际上是要存储原来的字符的，所以不行。\n第二种办法：制定一种规范，只有输出字符串的时候才进行编码，但是有个问题，有些要输出的字符串是不可以进行编码的，比如包含html语句的(换行等)。\n第三种方法：设置中间变量，所有用户输入的字符串都必须赋给以us开头的变量，所有已知安全的字符串和包含html的字符换，都赋给s开头的变量。\n![judge code](/img/judge_code.jpg)\n\n* 把相同的代码放在一起\n把相同的代码尽量放到一起，将有助于帮你发现你程序的错误。比如：`i = j*5` c语言可以一眼看出这句代码的意思，但是c++中必须要考虑到i和j的数据类型，以防进行了运算符重载，还要考虑继承和多态的问题。所以在c++中这样抽象不是好的行为\n\n# 开办软件公司\n软件个体户\n乔尔创建Fog Creek的真正目的：那就是创造一家我们愿意为之工作的软件公司。\n优秀的程序员和平庸的程序员差距非常大。\n\n# 经营软件公司\n* 仿生学办公室\n* 他山之石，不可攻玉\n* 简化性\n* 揉一揉，搓一搓\n* 组织beta测试的十二个最高秘诀\n* 建立优质客户服务的7个步骤\n>1.每件事都有两种做法：a.表面的、快速的解决方法;b.思考、防止类似的问题再次发生\n2.建议吹掉灰尘：客户忘记插好接口，可以以其他委婉的方式提醒客户\n3.让客户迷上你\n4.承受责备\n5.学会说软话\n6.学会做木偶\n7.贪婪让你一无所获\n\n# 发布软件\n* 挑选发布日期\n>1.确定发布日期，这个日期可以根据可观情况也可根据主管愿望进行选择\n2.列出软件要实现的功能，然后按照优先级排序\n3.每当你落后于预定进度时，就把排在最后的功能砍掉\n\n* 如何为软件定价：招无定式\n\n# 修订软件\n* 五个为什么\n* 确定优先顺序\n\n\n","slug":"more-joel-on-software","published":1,"updated":"2018-04-27T04:11:03.361Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczov000qe4rws0y5ozjl","content":"<p>joel Spolsky著 阮一峰译<br><a href=\"https://wizardforcel.gitbooks.io/joel-on-software/content/index.html\" title=\"软件随想录\" target=\"_blank\" rel=\"external\">Gitbook 电子书</a></p>\n<h1 id=\"寻找优秀程序员的三种办法\"><a href=\"#寻找优秀程序员的三种办法\" class=\"headerlink\" title=\"寻找优秀程序员的三种办法\"></a>寻找优秀程序员的三种办法</h1><blockquote>\n<p>社招(简历)不靠谱，员工推荐不太靠谱<br>走出去，参加开发者大会<br>找实习生。<br>创造自己的知名社区网站。</p>\n</blockquote>\n<h1 id=\"写给程序员的建议\"><a href=\"#写给程序员的建议\" class=\"headerlink\" title=\"写给程序员的建议\"></a>写给程序员的建议</h1><p>任何时刻不要想着推倒重来，重构而不是重新做一遍<br>不添加任何新功能<br>无论任何时刻向源码库添加代码，都要保证程序能够正常运行<br>所要做的只是一些合乎逻辑的变换，几乎都是机械性的，而且能够立刻确定不会改变代码行为<br>并不是每个人都适合当程序员</p>\n<a id=\"more\"></a>\n<h1 id=\"为什么做一个内部程序员就槽糕透了呢\"><a href=\"#为什么做一个内部程序员就槽糕透了呢\" class=\"headerlink\" title=\"为什么做一个内部程序员就槽糕透了呢\"></a>为什么做一个内部程序员就槽糕透了呢</h1><ol>\n<li>你永远无法用正确的事情做事情，总是被迫用最保险的方法做事。</li>\n<li>一旦你的程序可以用了，你就不得不停止项目，转而开发其他项目。</li>\n<li>如果你在专业的软件公司中编程，你的工作与公司的主营业务是直接相关，是能够为公司直接带来收入的，这至少意味着一件事情，就是管理层会想到你。</li>\n</ol>\n<h1 id=\"程序员管理的三种方法\"><a href=\"#程序员管理的三种方法\" class=\"headerlink\" title=\"程序员管理的三种方法\"></a>程序员管理的三种方法</h1><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">方法</th>\n<th style=\"text-align:center\">说明</th>\n<th style=\"text-align:center\">缺点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">军事化管理法</td>\n<td style=\"text-align:center\">军队可以让士兵绝对服从命令</td>\n<td style=\"text-align:center\">1.会使团队人员不爽 2.不可能管理到所有细节 3.对于技术问题，程序员才是做决策的最佳人选，因为他们知道更多的技术细节。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">经济利益驱动法</td>\n<td style=\"text-align:center\">假设每个人的行为动机都是钱</td>\n<td style=\"text-align:center\">1.会降低团队人员的内部驱动力，当你停止付钱或者他们不再需要钱，他们的驱动力就会消失。2.员工会追求局部利益最大化，最终为了自己的利益可能做出对公司不好的行为。3.会鼓励员工与制度博弈，寻找制度的缺失之处来为自己谋利。经济利益驱动法更像是管理的退位，表面上简化了管理，但实际上却是管理的缺失。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">认同法</td>\n<td style=\"text-align:center\">方法：1.培养认同感。设定积极的目标和价值观。2.培养凝聚力和归属感。团队的人要一起吃饭，多组织集体活动。3.信息共享。和员工要做到信息共享，以便员工更好的工作。</td>\n<td style=\"text-align:center\">实施起来不容易。</td>\n</tr>\n</tbody>\n</table>\n<p>推荐做法：<strong><em>认同法</em></strong></p>\n<h1 id=\"设计的作用\"><a href=\"#设计的作用\" class=\"headerlink\" title=\"设计的作用\"></a>设计的作用</h1><blockquote>\n<p>字体平滑、反锯齿和次像素渲染<br>苹果公司的设计有利于频幕界面和印刷一致<br>微软公司的设计有利于屏幕阅读<br>苹果的字体放到微软的系统上面会有一点模糊，比如在mac上面装windows系统，字体会变模糊。<br>寸土必争<br>随便找一个东西，如果你找不到它的缺点，那就说明你的转型还没有成功。<br>大构想的陷阱<br>阅读的时候，眼镜只会盯住一个点，而其它地方像素很低，但是由于眼镜的注意力快速移动，让你产生了你已经看到了所有细节的错觉。软件设计中，你以为你可以做出来，看上去大体流程很清楚，但是一旦你考虑细节的时候你才会知道，你少考虑了很多东西。</p>\n</blockquote>\n<h1 id=\"别让用户做太多选择\"><a href=\"#别让用户做太多选择\" class=\"headerlink\" title=\"别让用户做太多选择\"></a>别让用户做太多选择</h1><p>微软的关机选项有7种，再加上电源键(点击和长按)或者一些电脑上有快捷键关机或者重启，合下屏幕也可以睡眠或者关机。这样给用户的选择就有10种左右，而过多的选择会让用户产生选择困难而失去幸福感。<br>如何改进？</p>\n<blockquote>\n<p>Switch User之前肯定要Lock，这两个按钮可以合并。<br>Log Off就是为了退出当前运行的所有程序，可以和ShutDown按钮合并。<br>Restart和shutdown是一样的，只需要按两次shutdown按钮即可(假设关机速度很快，而且不是远程操控(一般远程操控是命令行操作))<br>Sleep和Hibernate说实话我不太懂他们的区别。<br>现在我们只剩下 switch user/lock     log off/shutdown     hibernate/sleep三个按钮。<br>考虑switch user/lock     hibernate/sleep这两个按钮的合并，当我按下这一个复合按钮的时候，会弹出一个切换用户的对话框，然后30秒内没有切换用户会进入休眠状态，而这个过程中计算机是一直锁定的。<br>现在计算机只剩两个按钮了，就是这两种状态：<br>1、我要离开电脑一会儿<br>2、我要离开电脑很久，需要拔下电源<br>现在考虑能不能合并这两个按钮，现在的电源管理系统已经能够做到你在睡眠状态下不关闭电脑也只耗很低的电源，即使你拔掉电源也能够保存你的数据，不会损失你的任何数据，所以这两个按钮完全可以合并。</p>\n</blockquote>\n<h1 id=\"管理大型项目\"><a href=\"#管理大型项目\" class=\"headerlink\" title=\"管理大型项目\"></a>管理大型项目</h1><p>火星人的耳机：这一部分主要讲述了为什么现在的web标准如此复杂。</p>\n<blockquote>\n<ul>\n<li>一对多模式：假设你在火星上发现火星人还在使用录音机，你发现了商机，你决定卖mp3给他们，为此你要制造一种耳机，于是你写了一份规格书，让其他厂商制造耳机，但是你的规格书里误写了电压的参数，结果厂商做出来的耳机总是爆炸，然后经过调整声音的赫兹终于能正常使用了，就这样你让火星人大量买了你的耳机，然后你想让你的耳机拥有打电话的功能，就是加一个麦克风，然后你重新设计了一个适配器，这个适配器考虑了以后的升级问题，但是推出以后火星人根本没人买，他们只在乎家里收藏了一衣柜的耳机，根本不在乎什么麦克风功能。然后你只有在耳机的接口处扩展功能，把耳机的金属轴接口分成三份，其中一份可以用来做麦克风功能，你又设计了一份协议，在接口处发射一个信号，当mp3找到这个信号的时候，就开启麦克风模式，否则就开启向后兼容的耳机模式，现在，整个市场就变成了一对多模式，同一个耳机有多个版本了。  </li>\n</ul>\n<ul>\n<li>多对多模式：由于你不停的给mp3增加功能，每个生产耳机的厂商都要把耳机在每一个mp3型号测试一遍，由于规格书的繁琐难读，有些产品出现了不兼容的现象，然后为了降低成本，厂商不得不只让耳机适配最流行的mp3播放器，这样，当耳机插入其他mp3的时候，会播放不出来或者更严重的会爆炸。原因是规格书有一个功能写得不清楚，比如，如果下雨，电压会升高，如果不下雨，电压不变。但是关于下雪，规格书没有讲，有的地方把下雪当成了下雨的一种，原因是都要用到雨刮器。有的地方从不下雪，所以就不是下雨。</li>\n</ul>\n<ul>\n<li>然后有一个无聊的家伙，发表了一篇文章，利用漏洞可以解决兼容问题，比如用程序把下雪也误判成下雨，于是市场上就出现了多个版本的耳机和mp3，这就是多对多。</li>\n</ul>\n</blockquote>\n<p>微软的ie8就是类似上面的流程</p>\n<ul>\n<li>为什么微软office的文件格式如此复杂</li>\n<li>要挣钱就别嫌脏</li>\n</ul>\n<h1 id=\"编程建议\"><a href=\"#编程建议\" class=\"headerlink\" title=\"编程建议\"></a>编程建议</h1><ul>\n<li>询证式日程规划<br>完后速率 = 估计用时/实际用时<br>蒙特卡洛方法估计值：<br><img src=\"/img/about_time.jpg\" alt=\"about time\"></li>\n<li><p>让错误的代码显而易见<br>网站中，用户输入的字符串必须经过编码后才能使用，否则有可能会受到攻击。<br>怎样才能尽量避免这种出错方式呢？</p>\n<blockquote>\n<p>第一种办法：当用户的数据一传进来，就对数据进行编码。但是当需要直接存到数据库的时候实际上是要存储原来的字符的，所以不行。<br>第二种办法：制定一种规范，只有输出字符串的时候才进行编码，但是有个问题，有些要输出的字符串是不可以进行编码的，比如包含html语句的(换行等)。<br>第三种方法：设置中间变量，所有用户输入的字符串都必须赋给以us开头的变量，所有已知安全的字符串和包含html的字符换，都赋给s开头的变量。<br><img src=\"/img/judge_code.jpg\" alt=\"judge code\"></p>\n</blockquote>\n</li>\n<li><p>把相同的代码放在一起<br>把相同的代码尽量放到一起，将有助于帮你发现你程序的错误。比如：<code>i = j*5</code> c语言可以一眼看出这句代码的意思，但是c++中必须要考虑到i和j的数据类型，以防进行了运算符重载，还要考虑继承和多态的问题。所以在c++中这样抽象不是好的行为</p>\n</li>\n</ul>\n<h1 id=\"开办软件公司\"><a href=\"#开办软件公司\" class=\"headerlink\" title=\"开办软件公司\"></a>开办软件公司</h1><p>软件个体户<br>乔尔创建Fog Creek的真正目的：那就是创造一家我们愿意为之工作的软件公司。<br>优秀的程序员和平庸的程序员差距非常大。</p>\n<h1 id=\"经营软件公司\"><a href=\"#经营软件公司\" class=\"headerlink\" title=\"经营软件公司\"></a>经营软件公司</h1><ul>\n<li>仿生学办公室</li>\n<li>他山之石，不可攻玉</li>\n<li>简化性</li>\n<li>揉一揉，搓一搓</li>\n<li>组织beta测试的十二个最高秘诀</li>\n<li>建立优质客户服务的7个步骤<blockquote>\n<p>1.每件事都有两种做法：a.表面的、快速的解决方法;b.思考、防止类似的问题再次发生<br>2.建议吹掉灰尘：客户忘记插好接口，可以以其他委婉的方式提醒客户<br>3.让客户迷上你<br>4.承受责备<br>5.学会说软话<br>6.学会做木偶<br>7.贪婪让你一无所获</p>\n</blockquote>\n</li>\n</ul>\n<h1 id=\"发布软件\"><a href=\"#发布软件\" class=\"headerlink\" title=\"发布软件\"></a>发布软件</h1><ul>\n<li><p>挑选发布日期</p>\n<blockquote>\n<p>1.确定发布日期，这个日期可以根据可观情况也可根据主管愿望进行选择<br>2.列出软件要实现的功能，然后按照优先级排序<br>3.每当你落后于预定进度时，就把排在最后的功能砍掉</p>\n</blockquote>\n</li>\n<li><p>如何为软件定价：招无定式</p>\n</li>\n</ul>\n<h1 id=\"修订软件\"><a href=\"#修订软件\" class=\"headerlink\" title=\"修订软件\"></a>修订软件</h1><ul>\n<li>五个为什么</li>\n<li>确定优先顺序</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>joel Spolsky著 阮一峰译<br><a href=\"https://wizardforcel.gitbooks.io/joel-on-software/content/index.html\" title=\"软件随想录\" target=\"_blank\" rel=\"external\">Gitbook 电子书</a></p>\n<h1 id=\"寻找优秀程序员的三种办法\"><a href=\"#寻找优秀程序员的三种办法\" class=\"headerlink\" title=\"寻找优秀程序员的三种办法\"></a>寻找优秀程序员的三种办法</h1><blockquote>\n<p>社招(简历)不靠谱，员工推荐不太靠谱<br>走出去，参加开发者大会<br>找实习生。<br>创造自己的知名社区网站。</p>\n</blockquote>\n<h1 id=\"写给程序员的建议\"><a href=\"#写给程序员的建议\" class=\"headerlink\" title=\"写给程序员的建议\"></a>写给程序员的建议</h1><p>任何时刻不要想着推倒重来，重构而不是重新做一遍<br>不添加任何新功能<br>无论任何时刻向源码库添加代码，都要保证程序能够正常运行<br>所要做的只是一些合乎逻辑的变换，几乎都是机械性的，而且能够立刻确定不会改变代码行为<br>并不是每个人都适合当程序员</p>","more":"<h1 id=\"为什么做一个内部程序员就槽糕透了呢\"><a href=\"#为什么做一个内部程序员就槽糕透了呢\" class=\"headerlink\" title=\"为什么做一个内部程序员就槽糕透了呢\"></a>为什么做一个内部程序员就槽糕透了呢</h1><ol>\n<li>你永远无法用正确的事情做事情，总是被迫用最保险的方法做事。</li>\n<li>一旦你的程序可以用了，你就不得不停止项目，转而开发其他项目。</li>\n<li>如果你在专业的软件公司中编程，你的工作与公司的主营业务是直接相关，是能够为公司直接带来收入的，这至少意味着一件事情，就是管理层会想到你。</li>\n</ol>\n<h1 id=\"程序员管理的三种方法\"><a href=\"#程序员管理的三种方法\" class=\"headerlink\" title=\"程序员管理的三种方法\"></a>程序员管理的三种方法</h1><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">方法</th>\n<th style=\"text-align:center\">说明</th>\n<th style=\"text-align:center\">缺点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">军事化管理法</td>\n<td style=\"text-align:center\">军队可以让士兵绝对服从命令</td>\n<td style=\"text-align:center\">1.会使团队人员不爽 2.不可能管理到所有细节 3.对于技术问题，程序员才是做决策的最佳人选，因为他们知道更多的技术细节。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">经济利益驱动法</td>\n<td style=\"text-align:center\">假设每个人的行为动机都是钱</td>\n<td style=\"text-align:center\">1.会降低团队人员的内部驱动力，当你停止付钱或者他们不再需要钱，他们的驱动力就会消失。2.员工会追求局部利益最大化，最终为了自己的利益可能做出对公司不好的行为。3.会鼓励员工与制度博弈，寻找制度的缺失之处来为自己谋利。经济利益驱动法更像是管理的退位，表面上简化了管理，但实际上却是管理的缺失。</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">认同法</td>\n<td style=\"text-align:center\">方法：1.培养认同感。设定积极的目标和价值观。2.培养凝聚力和归属感。团队的人要一起吃饭，多组织集体活动。3.信息共享。和员工要做到信息共享，以便员工更好的工作。</td>\n<td style=\"text-align:center\">实施起来不容易。</td>\n</tr>\n</tbody>\n</table>\n<p>推荐做法：<strong><em>认同法</em></strong></p>\n<h1 id=\"设计的作用\"><a href=\"#设计的作用\" class=\"headerlink\" title=\"设计的作用\"></a>设计的作用</h1><blockquote>\n<p>字体平滑、反锯齿和次像素渲染<br>苹果公司的设计有利于频幕界面和印刷一致<br>微软公司的设计有利于屏幕阅读<br>苹果的字体放到微软的系统上面会有一点模糊，比如在mac上面装windows系统，字体会变模糊。<br>寸土必争<br>随便找一个东西，如果你找不到它的缺点，那就说明你的转型还没有成功。<br>大构想的陷阱<br>阅读的时候，眼镜只会盯住一个点，而其它地方像素很低，但是由于眼镜的注意力快速移动，让你产生了你已经看到了所有细节的错觉。软件设计中，你以为你可以做出来，看上去大体流程很清楚，但是一旦你考虑细节的时候你才会知道，你少考虑了很多东西。</p>\n</blockquote>\n<h1 id=\"别让用户做太多选择\"><a href=\"#别让用户做太多选择\" class=\"headerlink\" title=\"别让用户做太多选择\"></a>别让用户做太多选择</h1><p>微软的关机选项有7种，再加上电源键(点击和长按)或者一些电脑上有快捷键关机或者重启，合下屏幕也可以睡眠或者关机。这样给用户的选择就有10种左右，而过多的选择会让用户产生选择困难而失去幸福感。<br>如何改进？</p>\n<blockquote>\n<p>Switch User之前肯定要Lock，这两个按钮可以合并。<br>Log Off就是为了退出当前运行的所有程序，可以和ShutDown按钮合并。<br>Restart和shutdown是一样的，只需要按两次shutdown按钮即可(假设关机速度很快，而且不是远程操控(一般远程操控是命令行操作))<br>Sleep和Hibernate说实话我不太懂他们的区别。<br>现在我们只剩下 switch user/lock     log off/shutdown     hibernate/sleep三个按钮。<br>考虑switch user/lock     hibernate/sleep这两个按钮的合并，当我按下这一个复合按钮的时候，会弹出一个切换用户的对话框，然后30秒内没有切换用户会进入休眠状态，而这个过程中计算机是一直锁定的。<br>现在计算机只剩两个按钮了，就是这两种状态：<br>1、我要离开电脑一会儿<br>2、我要离开电脑很久，需要拔下电源<br>现在考虑能不能合并这两个按钮，现在的电源管理系统已经能够做到你在睡眠状态下不关闭电脑也只耗很低的电源，即使你拔掉电源也能够保存你的数据，不会损失你的任何数据，所以这两个按钮完全可以合并。</p>\n</blockquote>\n<h1 id=\"管理大型项目\"><a href=\"#管理大型项目\" class=\"headerlink\" title=\"管理大型项目\"></a>管理大型项目</h1><p>火星人的耳机：这一部分主要讲述了为什么现在的web标准如此复杂。</p>\n<blockquote>\n<ul>\n<li>一对多模式：假设你在火星上发现火星人还在使用录音机，你发现了商机，你决定卖mp3给他们，为此你要制造一种耳机，于是你写了一份规格书，让其他厂商制造耳机，但是你的规格书里误写了电压的参数，结果厂商做出来的耳机总是爆炸，然后经过调整声音的赫兹终于能正常使用了，就这样你让火星人大量买了你的耳机，然后你想让你的耳机拥有打电话的功能，就是加一个麦克风，然后你重新设计了一个适配器，这个适配器考虑了以后的升级问题，但是推出以后火星人根本没人买，他们只在乎家里收藏了一衣柜的耳机，根本不在乎什么麦克风功能。然后你只有在耳机的接口处扩展功能，把耳机的金属轴接口分成三份，其中一份可以用来做麦克风功能，你又设计了一份协议，在接口处发射一个信号，当mp3找到这个信号的时候，就开启麦克风模式，否则就开启向后兼容的耳机模式，现在，整个市场就变成了一对多模式，同一个耳机有多个版本了。  </li>\n</ul>\n<ul>\n<li>多对多模式：由于你不停的给mp3增加功能，每个生产耳机的厂商都要把耳机在每一个mp3型号测试一遍，由于规格书的繁琐难读，有些产品出现了不兼容的现象，然后为了降低成本，厂商不得不只让耳机适配最流行的mp3播放器，这样，当耳机插入其他mp3的时候，会播放不出来或者更严重的会爆炸。原因是规格书有一个功能写得不清楚，比如，如果下雨，电压会升高，如果不下雨，电压不变。但是关于下雪，规格书没有讲，有的地方把下雪当成了下雨的一种，原因是都要用到雨刮器。有的地方从不下雪，所以就不是下雨。</li>\n</ul>\n<ul>\n<li>然后有一个无聊的家伙，发表了一篇文章，利用漏洞可以解决兼容问题，比如用程序把下雪也误判成下雨，于是市场上就出现了多个版本的耳机和mp3，这就是多对多。</li>\n</ul>\n</blockquote>\n<p>微软的ie8就是类似上面的流程</p>\n<ul>\n<li>为什么微软office的文件格式如此复杂</li>\n<li>要挣钱就别嫌脏</li>\n</ul>\n<h1 id=\"编程建议\"><a href=\"#编程建议\" class=\"headerlink\" title=\"编程建议\"></a>编程建议</h1><ul>\n<li>询证式日程规划<br>完后速率 = 估计用时/实际用时<br>蒙特卡洛方法估计值：<br><img src=\"/img/about_time.jpg\" alt=\"about time\"></li>\n<li><p>让错误的代码显而易见<br>网站中，用户输入的字符串必须经过编码后才能使用，否则有可能会受到攻击。<br>怎样才能尽量避免这种出错方式呢？</p>\n<blockquote>\n<p>第一种办法：当用户的数据一传进来，就对数据进行编码。但是当需要直接存到数据库的时候实际上是要存储原来的字符的，所以不行。<br>第二种办法：制定一种规范，只有输出字符串的时候才进行编码，但是有个问题，有些要输出的字符串是不可以进行编码的，比如包含html语句的(换行等)。<br>第三种方法：设置中间变量，所有用户输入的字符串都必须赋给以us开头的变量，所有已知安全的字符串和包含html的字符换，都赋给s开头的变量。<br><img src=\"/img/judge_code.jpg\" alt=\"judge code\"></p>\n</blockquote>\n</li>\n<li><p>把相同的代码放在一起<br>把相同的代码尽量放到一起，将有助于帮你发现你程序的错误。比如：<code>i = j*5</code> c语言可以一眼看出这句代码的意思，但是c++中必须要考虑到i和j的数据类型，以防进行了运算符重载，还要考虑继承和多态的问题。所以在c++中这样抽象不是好的行为</p>\n</li>\n</ul>\n<h1 id=\"开办软件公司\"><a href=\"#开办软件公司\" class=\"headerlink\" title=\"开办软件公司\"></a>开办软件公司</h1><p>软件个体户<br>乔尔创建Fog Creek的真正目的：那就是创造一家我们愿意为之工作的软件公司。<br>优秀的程序员和平庸的程序员差距非常大。</p>\n<h1 id=\"经营软件公司\"><a href=\"#经营软件公司\" class=\"headerlink\" title=\"经营软件公司\"></a>经营软件公司</h1><ul>\n<li>仿生学办公室</li>\n<li>他山之石，不可攻玉</li>\n<li>简化性</li>\n<li>揉一揉，搓一搓</li>\n<li>组织beta测试的十二个最高秘诀</li>\n<li>建立优质客户服务的7个步骤<blockquote>\n<p>1.每件事都有两种做法：a.表面的、快速的解决方法;b.思考、防止类似的问题再次发生<br>2.建议吹掉灰尘：客户忘记插好接口，可以以其他委婉的方式提醒客户<br>3.让客户迷上你<br>4.承受责备<br>5.学会说软话<br>6.学会做木偶<br>7.贪婪让你一无所获</p>\n</blockquote>\n</li>\n</ul>\n<h1 id=\"发布软件\"><a href=\"#发布软件\" class=\"headerlink\" title=\"发布软件\"></a>发布软件</h1><ul>\n<li><p>挑选发布日期</p>\n<blockquote>\n<p>1.确定发布日期，这个日期可以根据可观情况也可根据主管愿望进行选择<br>2.列出软件要实现的功能，然后按照优先级排序<br>3.每当你落后于预定进度时，就把排在最后的功能砍掉</p>\n</blockquote>\n</li>\n<li><p>如何为软件定价：招无定式</p>\n</li>\n</ul>\n<h1 id=\"修订软件\"><a href=\"#修订软件\" class=\"headerlink\" title=\"修订软件\"></a>修订软件</h1><ul>\n<li>五个为什么</li>\n<li>确定优先顺序</li>\n</ul>"},{"title":"Open-falcon 监控体系介绍","date":"2018-04-27T04:51:34.000Z","_content":"\n## 1.Openfalcon安装部署\n\n### 简介\n\n[官方文档 v2.0](https://book.open-falcon.org/zh_0_2/intro/)\n\n- 强大灵活的数据采集：自动发现，支持falcon-agent、snmp、支持用户主动push、用户自定义插件支持、opentsdb data model like（timestamp、endpoint、metric、key-value tags）\n- 水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询\n- 高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用\n- 人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期\n- 高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）\n- 高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据\n- dashboard：多维度的数据展示，用户自定义Screen\n- 高可用：整个系统无核心单点，易运维，易部署，可水平扩展\n- 开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。\n\n### 框架\n\n![func_tro](/img/openfalcon-func.png)\n\n\n\n<!-- more -->\n\n### 后端安装(docker)\n\n/opt/openfalcon/falcon-plus\n\n[官方教程](https://github.com/open-falcon/falcon-plus/blob/master/docker/README.md)\n\n```shell\n## Running falcon-plus container\n\n    docker pull openfalcon/falcon-plus:0.2.0\n    docker run -itd -p 8081:8081 openfalcon/falcon-plus:0.2.0 bash /run.sh hbs\n\n## Running falcon-plus container with docker-compose\n\n    docker-compose -f init.yml up -d falcon-plus\n\n## Running mysql and redis container\n\n    docker-compose -f init.yml up -d mysql redis\n\n## Stop and Remove containers\n\n    docker-compose -f init.yml rm -f\n```\n\ninit.yml\n\n```yaml\nversion: '2'\nservices:\n  mysql:\n    environment:\n    - MYSQL_ROOT_PASSWORD=password\n    extends:\n      file: common.yml\n      service: template\n    hostname: docker-mysql\n    image: mysql:5.7\n    labels:\n      owl: mysql\n    ports:\n    - 3306:3306\n    restart: always\n    volumes:\n    - ../scripts/mysql/db_schema:/docker-entrypoint-initdb.d\n    - ./mysql.cnf:/etc/mysql/conf.d/mysql.cnf:ro\n  redis:\n    command: redis-server /redis.conf\n    extends:\n      file: common.yml\n      service: template-backend\n    hostname: docker-redis\n    image: redis:3.0\n    labels:\n      owl: redis\n    ports:\n    - 6379:6379\n    restart: always\n    volumes:\n    - ./redis.conf:/redis.conf\n  falcon-plus:\n    command: bash /run.sh hbs\n    image: openfalcon/falcon-plus:0.2.0\n    ports:\n    - 8081:8081\n    restart: always\n```\n\n**注意**  需要打包mysql初始化脚本到这个路径下```../scripts/mysql/db_schema``` ，具体文件[在这里](https://github.com/open-falcon/falcon-plus/tree/master/scripts/mysql/db_schema)\n\nmysql登陆\n\n```\n#默认mysql密码  password\ndocker exec -it <容器id> mysql -p \n```\n\nweb 登陆 http://192.168.14.165:8081   新建用户\n\n![web](/img/openfalcon-web.png)\n\n### 前端安装(docker)\n\n/opt/openfalcon/dashboard\n\n[官方教程](https://github.com/open-falcon/dashboard/blob/master/README.md)\n\n```shell\n# make the image，run commands under dir of dashboard:\ndocker build -t falcon-dashboard:v1.0 .\n\n# start the container\ndocker run -itd --name aaa --net host \\\n\t-e API_ADDR=http://127.0.0.1:8080/api/v1 \\\n\t-e PORTAL_DB_HOST=127.0.0.1 \\\n\t-e PORTAL_DB_PORT=3306 \\\n\t-e PORTAL_DB_USER=root \\\n\t-e PORTAL_DB_PASS=123456 \\\n\t-e PORTAL_DB_NAME=falcon_portal \\\n\t-e ALARM_DB_PASS=123456 \\\n\t-e ALARM_DB_HOST=127.0.0.1 \\\n\t-e ALARM_DB_PORT=3306 \\\n\t-e ALARM_DB_USER=root \\\n\t-e ALARM_DB_PASS=123456 \\\n\t-e ALARM_DB_NAME=alarms \\\n\tfalcon-dashboard:v1.0\n```\n\nDockerfile\n\n```\nFROM centos:7.3.1611\n\nRUN yum clean all && yum install -y epel-release && yum -y update && \\\nyum install -y git python-virtualenv python-devel openldap-devel mysql-devel && \\\nyum groupinstall -y \"Development tools\"\n\nRUN export HOME=/home/work/ && mkdir -p $HOME/open-falcon/dashboard && cd $HOME/open-falcon/dashboard\nWORKDIR /home/work/open-falcon/dashboard\nADD ./ ./\nRUN virtualenv ./env && ./env/bin/pip install -r pip_requirements.txt -i http://pypi.douban.com/simple\n\nADD ./entrypoint.sh /entrypoint.sh\nRUN chmod +x /entrypoint.sh\n\nENTRYPOINT [\"/entrypoint.sh\"]\n```\n\n\n\n\n\n## 2.Openfalcon使用\n\n### 采集模式\n\n[入门手册](https://book.open-falcon.org/zh_0_2/usage/getting-started.html)\n\nfalcon-agent自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。\n\n另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。\n\n\n\n**机器负载信息**\n\n这部分比较通用，我们提供了一个agent部署在所有机器上去采集。不像zabbix，要采集什么数据需要在服务端配置，falcon无需配置，只要agent部署到机器上，配置好heartbeat和Transfer地址，就自动开始采集了，省去了用户配置的麻烦。目前agent只支持64位Linux，Mac、Windows均不支持。\n\n**硬件信息**\n\n硬件信息的采集脚本由系统组同学提供，作为plugin依托于agent运行，plugin机制介绍请看[这里](http://book.open-falcon.org/zh_0_2/philosophy/plugin.html)。\n\n**服务监控数据**\n\n服务的监控指标采集脚本，通常都是跟着服务的code走的，服务上线或者扩容，这个脚本也跟着上线或者扩容，服务下线，这个采集脚本也要相应下线。公司里Java的项目有不少，研发那边就提供了一个通用jar包，只要引入这个jar包，就可以自动采集接口的调用次数、延迟时间等数据。然后将采集到的数据push给监控，一分钟push一次。目前falcon的agent提供了一个简单的http接口，这个jar包采集到数据之后是post给本机agent。向agent推送数据的一个简单例子，如下：\n\n```\ncurl -X POST -d '[{\"metric\": \"qps\", \"endpoint\": \"open-falcon-graph01.bj\", \"timestamp\": 1431347802, \"step\": 60,\"value\": 9,\"counterType\": \"GAUGE\",\"tags\": \"project=falcon,module=graph\"}]' http://127.0.0.1:1988/v1/push\n\n```\n\n**各种开源软件的监控指标**\n\n这都是大用户，比如DBA自己写一些采集脚本，连到各个MySQL实例上去采集数据，完事直接调用server端的jsonrpc汇报数据，一分钟一次，每次甚至push几十万条数据，比较好的发送方式是500条数据做一个batch，别几十万数据一次性发送。\n\n\n\n由上可知，falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。\n\n","source":"_posts/open-falcon.md","raw":"---\ntitle: Open-falcon 监控体系介绍\ndate: 2018-04-27 12:51:34\ntags: \n - Open-falcon\n - Go\ncategories: 技术\n---\n\n## 1.Openfalcon安装部署\n\n### 简介\n\n[官方文档 v2.0](https://book.open-falcon.org/zh_0_2/intro/)\n\n- 强大灵活的数据采集：自动发现，支持falcon-agent、snmp、支持用户主动push、用户自定义插件支持、opentsdb data model like（timestamp、endpoint、metric、key-value tags）\n- 水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询\n- 高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用\n- 人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期\n- 高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）\n- 高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据\n- dashboard：多维度的数据展示，用户自定义Screen\n- 高可用：整个系统无核心单点，易运维，易部署，可水平扩展\n- 开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。\n\n### 框架\n\n![func_tro](/img/openfalcon-func.png)\n\n\n\n<!-- more -->\n\n### 后端安装(docker)\n\n/opt/openfalcon/falcon-plus\n\n[官方教程](https://github.com/open-falcon/falcon-plus/blob/master/docker/README.md)\n\n```shell\n## Running falcon-plus container\n\n    docker pull openfalcon/falcon-plus:0.2.0\n    docker run -itd -p 8081:8081 openfalcon/falcon-plus:0.2.0 bash /run.sh hbs\n\n## Running falcon-plus container with docker-compose\n\n    docker-compose -f init.yml up -d falcon-plus\n\n## Running mysql and redis container\n\n    docker-compose -f init.yml up -d mysql redis\n\n## Stop and Remove containers\n\n    docker-compose -f init.yml rm -f\n```\n\ninit.yml\n\n```yaml\nversion: '2'\nservices:\n  mysql:\n    environment:\n    - MYSQL_ROOT_PASSWORD=password\n    extends:\n      file: common.yml\n      service: template\n    hostname: docker-mysql\n    image: mysql:5.7\n    labels:\n      owl: mysql\n    ports:\n    - 3306:3306\n    restart: always\n    volumes:\n    - ../scripts/mysql/db_schema:/docker-entrypoint-initdb.d\n    - ./mysql.cnf:/etc/mysql/conf.d/mysql.cnf:ro\n  redis:\n    command: redis-server /redis.conf\n    extends:\n      file: common.yml\n      service: template-backend\n    hostname: docker-redis\n    image: redis:3.0\n    labels:\n      owl: redis\n    ports:\n    - 6379:6379\n    restart: always\n    volumes:\n    - ./redis.conf:/redis.conf\n  falcon-plus:\n    command: bash /run.sh hbs\n    image: openfalcon/falcon-plus:0.2.0\n    ports:\n    - 8081:8081\n    restart: always\n```\n\n**注意**  需要打包mysql初始化脚本到这个路径下```../scripts/mysql/db_schema``` ，具体文件[在这里](https://github.com/open-falcon/falcon-plus/tree/master/scripts/mysql/db_schema)\n\nmysql登陆\n\n```\n#默认mysql密码  password\ndocker exec -it <容器id> mysql -p \n```\n\nweb 登陆 http://192.168.14.165:8081   新建用户\n\n![web](/img/openfalcon-web.png)\n\n### 前端安装(docker)\n\n/opt/openfalcon/dashboard\n\n[官方教程](https://github.com/open-falcon/dashboard/blob/master/README.md)\n\n```shell\n# make the image，run commands under dir of dashboard:\ndocker build -t falcon-dashboard:v1.0 .\n\n# start the container\ndocker run -itd --name aaa --net host \\\n\t-e API_ADDR=http://127.0.0.1:8080/api/v1 \\\n\t-e PORTAL_DB_HOST=127.0.0.1 \\\n\t-e PORTAL_DB_PORT=3306 \\\n\t-e PORTAL_DB_USER=root \\\n\t-e PORTAL_DB_PASS=123456 \\\n\t-e PORTAL_DB_NAME=falcon_portal \\\n\t-e ALARM_DB_PASS=123456 \\\n\t-e ALARM_DB_HOST=127.0.0.1 \\\n\t-e ALARM_DB_PORT=3306 \\\n\t-e ALARM_DB_USER=root \\\n\t-e ALARM_DB_PASS=123456 \\\n\t-e ALARM_DB_NAME=alarms \\\n\tfalcon-dashboard:v1.0\n```\n\nDockerfile\n\n```\nFROM centos:7.3.1611\n\nRUN yum clean all && yum install -y epel-release && yum -y update && \\\nyum install -y git python-virtualenv python-devel openldap-devel mysql-devel && \\\nyum groupinstall -y \"Development tools\"\n\nRUN export HOME=/home/work/ && mkdir -p $HOME/open-falcon/dashboard && cd $HOME/open-falcon/dashboard\nWORKDIR /home/work/open-falcon/dashboard\nADD ./ ./\nRUN virtualenv ./env && ./env/bin/pip install -r pip_requirements.txt -i http://pypi.douban.com/simple\n\nADD ./entrypoint.sh /entrypoint.sh\nRUN chmod +x /entrypoint.sh\n\nENTRYPOINT [\"/entrypoint.sh\"]\n```\n\n\n\n\n\n## 2.Openfalcon使用\n\n### 采集模式\n\n[入门手册](https://book.open-falcon.org/zh_0_2/usage/getting-started.html)\n\nfalcon-agent自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。\n\n另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。\n\n\n\n**机器负载信息**\n\n这部分比较通用，我们提供了一个agent部署在所有机器上去采集。不像zabbix，要采集什么数据需要在服务端配置，falcon无需配置，只要agent部署到机器上，配置好heartbeat和Transfer地址，就自动开始采集了，省去了用户配置的麻烦。目前agent只支持64位Linux，Mac、Windows均不支持。\n\n**硬件信息**\n\n硬件信息的采集脚本由系统组同学提供，作为plugin依托于agent运行，plugin机制介绍请看[这里](http://book.open-falcon.org/zh_0_2/philosophy/plugin.html)。\n\n**服务监控数据**\n\n服务的监控指标采集脚本，通常都是跟着服务的code走的，服务上线或者扩容，这个脚本也跟着上线或者扩容，服务下线，这个采集脚本也要相应下线。公司里Java的项目有不少，研发那边就提供了一个通用jar包，只要引入这个jar包，就可以自动采集接口的调用次数、延迟时间等数据。然后将采集到的数据push给监控，一分钟push一次。目前falcon的agent提供了一个简单的http接口，这个jar包采集到数据之后是post给本机agent。向agent推送数据的一个简单例子，如下：\n\n```\ncurl -X POST -d '[{\"metric\": \"qps\", \"endpoint\": \"open-falcon-graph01.bj\", \"timestamp\": 1431347802, \"step\": 60,\"value\": 9,\"counterType\": \"GAUGE\",\"tags\": \"project=falcon,module=graph\"}]' http://127.0.0.1:1988/v1/push\n\n```\n\n**各种开源软件的监控指标**\n\n这都是大用户，比如DBA自己写一些采集脚本，连到各个MySQL实例上去采集数据，完事直接调用server端的jsonrpc汇报数据，一分钟一次，每次甚至push几十万条数据，比较好的发送方式是500条数据做一个batch，别几十万数据一次性发送。\n\n\n\n由上可知，falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。\n\n","slug":"open-falcon","published":1,"updated":"2018-04-27T06:00:23.717Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczoy000se4rwaasmefg4","content":"<h2 id=\"1-Openfalcon安装部署\"><a href=\"#1-Openfalcon安装部署\" class=\"headerlink\" title=\"1.Openfalcon安装部署\"></a>1.Openfalcon安装部署</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p><a href=\"https://book.open-falcon.org/zh_0_2/intro/\" target=\"_blank\" rel=\"external\">官方文档 v2.0</a></p>\n<ul>\n<li>强大灵活的数据采集：自动发现，支持falcon-agent、snmp、支持用户主动push、用户自定义插件支持、opentsdb data model like（timestamp、endpoint、metric、key-value tags）</li>\n<li>水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询</li>\n<li>高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用</li>\n<li>人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期</li>\n<li>高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）</li>\n<li>高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据</li>\n<li>dashboard：多维度的数据展示，用户自定义Screen</li>\n<li>高可用：整个系统无核心单点，易运维，易部署，可水平扩展</li>\n<li>开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。</li>\n</ul>\n<h3 id=\"框架\"><a href=\"#框架\" class=\"headerlink\" title=\"框架\"></a>框架</h3><p><img src=\"/img/openfalcon-func.png\" alt=\"func_tro\"></p>\n<a id=\"more\"></a>\n<h3 id=\"后端安装-docker\"><a href=\"#后端安装-docker\" class=\"headerlink\" title=\"后端安装(docker)\"></a>后端安装(docker)</h3><p>/opt/openfalcon/falcon-plus</p>\n<p><a href=\"https://github.com/open-falcon/falcon-plus/blob/master/docker/README.md\" target=\"_blank\" rel=\"external\">官方教程</a></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Running falcon-plus container</span></span></div><div class=\"line\"></div><div class=\"line\">    docker pull openfalcon/falcon-plus:0.2.0</div><div class=\"line\">    docker run -itd -p 8081:8081 openfalcon/falcon-plus:0.2.0 bash /run.sh hbs</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Running falcon-plus container with docker-compose</span></span></div><div class=\"line\"></div><div class=\"line\">    docker-compose -f init.yml up -d falcon-plus</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Running mysql and redis container</span></span></div><div class=\"line\"></div><div class=\"line\">    docker-compose -f init.yml up -d mysql redis</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Stop and Remove containers</span></span></div><div class=\"line\"></div><div class=\"line\">    docker-compose -f init.yml rm -f</div></pre></td></tr></table></figure>\n<p>init.yml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">'2'</span></div><div class=\"line\"><span class=\"attr\">services:</span></div><div class=\"line\"><span class=\"attr\">  mysql:</span></div><div class=\"line\"><span class=\"attr\">    environment:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">MYSQL_ROOT_PASSWORD=password</span></div><div class=\"line\"><span class=\"attr\">    extends:</span></div><div class=\"line\"><span class=\"attr\">      file:</span> <span class=\"string\">common.yml</span></div><div class=\"line\"><span class=\"attr\">      service:</span> <span class=\"string\">template</span></div><div class=\"line\"><span class=\"attr\">    hostname:</span> <span class=\"string\">docker-mysql</span></div><div class=\"line\"><span class=\"attr\">    image:</span> <span class=\"attr\">mysql:5.7</span></div><div class=\"line\"><span class=\"attr\">    labels:</span></div><div class=\"line\"><span class=\"attr\">      owl:</span> <span class=\"string\">mysql</span></div><div class=\"line\"><span class=\"attr\">    ports:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"number\">3306</span><span class=\"string\">:3306</span></div><div class=\"line\"><span class=\"attr\">    restart:</span> <span class=\"string\">always</span></div><div class=\"line\"><span class=\"attr\">    volumes:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">../scripts/mysql/db_schema:/docker-entrypoint-initdb.d</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">./mysql.cnf:/etc/mysql/conf.d/mysql.cnf:ro</span></div><div class=\"line\"><span class=\"attr\">  redis:</span></div><div class=\"line\"><span class=\"attr\">    command:</span> <span class=\"string\">redis-server</span> <span class=\"string\">/redis.conf</span></div><div class=\"line\"><span class=\"attr\">    extends:</span></div><div class=\"line\"><span class=\"attr\">      file:</span> <span class=\"string\">common.yml</span></div><div class=\"line\"><span class=\"attr\">      service:</span> <span class=\"string\">template-backend</span></div><div class=\"line\"><span class=\"attr\">    hostname:</span> <span class=\"string\">docker-redis</span></div><div class=\"line\"><span class=\"attr\">    image:</span> <span class=\"attr\">redis:3.0</span></div><div class=\"line\"><span class=\"attr\">    labels:</span></div><div class=\"line\"><span class=\"attr\">      owl:</span> <span class=\"string\">redis</span></div><div class=\"line\"><span class=\"attr\">    ports:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"number\">6379</span><span class=\"string\">:6379</span></div><div class=\"line\"><span class=\"attr\">    restart:</span> <span class=\"string\">always</span></div><div class=\"line\"><span class=\"attr\">    volumes:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">./redis.conf:/redis.conf</span></div><div class=\"line\"><span class=\"attr\">  falcon-plus:</span></div><div class=\"line\"><span class=\"attr\">    command:</span> <span class=\"string\">bash</span> <span class=\"string\">/run.sh</span> <span class=\"string\">hbs</span></div><div class=\"line\"><span class=\"attr\">    image:</span> <span class=\"string\">openfalcon/falcon-plus:0.2.0</span></div><div class=\"line\"><span class=\"attr\">    ports:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"number\">8081</span><span class=\"string\">:8081</span></div><div class=\"line\"><span class=\"attr\">    restart:</span> <span class=\"string\">always</span></div></pre></td></tr></table></figure>\n<p><strong>注意</strong>  需要打包mysql初始化脚本到这个路径下<figure class=\"highlight plain\"><figcaption><span>，具体文件[在这里](https://github.com/open-falcon/falcon-plus/tree/master/scripts/mysql/db_schema)</span></figcaption><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">mysql登陆</div></pre></td></tr></table></figure></p>\n<p>#默认mysql密码  password<br>docker exec -it &lt;容器id&gt; mysql -p<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">web 登陆 http://192.168.14.165:8081   新建用户</div><div class=\"line\"></div><div class=\"line\">![web](/img/openfalcon-web.png)</div><div class=\"line\"></div><div class=\"line\">### 前端安装(docker)</div><div class=\"line\"></div><div class=\"line\">/opt/openfalcon/dashboard</div><div class=\"line\"></div><div class=\"line\">[官方教程](https://github.com/open-falcon/dashboard/blob/master/README.md)</div><div class=\"line\"></div><div class=\"line\">```shell</div><div class=\"line\"># make the image，run commands under dir of dashboard:</div><div class=\"line\">docker build -t falcon-dashboard:v1.0 .</div><div class=\"line\"></div><div class=\"line\"># start the container</div><div class=\"line\">docker run -itd --name aaa --net host \\</div><div class=\"line\">\t-e API_ADDR=http://127.0.0.1:8080/api/v1 \\</div><div class=\"line\">\t-e PORTAL_DB_HOST=127.0.0.1 \\</div><div class=\"line\">\t-e PORTAL_DB_PORT=3306 \\</div><div class=\"line\">\t-e PORTAL_DB_USER=root \\</div><div class=\"line\">\t-e PORTAL_DB_PASS=123456 \\</div><div class=\"line\">\t-e PORTAL_DB_NAME=falcon_portal \\</div><div class=\"line\">\t-e ALARM_DB_PASS=123456 \\</div><div class=\"line\">\t-e ALARM_DB_HOST=127.0.0.1 \\</div><div class=\"line\">\t-e ALARM_DB_PORT=3306 \\</div><div class=\"line\">\t-e ALARM_DB_USER=root \\</div><div class=\"line\">\t-e ALARM_DB_PASS=123456 \\</div><div class=\"line\">\t-e ALARM_DB_NAME=alarms \\</div><div class=\"line\">\tfalcon-dashboard:v1.0</div></pre></td></tr></table></figure></p>\n<p>Dockerfile</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">FROM centos:7.3.1611</div><div class=\"line\"></div><div class=\"line\">RUN yum clean all &amp;&amp; yum install -y epel-release &amp;&amp; yum -y update &amp;&amp; \\</div><div class=\"line\">yum install -y git python-virtualenv python-devel openldap-devel mysql-devel &amp;&amp; \\</div><div class=\"line\">yum groupinstall -y &quot;Development tools&quot;</div><div class=\"line\"></div><div class=\"line\">RUN export HOME=/home/work/ &amp;&amp; mkdir -p $HOME/open-falcon/dashboard &amp;&amp; cd $HOME/open-falcon/dashboard</div><div class=\"line\">WORKDIR /home/work/open-falcon/dashboard</div><div class=\"line\">ADD ./ ./</div><div class=\"line\">RUN virtualenv ./env &amp;&amp; ./env/bin/pip install -r pip_requirements.txt -i http://pypi.douban.com/simple</div><div class=\"line\"></div><div class=\"line\">ADD ./entrypoint.sh /entrypoint.sh</div><div class=\"line\">RUN chmod +x /entrypoint.sh</div><div class=\"line\"></div><div class=\"line\">ENTRYPOINT [&quot;/entrypoint.sh&quot;]</div></pre></td></tr></table></figure>\n<h2 id=\"2-Openfalcon使用\"><a href=\"#2-Openfalcon使用\" class=\"headerlink\" title=\"2.Openfalcon使用\"></a>2.Openfalcon使用</h2><h3 id=\"采集模式\"><a href=\"#采集模式\" class=\"headerlink\" title=\"采集模式\"></a>采集模式</h3><p><a href=\"https://book.open-falcon.org/zh_0_2/usage/getting-started.html\" target=\"_blank\" rel=\"external\">入门手册</a></p>\n<p>falcon-agent自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。</p>\n<p>另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。</p>\n<p><strong>机器负载信息</strong></p>\n<p>这部分比较通用，我们提供了一个agent部署在所有机器上去采集。不像zabbix，要采集什么数据需要在服务端配置，falcon无需配置，只要agent部署到机器上，配置好heartbeat和Transfer地址，就自动开始采集了，省去了用户配置的麻烦。目前agent只支持64位Linux，Mac、Windows均不支持。</p>\n<p><strong>硬件信息</strong></p>\n<p>硬件信息的采集脚本由系统组同学提供，作为plugin依托于agent运行，plugin机制介绍请看<a href=\"http://book.open-falcon.org/zh_0_2/philosophy/plugin.html\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p><strong>服务监控数据</strong></p>\n<p>服务的监控指标采集脚本，通常都是跟着服务的code走的，服务上线或者扩容，这个脚本也跟着上线或者扩容，服务下线，这个采集脚本也要相应下线。公司里Java的项目有不少，研发那边就提供了一个通用jar包，只要引入这个jar包，就可以自动采集接口的调用次数、延迟时间等数据。然后将采集到的数据push给监控，一分钟push一次。目前falcon的agent提供了一个简单的http接口，这个jar包采集到数据之后是post给本机agent。向agent推送数据的一个简单例子，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -X POST -d &apos;[&#123;&quot;metric&quot;: &quot;qps&quot;, &quot;endpoint&quot;: &quot;open-falcon-graph01.bj&quot;, &quot;timestamp&quot;: 1431347802, &quot;step&quot;: 60,&quot;value&quot;: 9,&quot;counterType&quot;: &quot;GAUGE&quot;,&quot;tags&quot;: &quot;project=falcon,module=graph&quot;&#125;]&apos; http://127.0.0.1:1988/v1/push</div></pre></td></tr></table></figure>\n<p><strong>各种开源软件的监控指标</strong></p>\n<p>这都是大用户，比如DBA自己写一些采集脚本，连到各个MySQL实例上去采集数据，完事直接调用server端的jsonrpc汇报数据，一分钟一次，每次甚至push几十万条数据，比较好的发送方式是500条数据做一个batch，别几十万数据一次性发送。</p>\n<p>由上可知，falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-Openfalcon安装部署\"><a href=\"#1-Openfalcon安装部署\" class=\"headerlink\" title=\"1.Openfalcon安装部署\"></a>1.Openfalcon安装部署</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p><a href=\"https://book.open-falcon.org/zh_0_2/intro/\" target=\"_blank\" rel=\"external\">官方文档 v2.0</a></p>\n<ul>\n<li>强大灵活的数据采集：自动发现，支持falcon-agent、snmp、支持用户主动push、用户自定义插件支持、opentsdb data model like（timestamp、endpoint、metric、key-value tags）</li>\n<li>水平扩展能力：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询</li>\n<li>高效率的告警策略管理：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用</li>\n<li>人性化的告警设置：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期</li>\n<li>高效率的graph组件：单机支撑200万metric的上报、归档、存储（周期为1分钟）</li>\n<li>高效的历史数据query组件：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据</li>\n<li>dashboard：多维度的数据展示，用户自定义Screen</li>\n<li>高可用：整个系统无核心单点，易运维，易部署，可水平扩展</li>\n<li>开发语言： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。</li>\n</ul>\n<h3 id=\"框架\"><a href=\"#框架\" class=\"headerlink\" title=\"框架\"></a>框架</h3><p><img src=\"/img/openfalcon-func.png\" alt=\"func_tro\"></p>","more":"<h3 id=\"后端安装-docker\"><a href=\"#后端安装-docker\" class=\"headerlink\" title=\"后端安装(docker)\"></a>后端安装(docker)</h3><p>/opt/openfalcon/falcon-plus</p>\n<p><a href=\"https://github.com/open-falcon/falcon-plus/blob/master/docker/README.md\" target=\"_blank\" rel=\"external\">官方教程</a></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Running falcon-plus container</span></span></div><div class=\"line\"></div><div class=\"line\">    docker pull openfalcon/falcon-plus:0.2.0</div><div class=\"line\">    docker run -itd -p 8081:8081 openfalcon/falcon-plus:0.2.0 bash /run.sh hbs</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Running falcon-plus container with docker-compose</span></span></div><div class=\"line\"></div><div class=\"line\">    docker-compose -f init.yml up -d falcon-plus</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Running mysql and redis container</span></span></div><div class=\"line\"></div><div class=\"line\">    docker-compose -f init.yml up -d mysql redis</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"><span class=\"comment\"># Stop and Remove containers</span></span></div><div class=\"line\"></div><div class=\"line\">    docker-compose -f init.yml rm -f</div></pre></td></tr></table></figure>\n<p>init.yml</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">'2'</span></div><div class=\"line\"><span class=\"attr\">services:</span></div><div class=\"line\"><span class=\"attr\">  mysql:</span></div><div class=\"line\"><span class=\"attr\">    environment:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">MYSQL_ROOT_PASSWORD=password</span></div><div class=\"line\"><span class=\"attr\">    extends:</span></div><div class=\"line\"><span class=\"attr\">      file:</span> <span class=\"string\">common.yml</span></div><div class=\"line\"><span class=\"attr\">      service:</span> <span class=\"string\">template</span></div><div class=\"line\"><span class=\"attr\">    hostname:</span> <span class=\"string\">docker-mysql</span></div><div class=\"line\"><span class=\"attr\">    image:</span> <span class=\"attr\">mysql:5.7</span></div><div class=\"line\"><span class=\"attr\">    labels:</span></div><div class=\"line\"><span class=\"attr\">      owl:</span> <span class=\"string\">mysql</span></div><div class=\"line\"><span class=\"attr\">    ports:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"number\">3306</span><span class=\"string\">:3306</span></div><div class=\"line\"><span class=\"attr\">    restart:</span> <span class=\"string\">always</span></div><div class=\"line\"><span class=\"attr\">    volumes:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">../scripts/mysql/db_schema:/docker-entrypoint-initdb.d</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">./mysql.cnf:/etc/mysql/conf.d/mysql.cnf:ro</span></div><div class=\"line\"><span class=\"attr\">  redis:</span></div><div class=\"line\"><span class=\"attr\">    command:</span> <span class=\"string\">redis-server</span> <span class=\"string\">/redis.conf</span></div><div class=\"line\"><span class=\"attr\">    extends:</span></div><div class=\"line\"><span class=\"attr\">      file:</span> <span class=\"string\">common.yml</span></div><div class=\"line\"><span class=\"attr\">      service:</span> <span class=\"string\">template-backend</span></div><div class=\"line\"><span class=\"attr\">    hostname:</span> <span class=\"string\">docker-redis</span></div><div class=\"line\"><span class=\"attr\">    image:</span> <span class=\"attr\">redis:3.0</span></div><div class=\"line\"><span class=\"attr\">    labels:</span></div><div class=\"line\"><span class=\"attr\">      owl:</span> <span class=\"string\">redis</span></div><div class=\"line\"><span class=\"attr\">    ports:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"number\">6379</span><span class=\"string\">:6379</span></div><div class=\"line\"><span class=\"attr\">    restart:</span> <span class=\"string\">always</span></div><div class=\"line\"><span class=\"attr\">    volumes:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">./redis.conf:/redis.conf</span></div><div class=\"line\"><span class=\"attr\">  falcon-plus:</span></div><div class=\"line\"><span class=\"attr\">    command:</span> <span class=\"string\">bash</span> <span class=\"string\">/run.sh</span> <span class=\"string\">hbs</span></div><div class=\"line\"><span class=\"attr\">    image:</span> <span class=\"string\">openfalcon/falcon-plus:0.2.0</span></div><div class=\"line\"><span class=\"attr\">    ports:</span></div><div class=\"line\"><span class=\"bullet\">    -</span> <span class=\"number\">8081</span><span class=\"string\">:8081</span></div><div class=\"line\"><span class=\"attr\">    restart:</span> <span class=\"string\">always</span></div></pre></td></tr></table></figure>\n<p><strong>注意</strong>  需要打包mysql初始化脚本到这个路径下<figure class=\"highlight plain\"><figcaption><span>，具体文件[在这里](https://github.com/open-falcon/falcon-plus/tree/master/scripts/mysql/db_schema)</span></figcaption><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">mysql登陆</div></pre></td></tr></table></figure></p>\n<p>#默认mysql密码  password<br>docker exec -it &lt;容器id&gt; mysql -p<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div></pre></td><td class=\"code\"><pre><div class=\"line\"></div><div class=\"line\">web 登陆 http://192.168.14.165:8081   新建用户</div><div class=\"line\"></div><div class=\"line\">![web](/img/openfalcon-web.png)</div><div class=\"line\"></div><div class=\"line\">### 前端安装(docker)</div><div class=\"line\"></div><div class=\"line\">/opt/openfalcon/dashboard</div><div class=\"line\"></div><div class=\"line\">[官方教程](https://github.com/open-falcon/dashboard/blob/master/README.md)</div><div class=\"line\"></div><div class=\"line\">```shell</div><div class=\"line\"># make the image，run commands under dir of dashboard:</div><div class=\"line\">docker build -t falcon-dashboard:v1.0 .</div><div class=\"line\"></div><div class=\"line\"># start the container</div><div class=\"line\">docker run -itd --name aaa --net host \\</div><div class=\"line\">\t-e API_ADDR=http://127.0.0.1:8080/api/v1 \\</div><div class=\"line\">\t-e PORTAL_DB_HOST=127.0.0.1 \\</div><div class=\"line\">\t-e PORTAL_DB_PORT=3306 \\</div><div class=\"line\">\t-e PORTAL_DB_USER=root \\</div><div class=\"line\">\t-e PORTAL_DB_PASS=123456 \\</div><div class=\"line\">\t-e PORTAL_DB_NAME=falcon_portal \\</div><div class=\"line\">\t-e ALARM_DB_PASS=123456 \\</div><div class=\"line\">\t-e ALARM_DB_HOST=127.0.0.1 \\</div><div class=\"line\">\t-e ALARM_DB_PORT=3306 \\</div><div class=\"line\">\t-e ALARM_DB_USER=root \\</div><div class=\"line\">\t-e ALARM_DB_PASS=123456 \\</div><div class=\"line\">\t-e ALARM_DB_NAME=alarms \\</div><div class=\"line\">\tfalcon-dashboard:v1.0</div></pre></td></tr></table></figure></p>\n<p>Dockerfile</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">FROM centos:7.3.1611</div><div class=\"line\"></div><div class=\"line\">RUN yum clean all &amp;&amp; yum install -y epel-release &amp;&amp; yum -y update &amp;&amp; \\</div><div class=\"line\">yum install -y git python-virtualenv python-devel openldap-devel mysql-devel &amp;&amp; \\</div><div class=\"line\">yum groupinstall -y &quot;Development tools&quot;</div><div class=\"line\"></div><div class=\"line\">RUN export HOME=/home/work/ &amp;&amp; mkdir -p $HOME/open-falcon/dashboard &amp;&amp; cd $HOME/open-falcon/dashboard</div><div class=\"line\">WORKDIR /home/work/open-falcon/dashboard</div><div class=\"line\">ADD ./ ./</div><div class=\"line\">RUN virtualenv ./env &amp;&amp; ./env/bin/pip install -r pip_requirements.txt -i http://pypi.douban.com/simple</div><div class=\"line\"></div><div class=\"line\">ADD ./entrypoint.sh /entrypoint.sh</div><div class=\"line\">RUN chmod +x /entrypoint.sh</div><div class=\"line\"></div><div class=\"line\">ENTRYPOINT [&quot;/entrypoint.sh&quot;]</div></pre></td></tr></table></figure>\n<h2 id=\"2-Openfalcon使用\"><a href=\"#2-Openfalcon使用\" class=\"headerlink\" title=\"2.Openfalcon使用\"></a>2.Openfalcon使用</h2><h3 id=\"采集模式\"><a href=\"#采集模式\" class=\"headerlink\" title=\"采集模式\"></a>采集模式</h3><p><a href=\"https://book.open-falcon.org/zh_0_2/usage/getting-started.html\" target=\"_blank\" rel=\"external\">入门手册</a></p>\n<p>falcon-agent自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。</p>\n<p>另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。</p>\n<p><strong>机器负载信息</strong></p>\n<p>这部分比较通用，我们提供了一个agent部署在所有机器上去采集。不像zabbix，要采集什么数据需要在服务端配置，falcon无需配置，只要agent部署到机器上，配置好heartbeat和Transfer地址，就自动开始采集了，省去了用户配置的麻烦。目前agent只支持64位Linux，Mac、Windows均不支持。</p>\n<p><strong>硬件信息</strong></p>\n<p>硬件信息的采集脚本由系统组同学提供，作为plugin依托于agent运行，plugin机制介绍请看<a href=\"http://book.open-falcon.org/zh_0_2/philosophy/plugin.html\" target=\"_blank\" rel=\"external\">这里</a>。</p>\n<p><strong>服务监控数据</strong></p>\n<p>服务的监控指标采集脚本，通常都是跟着服务的code走的，服务上线或者扩容，这个脚本也跟着上线或者扩容，服务下线，这个采集脚本也要相应下线。公司里Java的项目有不少，研发那边就提供了一个通用jar包，只要引入这个jar包，就可以自动采集接口的调用次数、延迟时间等数据。然后将采集到的数据push给监控，一分钟push一次。目前falcon的agent提供了一个简单的http接口，这个jar包采集到数据之后是post给本机agent。向agent推送数据的一个简单例子，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -X POST -d &apos;[&#123;&quot;metric&quot;: &quot;qps&quot;, &quot;endpoint&quot;: &quot;open-falcon-graph01.bj&quot;, &quot;timestamp&quot;: 1431347802, &quot;step&quot;: 60,&quot;value&quot;: 9,&quot;counterType&quot;: &quot;GAUGE&quot;,&quot;tags&quot;: &quot;project=falcon,module=graph&quot;&#125;]&apos; http://127.0.0.1:1988/v1/push</div></pre></td></tr></table></figure>\n<p><strong>各种开源软件的监控指标</strong></p>\n<p>这都是大用户，比如DBA自己写一些采集脚本，连到各个MySQL实例上去采集数据，完事直接调用server端的jsonrpc汇报数据，一分钟一次，每次甚至push几十万条数据，比较好的发送方式是500条数据做一个batch，别几十万数据一次性发送。</p>\n<p>由上可知，falcon-agent本身仅支持主机类的指标采集，对于其他业务系统、开源软件，需独立的使用采集脚本，将数据按照规定格式，发送到falcon-agent 所在的监听端口。最终再由falcon-agent 转发到服务端。</p>"},{"title":"凤凰项目-一个IT运维的传奇故事","date":"2018-05-17T12:51:43.000Z","_content":"\n本书讲述了一位IT经理临危受命，在未来董事的帮助和自己“三步工作法”理念的支撑下，最终挽救了一家具有悠久历史的汽车配件制造商的故事。小说揭示了管理现代IT组织与管理传统工厂的共通之处，让读者不仅能对如何管理IT组织心领神会，更重要的是将以完全不同于以往的视角来看待自己的工作环境。\n\n只有掌握了战术，才能实现战略目标。\n半成品是隐形杀手。\n约束理论：在瓶颈之外的任何地方作出的改进都是假象。在瓶颈之后作出的任何改进都是徒劳的，因为只能干等着瓶颈把工作传送过来。而在瓶颈之前作出的任何改进则只会导致瓶颈处堆积更多的库存。\n三步工作法：\n\n- 第一工作法帮助我们理解在工作从开发部移向运维部时该如何建立快速工作流，因为那就是业务部门与客户之间的衔接。\n- 第二工作法告诉我们如何缩短以及放大反馈环路，从而在源头上解决质量问题，避免返工。\n- 第三工作法告诉我们如何建立一种文化，既能鼓励探索、从失败中吸取教训，又能理解反复的实践是精通工作的先觉条件。","source":"_posts/phoenix.md","raw":"---\ntitle: 凤凰项目-一个IT运维的传奇故事\ndate: 2018-05-17 20:51:43\ntags: 随笔\n---\n\n本书讲述了一位IT经理临危受命，在未来董事的帮助和自己“三步工作法”理念的支撑下，最终挽救了一家具有悠久历史的汽车配件制造商的故事。小说揭示了管理现代IT组织与管理传统工厂的共通之处，让读者不仅能对如何管理IT组织心领神会，更重要的是将以完全不同于以往的视角来看待自己的工作环境。\n\n只有掌握了战术，才能实现战略目标。\n半成品是隐形杀手。\n约束理论：在瓶颈之外的任何地方作出的改进都是假象。在瓶颈之后作出的任何改进都是徒劳的，因为只能干等着瓶颈把工作传送过来。而在瓶颈之前作出的任何改进则只会导致瓶颈处堆积更多的库存。\n三步工作法：\n\n- 第一工作法帮助我们理解在工作从开发部移向运维部时该如何建立快速工作流，因为那就是业务部门与客户之间的衔接。\n- 第二工作法告诉我们如何缩短以及放大反馈环路，从而在源头上解决质量问题，避免返工。\n- 第三工作法告诉我们如何建立一种文化，既能鼓励探索、从失败中吸取教训，又能理解反复的实践是精通工作的先觉条件。","slug":"phoenix","published":1,"updated":"2018-05-17T12:52:34.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczp0000we4rwkfbth5ah","content":"<p>本书讲述了一位IT经理临危受命，在未来董事的帮助和自己“三步工作法”理念的支撑下，最终挽救了一家具有悠久历史的汽车配件制造商的故事。小说揭示了管理现代IT组织与管理传统工厂的共通之处，让读者不仅能对如何管理IT组织心领神会，更重要的是将以完全不同于以往的视角来看待自己的工作环境。</p>\n<p>只有掌握了战术，才能实现战略目标。<br>半成品是隐形杀手。<br>约束理论：在瓶颈之外的任何地方作出的改进都是假象。在瓶颈之后作出的任何改进都是徒劳的，因为只能干等着瓶颈把工作传送过来。而在瓶颈之前作出的任何改进则只会导致瓶颈处堆积更多的库存。<br>三步工作法：</p>\n<ul>\n<li>第一工作法帮助我们理解在工作从开发部移向运维部时该如何建立快速工作流，因为那就是业务部门与客户之间的衔接。</li>\n<li>第二工作法告诉我们如何缩短以及放大反馈环路，从而在源头上解决质量问题，避免返工。</li>\n<li>第三工作法告诉我们如何建立一种文化，既能鼓励探索、从失败中吸取教训，又能理解反复的实践是精通工作的先觉条件。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>本书讲述了一位IT经理临危受命，在未来董事的帮助和自己“三步工作法”理念的支撑下，最终挽救了一家具有悠久历史的汽车配件制造商的故事。小说揭示了管理现代IT组织与管理传统工厂的共通之处，让读者不仅能对如何管理IT组织心领神会，更重要的是将以完全不同于以往的视角来看待自己的工作环境。</p>\n<p>只有掌握了战术，才能实现战略目标。<br>半成品是隐形杀手。<br>约束理论：在瓶颈之外的任何地方作出的改进都是假象。在瓶颈之后作出的任何改进都是徒劳的，因为只能干等着瓶颈把工作传送过来。而在瓶颈之前作出的任何改进则只会导致瓶颈处堆积更多的库存。<br>三步工作法：</p>\n<ul>\n<li>第一工作法帮助我们理解在工作从开发部移向运维部时该如何建立快速工作流，因为那就是业务部门与客户之间的衔接。</li>\n<li>第二工作法告诉我们如何缩短以及放大反馈环路，从而在源头上解决质量问题，避免返工。</li>\n<li>第三工作法告诉我们如何建立一种文化，既能鼓励探索、从失败中吸取教训，又能理解反复的实践是精通工作的先觉条件。</li>\n</ul>\n"},{"title":"程序员的思维训练","date":"2015-04-20T13:05:49.000Z","_content":"这是一本关于训练程序员思维的书，当然也不仅仅局限于此。各行各业的本质很多都是相同。在本书中，作者提出了程序员的两大重要能力：沟通能力以及学习和思考能力。同时作者也提出了情境的重要性，因为事物都之间都是互相联系的，关注情境才能把握大局。\n![programmer thought](/img/programmer.png)\n\n<!-- more -->\n\n# 介绍从新手到专家的历程\n    德雷福斯模型:\n    新手：严重依赖与规则，只能按照规则行事，不能独立的思考以解决问题。\n    高级新手：没有全局思维，只关注自己的工作部分。\n    胜任者：可以独立解决问题，也开始思考如何解决新的问题，过于依赖以前的经验，缺乏反思和自我纠正。\n    精通：能够自我纠正，反思，并且改进，以期做得更好。\n    专家：总是不断的寻找更好的方法和方式去做事，有丰富的经验，可以在恰当的情境中选取和应用这些经验。专家根据直觉工作。专家知道哪些是无关紧要的细节，哪些是非常重要的细节。专家非常擅长做有针对性的特征匹配。举例说明，一个众所周知的极限编程方法经验之谈是“测试一切可能出错的东西”。对于新手来说，这只是一个指令清单。测试什么？是所有的setter和getter方法，还是只是打印语句?他们最终会测试所有无关的东西。但是处于精通水平的人员知道，什么地方有可能出错，或者更确切的说，什么地方非常有可能出错。他们具有经验和判断力，能够理解这句格言在情境中意味着什么。事实证明，理解情境是成为专家的关键。\n    新手到专家的转变，最重要的三个变化是：从依赖规则到依赖直觉；观念的转变，问题已不再是一个相关度等同的所有单元的集合体，而是一个完整和独特的整体，其中只有某些单元是相关的；最后，从问题的旁观者转变为问题设计的系统本身的一部分。\n    诀窍：专家依赖直觉。知道你不知道什么。通过观察和模仿来学习。学习如何学习的技能。\n# 认识你的大脑\n    大脑的结构：单总线，双CPU。左右脑的区别，一个处理逻辑的线性的L型，一个则是感性的非线性的R型。这两种模式都需要：R型对直觉、问题解决和创造性非常重要；L型让你细致工作并实现目标。R型侧重全局，L型则关注局部。R型是异步处理任务的，他实时的记录存储着我们所感知的一切，但是并没有建立索引，换言之，我们见过的一切实物，可能都已经深深的印在脑海中，只是大脑认为这些不重要，因而没有被立即索引，就被抛在脑后了，当哪天我们在努力思考解决一个问题的时候，R型就会在脑海里异步搜索，并在某个时刻，以灵光一闪的惊喜给你答案。因此，我们需要7*24记录想法。\n    诀窍：综合学习和分析学习并重。\n\n# 利用右脑\n    既然右脑（R型）如此重要，那么我们如何来训练，以期充分地发掘它的潜力呢？R型开路，L型紧跟。R型只能邀请，不能强制命令。\n    举例：乐高积木的角色扮演。攀岩的例子，教练先让我们体验了一把真正的攀岩，然后再来解释其中的技巧和关键。这实际上是建立了从R型到L型的转换\n    诀窍：增加感官体验以促进大脑的使用。R型开路，L型紧跟。使用隐喻作为R型和L型的融合之所。晨写日志。离开键盘去解决难题。改变解决问题的角度。培养快速的洞察能力，寻找不相关事物之间的关系或者类比。\n\n\n\n# 调试大脑\n    如何调试大脑：认知偏见，思维如何被误导；时代影响，同代人如何影响你；个性倾向，个性如何影响思维；硬件故障，大脑较老区域如何压制脚聪明的区域。\n    诀窍：像高级动物一样行动，请做深呼吸，而不要张口嘶鸣。相信直觉，但是要验证。\n# 积极学习\n    大脑不是一个用于填充的容器，而是一束需要点燃的火焰。\n    瞄准SMART目标。SMART代表具体的、可度量的、可实现的、相关的和时间可控的（Specific,Measurable,Achieveable,Relevant and Time-boxed）..使用你的原生学习模式：视觉型，听觉型和动觉型。使用增强的学习方法，既然已经建立了主动学习的良好框架，我们需要看看学习本身。以下是好方法：\n\t主动阅读和总结书面材料的更好方式：使用SQ3R法主动阅读，调查（Survey）：扫描目录和每章总结，得出总体看法；问题（Question）：记录所有的问题；阅读（Read）:阅读全部内容；复述（Recite）：总结，做笔记，用自己的话来描述；回顾（Review）：重读，拓展笔记，与同时讨论。具体例子：假设我正在阅读一本有关于新编程语言D,Erlang或者Ruby的书。我翻阅目录，看看书的主要内容。噢，一些语法的介绍，几个简单项目，还有我目前不感兴趣的高级特性。嗯，它是单继承、多继承还是混合的？我想知道迭代器在该语言中是怎么用的？如何创建和管理包或者模块？运行时性能如何？接下来看书-如果可能的话就多看点，如果时间紧的话就少看点。接下来是复述，即改写。整个事件流听起来很熟悉，是吗？我想它清晰的反映了R型到L型的转换，就像攀岩体验一样，首先是一种全盘、浅显但是广泛的调查，然后转换到传统的L型活动，扩大到多重感官的参与（讨论，笔记，图片，隐喻等。）\n\t使用思维导图探索和发现模式和关系。 手写思维导图，更加的形象，易于被大脑（R型）接受。\n\t以教代学。和橡皮鸭聊天。学习某项实物的最简单和有效的方法就是尝试教别人。\n    诀窍：写文档的过程比文档本身更重要。观察，实践，教学。\n\n# 积累经验\n    积累经验是学习和成长的关键--我们通过实践的方法学习，效果最好。运用内在诀窍的关键要素：不要把精力放在纠正一个一个的细节上，只需要具有意识。举例：在采取纠正行动之前，先知道“这是什么”对于调试非常重要。太多的程序员往往没有完全明白正真的错误是什么就着急修正它。匆忙的做出判断或者过早的就进行修补。你需要首先完全明白系统的原理，然后在判断哪部分错了，最后提供解决方案。现在闭上眼睛，想象一下错误代码的位置。把它看作是地震的震中，你可能感觉到地面到处在抖动，但是震中最为明显。出错的代码应该是什么样的？周围的代码呢？\n    诀窍：为了更好的学习，请更好的玩。从相似点中学习，从差异中忘却。利用大脑模拟成功，像专家一样学习。\n# 控制注意力\n    通过以下三点更好的管理思维：增强注意力，管理你的知识，优化当前情境。\n    其实就是减少干扰，营造学习的良好环境。控制注意力，有助于我们更好的学习。\n    记住这三件事情：1.学会安抚喋喋不休的L型思维；2主动在前进中思考和增强思想，即使是不成熟的；3明确情境切换的昂贵代价，尽可能的避免。\n# 超越专家\n    保持好奇心，学习新知识，成为新的“新手”。认识你自己，认识当前时刻，认识你所处的情境。自由的代价是永远提高警惕。\n\n\n","source":"_posts/programmer-thought.md","raw":"---\ntitle: 程序员的思维训练\ndate: 2015-04-20 21:05:49\ntags: 随笔\n---\n这是一本关于训练程序员思维的书，当然也不仅仅局限于此。各行各业的本质很多都是相同。在本书中，作者提出了程序员的两大重要能力：沟通能力以及学习和思考能力。同时作者也提出了情境的重要性，因为事物都之间都是互相联系的，关注情境才能把握大局。\n![programmer thought](/img/programmer.png)\n\n<!-- more -->\n\n# 介绍从新手到专家的历程\n    德雷福斯模型:\n    新手：严重依赖与规则，只能按照规则行事，不能独立的思考以解决问题。\n    高级新手：没有全局思维，只关注自己的工作部分。\n    胜任者：可以独立解决问题，也开始思考如何解决新的问题，过于依赖以前的经验，缺乏反思和自我纠正。\n    精通：能够自我纠正，反思，并且改进，以期做得更好。\n    专家：总是不断的寻找更好的方法和方式去做事，有丰富的经验，可以在恰当的情境中选取和应用这些经验。专家根据直觉工作。专家知道哪些是无关紧要的细节，哪些是非常重要的细节。专家非常擅长做有针对性的特征匹配。举例说明，一个众所周知的极限编程方法经验之谈是“测试一切可能出错的东西”。对于新手来说，这只是一个指令清单。测试什么？是所有的setter和getter方法，还是只是打印语句?他们最终会测试所有无关的东西。但是处于精通水平的人员知道，什么地方有可能出错，或者更确切的说，什么地方非常有可能出错。他们具有经验和判断力，能够理解这句格言在情境中意味着什么。事实证明，理解情境是成为专家的关键。\n    新手到专家的转变，最重要的三个变化是：从依赖规则到依赖直觉；观念的转变，问题已不再是一个相关度等同的所有单元的集合体，而是一个完整和独特的整体，其中只有某些单元是相关的；最后，从问题的旁观者转变为问题设计的系统本身的一部分。\n    诀窍：专家依赖直觉。知道你不知道什么。通过观察和模仿来学习。学习如何学习的技能。\n# 认识你的大脑\n    大脑的结构：单总线，双CPU。左右脑的区别，一个处理逻辑的线性的L型，一个则是感性的非线性的R型。这两种模式都需要：R型对直觉、问题解决和创造性非常重要；L型让你细致工作并实现目标。R型侧重全局，L型则关注局部。R型是异步处理任务的，他实时的记录存储着我们所感知的一切，但是并没有建立索引，换言之，我们见过的一切实物，可能都已经深深的印在脑海中，只是大脑认为这些不重要，因而没有被立即索引，就被抛在脑后了，当哪天我们在努力思考解决一个问题的时候，R型就会在脑海里异步搜索，并在某个时刻，以灵光一闪的惊喜给你答案。因此，我们需要7*24记录想法。\n    诀窍：综合学习和分析学习并重。\n\n# 利用右脑\n    既然右脑（R型）如此重要，那么我们如何来训练，以期充分地发掘它的潜力呢？R型开路，L型紧跟。R型只能邀请，不能强制命令。\n    举例：乐高积木的角色扮演。攀岩的例子，教练先让我们体验了一把真正的攀岩，然后再来解释其中的技巧和关键。这实际上是建立了从R型到L型的转换\n    诀窍：增加感官体验以促进大脑的使用。R型开路，L型紧跟。使用隐喻作为R型和L型的融合之所。晨写日志。离开键盘去解决难题。改变解决问题的角度。培养快速的洞察能力，寻找不相关事物之间的关系或者类比。\n\n\n\n# 调试大脑\n    如何调试大脑：认知偏见，思维如何被误导；时代影响，同代人如何影响你；个性倾向，个性如何影响思维；硬件故障，大脑较老区域如何压制脚聪明的区域。\n    诀窍：像高级动物一样行动，请做深呼吸，而不要张口嘶鸣。相信直觉，但是要验证。\n# 积极学习\n    大脑不是一个用于填充的容器，而是一束需要点燃的火焰。\n    瞄准SMART目标。SMART代表具体的、可度量的、可实现的、相关的和时间可控的（Specific,Measurable,Achieveable,Relevant and Time-boxed）..使用你的原生学习模式：视觉型，听觉型和动觉型。使用增强的学习方法，既然已经建立了主动学习的良好框架，我们需要看看学习本身。以下是好方法：\n\t主动阅读和总结书面材料的更好方式：使用SQ3R法主动阅读，调查（Survey）：扫描目录和每章总结，得出总体看法；问题（Question）：记录所有的问题；阅读（Read）:阅读全部内容；复述（Recite）：总结，做笔记，用自己的话来描述；回顾（Review）：重读，拓展笔记，与同时讨论。具体例子：假设我正在阅读一本有关于新编程语言D,Erlang或者Ruby的书。我翻阅目录，看看书的主要内容。噢，一些语法的介绍，几个简单项目，还有我目前不感兴趣的高级特性。嗯，它是单继承、多继承还是混合的？我想知道迭代器在该语言中是怎么用的？如何创建和管理包或者模块？运行时性能如何？接下来看书-如果可能的话就多看点，如果时间紧的话就少看点。接下来是复述，即改写。整个事件流听起来很熟悉，是吗？我想它清晰的反映了R型到L型的转换，就像攀岩体验一样，首先是一种全盘、浅显但是广泛的调查，然后转换到传统的L型活动，扩大到多重感官的参与（讨论，笔记，图片，隐喻等。）\n\t使用思维导图探索和发现模式和关系。 手写思维导图，更加的形象，易于被大脑（R型）接受。\n\t以教代学。和橡皮鸭聊天。学习某项实物的最简单和有效的方法就是尝试教别人。\n    诀窍：写文档的过程比文档本身更重要。观察，实践，教学。\n\n# 积累经验\n    积累经验是学习和成长的关键--我们通过实践的方法学习，效果最好。运用内在诀窍的关键要素：不要把精力放在纠正一个一个的细节上，只需要具有意识。举例：在采取纠正行动之前，先知道“这是什么”对于调试非常重要。太多的程序员往往没有完全明白正真的错误是什么就着急修正它。匆忙的做出判断或者过早的就进行修补。你需要首先完全明白系统的原理，然后在判断哪部分错了，最后提供解决方案。现在闭上眼睛，想象一下错误代码的位置。把它看作是地震的震中，你可能感觉到地面到处在抖动，但是震中最为明显。出错的代码应该是什么样的？周围的代码呢？\n    诀窍：为了更好的学习，请更好的玩。从相似点中学习，从差异中忘却。利用大脑模拟成功，像专家一样学习。\n# 控制注意力\n    通过以下三点更好的管理思维：增强注意力，管理你的知识，优化当前情境。\n    其实就是减少干扰，营造学习的良好环境。控制注意力，有助于我们更好的学习。\n    记住这三件事情：1.学会安抚喋喋不休的L型思维；2主动在前进中思考和增强思想，即使是不成熟的；3明确情境切换的昂贵代价，尽可能的避免。\n# 超越专家\n    保持好奇心，学习新知识，成为新的“新手”。认识你自己，认识当前时刻，认识你所处的情境。自由的代价是永远提高警惕。\n\n\n","slug":"programmer-thought","published":1,"updated":"2018-04-27T04:11:03.364Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczp2000ye4rw357hwar7","content":"<p>这是一本关于训练程序员思维的书，当然也不仅仅局限于此。各行各业的本质很多都是相同。在本书中，作者提出了程序员的两大重要能力：沟通能力以及学习和思考能力。同时作者也提出了情境的重要性，因为事物都之间都是互相联系的，关注情境才能把握大局。<br><img src=\"/img/programmer.png\" alt=\"programmer thought\"></p>\n<a id=\"more\"></a>\n<h1 id=\"介绍从新手到专家的历程\"><a href=\"#介绍从新手到专家的历程\" class=\"headerlink\" title=\"介绍从新手到专家的历程\"></a>介绍从新手到专家的历程</h1><pre><code>德雷福斯模型:\n新手：严重依赖与规则，只能按照规则行事，不能独立的思考以解决问题。\n高级新手：没有全局思维，只关注自己的工作部分。\n胜任者：可以独立解决问题，也开始思考如何解决新的问题，过于依赖以前的经验，缺乏反思和自我纠正。\n精通：能够自我纠正，反思，并且改进，以期做得更好。\n专家：总是不断的寻找更好的方法和方式去做事，有丰富的经验，可以在恰当的情境中选取和应用这些经验。专家根据直觉工作。专家知道哪些是无关紧要的细节，哪些是非常重要的细节。专家非常擅长做有针对性的特征匹配。举例说明，一个众所周知的极限编程方法经验之谈是“测试一切可能出错的东西”。对于新手来说，这只是一个指令清单。测试什么？是所有的setter和getter方法，还是只是打印语句?他们最终会测试所有无关的东西。但是处于精通水平的人员知道，什么地方有可能出错，或者更确切的说，什么地方非常有可能出错。他们具有经验和判断力，能够理解这句格言在情境中意味着什么。事实证明，理解情境是成为专家的关键。\n新手到专家的转变，最重要的三个变化是：从依赖规则到依赖直觉；观念的转变，问题已不再是一个相关度等同的所有单元的集合体，而是一个完整和独特的整体，其中只有某些单元是相关的；最后，从问题的旁观者转变为问题设计的系统本身的一部分。\n诀窍：专家依赖直觉。知道你不知道什么。通过观察和模仿来学习。学习如何学习的技能。\n</code></pre><h1 id=\"认识你的大脑\"><a href=\"#认识你的大脑\" class=\"headerlink\" title=\"认识你的大脑\"></a>认识你的大脑</h1><pre><code>大脑的结构：单总线，双CPU。左右脑的区别，一个处理逻辑的线性的L型，一个则是感性的非线性的R型。这两种模式都需要：R型对直觉、问题解决和创造性非常重要；L型让你细致工作并实现目标。R型侧重全局，L型则关注局部。R型是异步处理任务的，他实时的记录存储着我们所感知的一切，但是并没有建立索引，换言之，我们见过的一切实物，可能都已经深深的印在脑海中，只是大脑认为这些不重要，因而没有被立即索引，就被抛在脑后了，当哪天我们在努力思考解决一个问题的时候，R型就会在脑海里异步搜索，并在某个时刻，以灵光一闪的惊喜给你答案。因此，我们需要7*24记录想法。\n诀窍：综合学习和分析学习并重。\n</code></pre><h1 id=\"利用右脑\"><a href=\"#利用右脑\" class=\"headerlink\" title=\"利用右脑\"></a>利用右脑</h1><pre><code>既然右脑（R型）如此重要，那么我们如何来训练，以期充分地发掘它的潜力呢？R型开路，L型紧跟。R型只能邀请，不能强制命令。\n举例：乐高积木的角色扮演。攀岩的例子，教练先让我们体验了一把真正的攀岩，然后再来解释其中的技巧和关键。这实际上是建立了从R型到L型的转换\n诀窍：增加感官体验以促进大脑的使用。R型开路，L型紧跟。使用隐喻作为R型和L型的融合之所。晨写日志。离开键盘去解决难题。改变解决问题的角度。培养快速的洞察能力，寻找不相关事物之间的关系或者类比。\n</code></pre><h1 id=\"调试大脑\"><a href=\"#调试大脑\" class=\"headerlink\" title=\"调试大脑\"></a>调试大脑</h1><pre><code>如何调试大脑：认知偏见，思维如何被误导；时代影响，同代人如何影响你；个性倾向，个性如何影响思维；硬件故障，大脑较老区域如何压制脚聪明的区域。\n诀窍：像高级动物一样行动，请做深呼吸，而不要张口嘶鸣。相信直觉，但是要验证。\n</code></pre><h1 id=\"积极学习\"><a href=\"#积极学习\" class=\"headerlink\" title=\"积极学习\"></a>积极学习</h1><pre><code>大脑不是一个用于填充的容器，而是一束需要点燃的火焰。\n瞄准SMART目标。SMART代表具体的、可度量的、可实现的、相关的和时间可控的（Specific,Measurable,Achieveable,Relevant and Time-boxed）..使用你的原生学习模式：视觉型，听觉型和动觉型。使用增强的学习方法，既然已经建立了主动学习的良好框架，我们需要看看学习本身。以下是好方法：\n主动阅读和总结书面材料的更好方式：使用SQ3R法主动阅读，调查（Survey）：扫描目录和每章总结，得出总体看法；问题（Question）：记录所有的问题；阅读（Read）:阅读全部内容；复述（Recite）：总结，做笔记，用自己的话来描述；回顾（Review）：重读，拓展笔记，与同时讨论。具体例子：假设我正在阅读一本有关于新编程语言D,Erlang或者Ruby的书。我翻阅目录，看看书的主要内容。噢，一些语法的介绍，几个简单项目，还有我目前不感兴趣的高级特性。嗯，它是单继承、多继承还是混合的？我想知道迭代器在该语言中是怎么用的？如何创建和管理包或者模块？运行时性能如何？接下来看书-如果可能的话就多看点，如果时间紧的话就少看点。接下来是复述，即改写。整个事件流听起来很熟悉，是吗？我想它清晰的反映了R型到L型的转换，就像攀岩体验一样，首先是一种全盘、浅显但是广泛的调查，然后转换到传统的L型活动，扩大到多重感官的参与（讨论，笔记，图片，隐喻等。）\n使用思维导图探索和发现模式和关系。 手写思维导图，更加的形象，易于被大脑（R型）接受。\n以教代学。和橡皮鸭聊天。学习某项实物的最简单和有效的方法就是尝试教别人。\n诀窍：写文档的过程比文档本身更重要。观察，实践，教学。\n</code></pre><h1 id=\"积累经验\"><a href=\"#积累经验\" class=\"headerlink\" title=\"积累经验\"></a>积累经验</h1><pre><code>积累经验是学习和成长的关键--我们通过实践的方法学习，效果最好。运用内在诀窍的关键要素：不要把精力放在纠正一个一个的细节上，只需要具有意识。举例：在采取纠正行动之前，先知道“这是什么”对于调试非常重要。太多的程序员往往没有完全明白正真的错误是什么就着急修正它。匆忙的做出判断或者过早的就进行修补。你需要首先完全明白系统的原理，然后在判断哪部分错了，最后提供解决方案。现在闭上眼睛，想象一下错误代码的位置。把它看作是地震的震中，你可能感觉到地面到处在抖动，但是震中最为明显。出错的代码应该是什么样的？周围的代码呢？\n诀窍：为了更好的学习，请更好的玩。从相似点中学习，从差异中忘却。利用大脑模拟成功，像专家一样学习。\n</code></pre><h1 id=\"控制注意力\"><a href=\"#控制注意力\" class=\"headerlink\" title=\"控制注意力\"></a>控制注意力</h1><pre><code>通过以下三点更好的管理思维：增强注意力，管理你的知识，优化当前情境。\n其实就是减少干扰，营造学习的良好环境。控制注意力，有助于我们更好的学习。\n记住这三件事情：1.学会安抚喋喋不休的L型思维；2主动在前进中思考和增强思想，即使是不成熟的；3明确情境切换的昂贵代价，尽可能的避免。\n</code></pre><h1 id=\"超越专家\"><a href=\"#超越专家\" class=\"headerlink\" title=\"超越专家\"></a>超越专家</h1><pre><code>保持好奇心，学习新知识，成为新的“新手”。认识你自己，认识当前时刻，认识你所处的情境。自由的代价是永远提高警惕。\n</code></pre>","site":{"data":{}},"excerpt":"<p>这是一本关于训练程序员思维的书，当然也不仅仅局限于此。各行各业的本质很多都是相同。在本书中，作者提出了程序员的两大重要能力：沟通能力以及学习和思考能力。同时作者也提出了情境的重要性，因为事物都之间都是互相联系的，关注情境才能把握大局。<br><img src=\"/img/programmer.png\" alt=\"programmer thought\"></p>","more":"<h1 id=\"介绍从新手到专家的历程\"><a href=\"#介绍从新手到专家的历程\" class=\"headerlink\" title=\"介绍从新手到专家的历程\"></a>介绍从新手到专家的历程</h1><pre><code>德雷福斯模型:\n新手：严重依赖与规则，只能按照规则行事，不能独立的思考以解决问题。\n高级新手：没有全局思维，只关注自己的工作部分。\n胜任者：可以独立解决问题，也开始思考如何解决新的问题，过于依赖以前的经验，缺乏反思和自我纠正。\n精通：能够自我纠正，反思，并且改进，以期做得更好。\n专家：总是不断的寻找更好的方法和方式去做事，有丰富的经验，可以在恰当的情境中选取和应用这些经验。专家根据直觉工作。专家知道哪些是无关紧要的细节，哪些是非常重要的细节。专家非常擅长做有针对性的特征匹配。举例说明，一个众所周知的极限编程方法经验之谈是“测试一切可能出错的东西”。对于新手来说，这只是一个指令清单。测试什么？是所有的setter和getter方法，还是只是打印语句?他们最终会测试所有无关的东西。但是处于精通水平的人员知道，什么地方有可能出错，或者更确切的说，什么地方非常有可能出错。他们具有经验和判断力，能够理解这句格言在情境中意味着什么。事实证明，理解情境是成为专家的关键。\n新手到专家的转变，最重要的三个变化是：从依赖规则到依赖直觉；观念的转变，问题已不再是一个相关度等同的所有单元的集合体，而是一个完整和独特的整体，其中只有某些单元是相关的；最后，从问题的旁观者转变为问题设计的系统本身的一部分。\n诀窍：专家依赖直觉。知道你不知道什么。通过观察和模仿来学习。学习如何学习的技能。\n</code></pre><h1 id=\"认识你的大脑\"><a href=\"#认识你的大脑\" class=\"headerlink\" title=\"认识你的大脑\"></a>认识你的大脑</h1><pre><code>大脑的结构：单总线，双CPU。左右脑的区别，一个处理逻辑的线性的L型，一个则是感性的非线性的R型。这两种模式都需要：R型对直觉、问题解决和创造性非常重要；L型让你细致工作并实现目标。R型侧重全局，L型则关注局部。R型是异步处理任务的，他实时的记录存储着我们所感知的一切，但是并没有建立索引，换言之，我们见过的一切实物，可能都已经深深的印在脑海中，只是大脑认为这些不重要，因而没有被立即索引，就被抛在脑后了，当哪天我们在努力思考解决一个问题的时候，R型就会在脑海里异步搜索，并在某个时刻，以灵光一闪的惊喜给你答案。因此，我们需要7*24记录想法。\n诀窍：综合学习和分析学习并重。\n</code></pre><h1 id=\"利用右脑\"><a href=\"#利用右脑\" class=\"headerlink\" title=\"利用右脑\"></a>利用右脑</h1><pre><code>既然右脑（R型）如此重要，那么我们如何来训练，以期充分地发掘它的潜力呢？R型开路，L型紧跟。R型只能邀请，不能强制命令。\n举例：乐高积木的角色扮演。攀岩的例子，教练先让我们体验了一把真正的攀岩，然后再来解释其中的技巧和关键。这实际上是建立了从R型到L型的转换\n诀窍：增加感官体验以促进大脑的使用。R型开路，L型紧跟。使用隐喻作为R型和L型的融合之所。晨写日志。离开键盘去解决难题。改变解决问题的角度。培养快速的洞察能力，寻找不相关事物之间的关系或者类比。\n</code></pre><h1 id=\"调试大脑\"><a href=\"#调试大脑\" class=\"headerlink\" title=\"调试大脑\"></a>调试大脑</h1><pre><code>如何调试大脑：认知偏见，思维如何被误导；时代影响，同代人如何影响你；个性倾向，个性如何影响思维；硬件故障，大脑较老区域如何压制脚聪明的区域。\n诀窍：像高级动物一样行动，请做深呼吸，而不要张口嘶鸣。相信直觉，但是要验证。\n</code></pre><h1 id=\"积极学习\"><a href=\"#积极学习\" class=\"headerlink\" title=\"积极学习\"></a>积极学习</h1><pre><code>大脑不是一个用于填充的容器，而是一束需要点燃的火焰。\n瞄准SMART目标。SMART代表具体的、可度量的、可实现的、相关的和时间可控的（Specific,Measurable,Achieveable,Relevant and Time-boxed）..使用你的原生学习模式：视觉型，听觉型和动觉型。使用增强的学习方法，既然已经建立了主动学习的良好框架，我们需要看看学习本身。以下是好方法：\n主动阅读和总结书面材料的更好方式：使用SQ3R法主动阅读，调查（Survey）：扫描目录和每章总结，得出总体看法；问题（Question）：记录所有的问题；阅读（Read）:阅读全部内容；复述（Recite）：总结，做笔记，用自己的话来描述；回顾（Review）：重读，拓展笔记，与同时讨论。具体例子：假设我正在阅读一本有关于新编程语言D,Erlang或者Ruby的书。我翻阅目录，看看书的主要内容。噢，一些语法的介绍，几个简单项目，还有我目前不感兴趣的高级特性。嗯，它是单继承、多继承还是混合的？我想知道迭代器在该语言中是怎么用的？如何创建和管理包或者模块？运行时性能如何？接下来看书-如果可能的话就多看点，如果时间紧的话就少看点。接下来是复述，即改写。整个事件流听起来很熟悉，是吗？我想它清晰的反映了R型到L型的转换，就像攀岩体验一样，首先是一种全盘、浅显但是广泛的调查，然后转换到传统的L型活动，扩大到多重感官的参与（讨论，笔记，图片，隐喻等。）\n使用思维导图探索和发现模式和关系。 手写思维导图，更加的形象，易于被大脑（R型）接受。\n以教代学。和橡皮鸭聊天。学习某项实物的最简单和有效的方法就是尝试教别人。\n诀窍：写文档的过程比文档本身更重要。观察，实践，教学。\n</code></pre><h1 id=\"积累经验\"><a href=\"#积累经验\" class=\"headerlink\" title=\"积累经验\"></a>积累经验</h1><pre><code>积累经验是学习和成长的关键--我们通过实践的方法学习，效果最好。运用内在诀窍的关键要素：不要把精力放在纠正一个一个的细节上，只需要具有意识。举例：在采取纠正行动之前，先知道“这是什么”对于调试非常重要。太多的程序员往往没有完全明白正真的错误是什么就着急修正它。匆忙的做出判断或者过早的就进行修补。你需要首先完全明白系统的原理，然后在判断哪部分错了，最后提供解决方案。现在闭上眼睛，想象一下错误代码的位置。把它看作是地震的震中，你可能感觉到地面到处在抖动，但是震中最为明显。出错的代码应该是什么样的？周围的代码呢？\n诀窍：为了更好的学习，请更好的玩。从相似点中学习，从差异中忘却。利用大脑模拟成功，像专家一样学习。\n</code></pre><h1 id=\"控制注意力\"><a href=\"#控制注意力\" class=\"headerlink\" title=\"控制注意力\"></a>控制注意力</h1><pre><code>通过以下三点更好的管理思维：增强注意力，管理你的知识，优化当前情境。\n其实就是减少干扰，营造学习的良好环境。控制注意力，有助于我们更好的学习。\n记住这三件事情：1.学会安抚喋喋不休的L型思维；2主动在前进中思考和增强思想，即使是不成熟的；3明确情境切换的昂贵代价，尽可能的避免。\n</code></pre><h1 id=\"超越专家\"><a href=\"#超越专家\" class=\"headerlink\" title=\"超越专家\"></a>超越专家</h1><pre><code>保持好奇心，学习新知识，成为新的“新手”。认识你自己，认识当前时刻，认识你所处的情境。自由的代价是永远提高警惕。\n</code></pre>"},{"title":"Prometheus 监控体系","date":"2018-03-25T07:48:29.000Z","_content":"## 1 概述\n\n### 1.1 主要功能\n\n- 多维 [数据模型](https://prometheus.io/docs/concepts/data_model/)（时序由 metric 名字和 k/v 的 labels 构成）。\n- 灵活的查询语句（[PromQL](https://prometheus.io/docs/querying/basics/)）。\n- 无依赖存储，支持 local 和 remote 不同模型。\n- 采用 http 协议，使用 pull 模式，拉取数据，简单易懂。\n- 监控目标，可以采用服务发现或静态配置的方式。\n- 支持多种统计数据模型，图形化友好。\n\n### 1.2 核心组件\n\n- [Prometheus Server](https://github.com/prometheus/prometheus)， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。\n- [client libraries](https://prometheus.io/docs/instrumenting/clientlibs/)，用于对接 Prometheus Server, 可以查询和上报数据。\n- [push gateway](https://github.com/prometheus/pushgateway) ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。\n- 各种汇报数据的 [exporters](https://prometheus.io/docs/instrumenting/exporters/) ，例如汇报机器数据的 node_exporter,  汇报 MongoDB 信息的 [MongoDB exporter](https://github.com/dcu/mongodb_exporter) 等等。\n- 用于告警通知管理的 [alertmanager](https://github.com/prometheus/alertmanager) 。\n\n### 1.3 基础架构\n\n一图胜千言，先来张官方的架构图\n\n![img](/img/prometheus1.png)\n\n<!-- more -->\n\n从这个架构图，也可以看出 Prometheus 的主要模块包含， Server,  Exporters, Pushgateway, PromQL, Alertmanager, WebUI 等。\n\n它大致使用逻辑是这样：\n\n1. Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。\n2. 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。\n3. Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。\n4. Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。\n5. 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。\n\n### 1.4 注意\n\n- Prometheus 的数据是基于时序的 float64 的值，如果你的数据值有更多类型，无法满足。\n- Prometheus 不适合做审计计费，因为它的数据是按一定时间采集的，关注的更多是系统的运行瞬时状态以及趋势，即使有少量数据没有采集也能容忍，但是审计计费需要记录每个请求，并且数据长期存储，这个和 Prometheus 无法满足，可能需要采用专门的审计系统。\n\n\n\n## 2 BO关注项\n\n### 2.1 数据收集方式\n\n使用 pull 模式，拉取数据。\n\n\n\n### 2.2 数据格式\n\nPrometheus 时序格式与 [OpenTSDB](http://opentsdb.net/) 相似：\n\n```\n<metric name>{<label name>=<label value>, ...}\n\n```\n\n其中包含时序名字以及时序的标签。\n\n\n\n#### 2.2.1 时序 4 种类型\n\nPrometheus 时序数据分为 [Counter](https://prometheus.io/docs/concepts/metric_types/#counter), [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge), [Histogram](https://prometheus.io/docs/concepts/metric_types/#histogram), [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) 四种类型。\n\n##### 2.2.1.1 Counter\n\nCounter 表示收集的数据是按照某个趋势（增加／减少）一直变化的，我们往往用它记录服务请求总量，错误总数等。\n\n例如 Prometheus server 中 `http_requests_total`,  表示 Prometheus 处理的 http 请求总数，我们可以使用 `delta`, 很容易得到任意区间数据的增量，这个会在 PromQL 一节中细讲。\n\n```\n# HELP http_requests_total Total number of HTTP requests made.\n# TYPE http_requests_total counter\nhttp_requests_total{code=\"200\",handler=\"alerts\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"config\",method=\"get\"} 1\nhttp_requests_total{code=\"200\",handler=\"flags\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"graph\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"label_values\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"prometheus\",method=\"get\"} 24755\nhttp_requests_total{code=\"200\",handler=\"query\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"static\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"status\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"targets\",method=\"get\"} 4\nhttp_requests_total{code=\"304\",handler=\"static\",method=\"get\"} 4\n\n```\n\n##### 2.2.1.2 Gauge\n\nGauge 表示搜集的数据是一个瞬时的，与时间没有关系，可以任意变高变低，往往可以用来记录内存使用率、磁盘使用率等。\n\n例如 Prometheus server 中 `go_goroutines`,  表示 Prometheus 当前 goroutines 的数量。\n\n```\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 100\n\n```\n\n##### 2.2.1.3 Histogram\n\nHistogram 由 `<basename>_bucket{le=\"<upper inclusive bound>\"}`，`<basename>_bucket{le=\"+Inf\"}`, `<basename>_sum`，`<basename>_count` 组成，主要用于表示一段时间范围内对数据进行采样，（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常我们用它计算分位数的直方图。\n\n例如 Prometheus server 中 `prometheus_local_storage_series_chunks_persisted`,  表示 Prometheus 中每个时序需要存储的 chunks 数量，我们可以用它计算待持久化的数据的分位数。\n\n```\n# HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction\n# TYPE prometheus_tsdb_compaction_chunk_range histogram\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"100\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"400\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1600\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6400\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"25600\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"102400\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"409600\"} 605\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1.6384e+06\"} 612\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6.5536e+06\"} 126358\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"2.62144e+07\"} 126358\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"+Inf\"} 126358\nprometheus_tsdb_compaction_chunk_range_sum 2.25313627417e+11\nprometheus_tsdb_compaction_chunk_range_count 126358\n\n```\n\n##### 2.2.1.4 Summary\n\nSummary 和 Histogram 类似，由 `<basename>{quantile=\"<φ>\"}`，`<basename>_sum`，`<basename>_count` 组成，主要用于表示一段时间内数据采样结果，（通常是请求持续时间或响应大小），它直接存储了 quantile 数据，而不是根据统计区间计算出来的。\n\n\n\n例如 Prometheus server 中 `prometheus_target_interval_length_seconds`。\n\n```\n# HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.\n# TYPE prometheus_target_interval_length_seconds summary\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.01\"} 14.999987534\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.05\"} 14.999987534\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.5\"} 15.000020575\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.9\"} 15.000045415\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.99\"} 15.000050555\nprometheus_target_interval_length_seconds_sum{interval=\"15s\"} 371280.61110144516\nprometheus_target_interval_length_seconds_count{interval=\"15s\"} 24752\n\n```\n\n##### 2.2.1.5 Histogram vs Summary\n\n- 都包含 `<basename>_sum`，`<basename>_count`\n- Histogram 需要通过 `<basename>_bucket` 计算 quantile, 而 Summary 直接存储了 quantile 的值。\n\n\n\n### 2.2.3 数据存储方式\n\n​\t数据存在promethues自身的数据库，以数据文件的形式存储，有自身的查询方式：promql；详见https://songjiayang.gitbooks.io/prometheus/content/promql/summary.html\n\n### 2.2.4 数据输出方式\n\n​\tagent：被动拉取；\n\n​\tpromethues server：主动拉取客户端的数据。promethues将拉取到的数据存到data/目录。（除了 promethues 前台的PromQ查询页面，应该有某种工具可以直接在命令行查询promethues的历史数据（暂未找到）；多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式（工具未研究过）。）\n\n### 2.2.5 agent部署方式\n\n​\tpromethues未提供自动部署agent的功能。\n\n### 2.2.6 任务下发方式\n\n​\tagent每个周期固定采集设备的指定指标，若要自定义采集某些指标则需要修改agent源码。\n\n​\tpromethues server拉取数据的任务在prometheus.yml配置。\n\n## 3 promethues组件及部署\n\n### 3.1 promethues server\n\n#### 3.1.1 部署\n\n​\ttar包解压即可用\n\n#### 3.1.2 prometheus.yml配置举例\n\n```\nglobal:\n  scrape_interval:     15s # By default, scrape targets every 15 seconds.\n  evaluation_interval: 15s # By default, scrape targets every 15 seconds.\n\nrule_files:\n  - \"rules/node.rules\"\n\nscrape_configs:\n  - job_name: 'prometheus'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9090']\n\n  - job_name: 'node'\n    scrape_interval: 8s\n    static_configs:\n      - targets: ['127.0.0.1:9100', '127.0.0.12:9100']\n\n  - job_name: 'mysqld'\n    static_configs:\n      - targets: ['127.0.0.1:9104']\n  - job_name: 'memcached'\n    static_configs:\n      - targets: ['127.0.0.1:9150']\n\n```\n\n#### 3.1.3 命令\n\n[chenrj@kfapp01 prometheus-2.0.0.linux-amd64]$ ./prometheus -h\nusage: prometheus [<flags>]\n\nThe Prometheus monitoring server\n\nFlags:\n  -h, --help                     Show context-sensitive help (also try --help-long and --help-man).\n#### 3.1.4 前台地址\n\n​\thttp://192.168.7.40:9090/graph\n\n​\t默认9090端口\n\n### 3.2 grafana\n\n​       [http://192.168.7.40:3000](http://192.168.7.40:3000/)\n\n​       端口默认3000，\n\n​       用户密码： admin/admin\n\n​\t./grafana-server\n\n### 3.3 主机节点\n\n​\thttp://10.140.20.142:9100/metrics\n\n### 3.4 redis节点\n\n​\thttp://10.140.20.143:9121/metrics \n\n### 3.5 elasticsearch节点\n\n​\thttp://10.140.20.146:9108/metrics\n\n## 4 数据查询\n\n### 4.1 http方式查询promethues数据\n\n​\thttps://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata\n\n#### 4.1.1 即时查询\n\n```\nGET /api/v1/query\n\n```\n\n**URL查询参数：**\n\n- `query=<string>`：普罗米修斯表达查询字符串。\n- `time=<rfc3339 | unix_timestamp>`：评估时间戳。可选的。\n- `timeout=<duration>`：评价超时。可选的。默认为，并通过价值上限`-query.timeout`标志。\n\n若省略时间time测试，则默认使用服务器时间\n\n\n\n**例：**查询2018-01-16T03:12:51.781这个时刻go_memstats_frees_total的值\n\n[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl 'http://10.140.20.146:9090/api/v1/query?query=go_memstats_frees_total&time=2018-01-16T03:12:51.781Z'\n{\"status\":\"success\",\"data\":{\"resultType\":\"vector\",\"result\":[{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.142:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5599415948\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.143:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5152870637\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.143:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1385642849\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.143:9121\",\"job\":\"redis_exporter_143\"},\"value\":[1516072371.781,\"159639669\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.144:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5167404030\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.144:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1383957758\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.144:9121\",\"job\":\"redis_exporter_144\"},\"value\":[1516072371.781,\"373190465\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.145:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5124941908\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.145:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1370943258\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.146:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"4850755799\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.146:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1370683906\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"localhost:9090\",\"job\":\"prometheus\"},\"value\":[1516072371.781,\"2299674805\"]}]}}\n\n**注：\"value\":[时间戳,\"对应值\"]**\n\n\n\n#### 4.1.2 范围查询\n\n```\nGET /api/v1/query_range\n\n```\n\n**URL查询参数：**\n\n- `query=<string>`：普罗米修斯表达查询字符串。\n- `start=<rfc3339 | unix_timestamp>`：开始时间戳。\n- `end=<rfc3339 | unix_timestamp>`：结束时间戳。\n- `step=<duration>`：查询分辨率步的宽度。\n- `timeout=<duration>`：评价超时。可选的。默认为，并通过价值上限`-query.timeout`标志。\n\n\n\n例：时间在2018-01-01T20:10:30.781到2018-01-01T20:11:00.781范围内，间隔15秒，up的数据\n\n[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl 'http://10.140.20.146:9090/api/v1/query_range?query=up&start=2018-01-01T20:10:30.781Z&end=2018-01-01T20:11:00.781Z&step=15s'\n{\"status\":\"success\",\"data\":{\"resultType\":\"matrix\",\"result\":[{\"metric\":{\"__name__\":\"up\",\"instance\":\"localhost:9090\",\"job\":\"prometheus\"},\"values\":[[1514837430.781,\"1\"],[1514837445.781,\"1\"],[1514837460.781,\"1\"]]},{\"metric\":{\"__name__\":\"up\",\"instance\":\"localhost:9100\",\"job\":\"node\"},\"values\":[[1514837430.781,\"0\"],[1514837445.781,\"0\"],[1514837460.781,\"0\"]]}]}}\n\n\n\n### 4.2 http查询方式作用未知系列？？\n\n#### Querying metadata\n\n##### Finding series by label matchers\n\nThe following endpoint returns the list of time series that match a certain label set.\n\n```\nGET /api/v1/series\n\n```\n\nURL query parameters:\n\n- `match[]=<series_selector>`: Repeated series selector argument that selects the series to return. At least one `match[]` argument must be provided.\n- `start=<rfc3339 | unix_timestamp>`: Start timestamp.\n- `end=<rfc3339 | unix_timestamp>`: End timestamp.\n\nThe `data` section of the query result consists of a list of objects that contain the label name/value pairs which identify each series.\n\nThe following example returns all series that match either of the selectors `up` or `process_start_time_seconds{job=\"prometheus\"}`:\n\n```\n$ curl -g 'http://localhost:9090/api/v1/series?match[]=up&match[]=process_start_time_seconds{job=\"prometheus\"}'\n{\n   \"status\" : \"success\",\n   \"data\" : [\n      {\n         \"__name__\" : \"up\",\n         \"job\" : \"prometheus\",\n         \"instance\" : \"localhost:9090\"\n      },\n      {\n         \"__name__\" : \"up\",\n         \"job\" : \"node\",\n         \"instance\" : \"localhost:9091\"\n      },\n      {\n         \"__name__\" : \"process_start_time_seconds\",\n         \"job\" : \"prometheus\",\n         \"instance\" : \"localhost:9090\"\n      }\n   ]\n}\n\n```\n\n##### Querying label values\n\nThe following endpoint returns a list of label values for a provided label name:\n\n```\nGET /api/v1/label/<label_name>/values\n\n```\n\nThe `data` section of the JSON response is a list of string label names.\n\nThis example queries for all label values for the `job` label:\n\n```\n$ curl http://localhost:9090/api/v1/label/job/values\n{\n   \"status\" : \"success\",\n   \"data\" : [\n      \"node\",\n      \"prometheus\"\n   ]\n}\n\n```\n\n#### Expression query result formats\n\nExpression queries may return the following response values in the `result` property of the `data` section. `<sample_value>` placeholders are numeric sample values. JSON does not support special float values such as `NaN`, `Inf`, and `-Inf`, so sample values are transferred as quoted JSON strings rather than raw numbers.\n\n##### Range vectors\n\nRange vectors are returned as result type `matrix`. The corresponding `result` property has the following format:\n\n```\n[\n  {\n    \"metric\": { \"<label_name>\": \"<label_value>\", ... },\n    \"values\": [ [ <unix_time>, \"<sample_value>\" ], ... ]\n  },\n  ...\n]\n\n```\n\n##### Instant vectors\n\nInstant vectors are returned as result type `vector`. The corresponding `result` property has the following format:\n\n```\n[\n  {\n    \"metric\": { \"<label_name>\": \"<label_value>\", ... },\n    \"value\": [ <unix_time>, \"<sample_value>\" ]\n  },\n  ...\n]\n\n```\n\n##### Scalars\n\nScalar results are returned as result type `scalar`. The corresponding `result` property has the following format:\n\n```\n[ <unix_time>, \"<scalar_value>\" ]\n\n```\n\n##### Strings\n\nString results are returned as result type `string`. The corresponding `result` property has the following format:\n\n```\n[ <unix_time>, \"<string_value>\" ]\n\n```\n\n#### Targets\n\n> This API is experimental as it is intended to be extended with targets dropped due to relabelling in the future.\n\nThe following endpoint returns an overview of the current state of the Prometheus target discovery:\n\n```\nGET /api/v1/targets\n\n```\n\nCurrently only the active targets are part of the response.\n\n```\n$ curl http://localhost:9090/api/v1/targets\n{\n  \"status\": \"success\",                                                                                                                                [3/11]\n  \"data\": {\n    \"activeTargets\": [\n      {\n        \"discoveredLabels\": {\n          \"__address__\": \"127.0.0.1:9090\",\n          \"__metrics_path__\": \"/metrics\",\n          \"__scheme__\": \"http\",\n          \"job\": \"prometheus\"\n        },\n        \"labels\": {\n          \"instance\": \"127.0.0.1:9090\",\n          \"job\": \"prometheus\"\n        },\n        \"scrapeUrl\": \"http://127.0.0.1:9090/metrics\",\n        \"lastError\": \"\",\n        \"lastScrape\": \"2017-01-17T15:07:44.723715405+01:00\",\n        \"health\": \"up\"\n      }\n    ]\n  }\n}\n\n```\n\n#### Alertmanagers\n\n> This API is experimental as it is intended to be extended with Alertmanagers dropped due to relabelling in the future.\n\nThe following endpoint returns an overview of the current state of the Prometheus alertmanager discovery:\n\n```\nGET /api/v1/alertmanagers\n\n```\n\nCurrently only the active Alertmanagers are part of the response.\n\n```\n$ curl http://localhost:9090/api/v1/alertmanagers\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"activeAlertmanagers\": [\n      {\n        \"url\": \"http://127.0.0.1:9090/api/v1/alerts\"\n      }\n    ]\n  }\n}\n```\n\n\n\n\n\n查询指标标签：\tcurl -g 'http://192.168.7.40:9090/api/v1/series?match[]=up&match[]=process_start_time_seconds{job=\"prometheus\"}'\n\n\n\n查询标签 {\"status\":\"success\",\"data\":[]}[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl http://10.140.20.146:9090/api/v1/label/job/values\n{\"status\":\"success\",\"data\":[\"elasticsearch_exporter\",\"node\",\"prometheus\",\"redis_exporter\",\"redis_exporter_143\",\"redis_exporter_144\"]}\n\n\n\n\n\n### 4.3 查询节点数据\n\n​\t查询节点exporter的所有数据：curl -s http://192.168.7.40:9100/metrics\n\n\n\n## 5 exporter格式\n\n基于协议缓冲区格式 和 文本格式\n\n客户端可以暴露promethues无法解析的其他格式\n\n\n\n### 5.1 基于协议缓冲区格式 和 文本格式 的区别\n\n|                                    | Protocol buffer format                   | Text format                              |\n| ---------------------------------- | ---------------------------------------- | ---------------------------------------- |\n| **Inception**                      | April 2014                               | April 2014                               |\n| **Supported in**                   | Prometheus version `>=0.4.0`             | Prometheus version `>=0.4.0`             |\n| **Transmission**                   | HTTP                                     | HTTP                                     |\n| **Encoding**                       | [32-bit varint-encoded record length-delimited](https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/AbstractMessageLite#writeDelimitedTo(java.io.OutputStream)) Protocol Buffer messages of type [io.prometheus.client.MetricFamily](https://github.com/prometheus/client_model/blob/086fe7ca28bde6cec2acd5223423c1475a362858/metrics.proto#L76-%20%20L81) | UTF-8, `\\n` line endings                 |\n| **HTTP Content-Type**              | `application/vnd.google.protobuf; proto=io.prometheus.client.MetricFamily; encoding=delimited` | `text/plain; version=0.0.4` (A missing `version` value will lead to a fall-back to the most recent text format version.) |\n| **Optional HTTP Content-Encoding** | `gzip`                                   | `gzip`                                   |\n| **Advantages**                     | Cross-platformSizeEncoding and decoding costsStrict schemaSupports concatenation and theoretically streaming (only server-side behavior would need to change) | Human-readableEasy to assemble, especially for minimalistic cases (no nesting required)Readable line by line (with the exception of type hints and docstrings) |\n| **Limitations**                    | Not human-readable                       | VerboseTypes and docstrings not integral part of the syntax, meaning little-to-nonexistent metric contract validationParsing cost |\n| **Supported metric primitives**    | CounterGaugeHistogramSummaryUntyped      | CounterGaugeHistogramSummaryUntyped      |\n| **Compatibility**                  | Version `0.0.3` protocol buffers are also valid version `0.0.4` protocol buffers. | none                                     |\n\n\n\n### 5.2 基于协议缓冲区格式\n\n​\tReproducible sorting of the protocol buffer fields in repeated expositions is preferred but not required, i.e. do not sort if the computational cost is prohibitive.\n\n​\tEach `MetricFamily` within the same exposition must have a unique name. Each `Metric` within the same `MetricFamily` must have a unique set of `LabelPair` fields. Otherwise, the ingestion behavior is undefined.\n\n### 5.3 文本类型格式\n\n​\t＃打头的是注释行（除非＃之后的第一个标记是HELP或TYPE）。\n\n​\tHELP行：可能包含任何UTF-8字符序列（在指标名称之后），但反斜杠和换行字符必须分别转义为`\\\\`和`\\ n`。对于相同的指标名称，只能有一条HELP行，一个指标只能有一个HELP行。\n\nTYPE行：TPYE后的第一个参数是指标名，第二个参数是数据类型（可以是counter, gauge, histogram, summary,  untyped）。相同的指标名称，只能有一个TYPE行。如果指标名称没有TYPE行，则该类型设置为无类型。\n\n格式：\n\n```\nmetric_name [\n  \"{\" label_name \"=\" `\"` label_value `\"` { \",\" label_name \"=\" `\"` label_value `\"` } [ \",\" ] \"}\"\n] value [ timestamp ]\n```\n\nlabel_value可以是任何UTF-8格式的内容，但反斜杠、双引号、换行符 必须转义成\n\n```\n\\\\  \\\"  \\\\n\n```\n\nhistogram（直方图）  summary（汇总）类型的特别格式：\n\n1. 需要单独一行xxx_sum；\n2. 需要单独一行xxx_count；\n3. Each quantile of a summary named x is given as a separate sample line with the same name x and a label {quantile=\"y\"}；\n4. A histogram must have a bucket with {le=\"+Inf\"}. Its value must be identical to the value of x_count；\n5. histogram类型必须要有{le=\"+Inf\"}，并且值要和xxx_count一致；\n\n\n\n### 5.4 文本类型格式举例\n\n```\n# HELP http_requests_total The total number of HTTP requests.\n# TYPE http_requests_total counter\nhttp_requests_total{method=\"post\",code=\"200\"} 1027 1395066363000\nhttp_requests_total{method=\"post\",code=\"400\"}    3 1395066363000\n\n# Escaping in label values:\nmsdos_file_access_time_seconds{path=\"C:\\\\DIR\\\\FILE.TXT\",error=\"Cannot find file:\\n\\\"FILE.TXT\\\"\"} 1.458255915e9\n\n# Minimalistic line:\nmetric_without_timestamp_and_labels 12.47\n\n# A weird metric from before the epoch:\nsomething_weird{problem=\"division by zero\"} +Inf -3982045\n\n# A histogram, which has a pretty complex representation in the text format:\n# HELP http_request_duration_seconds A histogram of the request duration.\n# TYPE http_request_duration_seconds histogram\nhttp_request_duration_seconds_bucket{le=\"0.05\"} 24054\nhttp_request_duration_seconds_bucket{le=\"0.1\"} 33444\nhttp_request_duration_seconds_bucket{le=\"0.2\"} 100392\nhttp_request_duration_seconds_bucket{le=\"0.5\"} 129389\nhttp_request_duration_seconds_bucket{le=\"1\"} 133988\nhttp_request_duration_seconds_bucket{le=\"+Inf\"} 144320\nhttp_request_duration_seconds_sum 53423\nhttp_request_duration_seconds_count 144320\n\n# Finally a summary, which has a complex representation, too:\n# HELP rpc_duration_seconds A summary of the RPC duration in seconds.\n# TYPE rpc_duration_seconds summary\nrpc_duration_seconds{quantile=\"0.01\"} 3102\nrpc_duration_seconds{quantile=\"0.05\"} 3272\nrpc_duration_seconds{quantile=\"0.5\"} 4773\nrpc_duration_seconds{quantile=\"0.9\"} 9001\nrpc_duration_seconds{quantile=\"0.99\"} 76656\nrpc_duration_seconds_sum 1.7560473e+07\nrpc_duration_seconds_count 2693\n```\n\n\n\n## 6 导出器exporter\n\n### 6.1 概述\n\n​\t指标名，一般为导出程序名称作为前缀，例如， haproxy_up；\n\n​\t度量标准必须使用基本单位（例如秒，字节），并保留将其转换为更具可读性的图形工具；\n\n \t指标有效字符：`[a-zA-Z0-9:_]` ，其他任何字符都要用下划线_代替；\n\n​\t指标后缀`_sum`, `_count`, `_bucket` and `_total` 只可用在Summaries、 Histograms 、 Counters\n\n\n\n## 7 告警alertmanager程序\n\n​\t概述：\n\n​\t\tpromethues：根据配置文件prometheus.yml的rule_files告警规则，将告警信息存到promethues的磁盘，供promethues的前台页面查看；根据配置文件prometheus.yml的alerting（配置altermanager进程的ip 端口信息），将告警信息发送altermanager进程上。\n\n​\t\taltermanager：接收promethues发来的告警信息，存在磁盘中供altermanager进程的前台查看；同时根据altermanager的告警配置文件simple.yml发送邮件等提醒。\n\n\n\n### 7.1 promethues告警配置举例\n\n![](/img/promethues-alarm.png)\n\n### 7.2 promethues告警规则配置文件举例\n\n![](/img/rule_file.png)\n\nalert：自定义的告警含义简写\n\nexpor：告警条件，如上图的node_forks为具体mertics里的指标\n\nfor：周期\n\nlabels：severity，在alertmanager前台页面可以根据severity条件来查询告警信息\n\nannotations：summary写些较详细的告警信息\n\n### 7.3 alertmanager告警发送邮件提示\n\n![](/img/email_1.png)\n\n![](/img/email_2.png)\n\n\n\n### 7.4 启动alertmanager\n\n nohup ./alertmanager --config.file=simple.yml &\n\nalertmanager前台：http://192.168.7.176:9093/\n\n### 7.5通过其他方式告警\n\n#### hipchat_config：\n\n​\t是一款能够在苹果mac平台上运行的社交聊天软件，HipChat的功能和QQ相似，集聊天、视频、语音等功能于一身，不同之处在于HipChat界面更加的简洁、操作更加的流畅。\n\n#### pagerduty_config：\n\n​\t是一款能够在服务器出问题时发送提醒的软件。在发生问题时，提醒的方式包括屏幕显示、电话呼叫、短信通知、电邮通知等，而且在无人应答时还会自动将提醒级别提高。PagerDuty 不是免费的。\n\n#### pushover_config：\n\n​\t是一款网络通知推送服务，类似ifttt或脚本服务，你可以将需要推送的服务设置好后，遇到情况将把通知自动推送到你的[安卓手机](http://www.onlinedown.net/soft/222292.htm)。\n\n#### slack_config：\n\n​\tslack是聊天群组 + 大规模工具集成 + 文件整合 + 统一搜索。截至2014年底，Slack 已经整合了电子邮件、短信、[Google](https://baike.baidu.com/item/Google) Drives、[Twitter](https://baike.baidu.com/item/Twitter)、Trello、Asana、[GitHub](https://baike.baidu.com/item/GitHub) 等 65 种工具和服务，可以把各种碎片化的企业沟通和协作集中到一起。\n\n```\n# Whether or not to notify about resolved alerts.\n[ send_resolved: <boolean> | default = false ]\n\n# The Slack webhook URL.\n[ api_url: <secret> | default = global.slack_api_url ]\n\n# The channel or user to send notifications to.\nchannel: <tmpl_string>\n\n# API request data as defined by the Slack webhook API.\n[ color: <tmpl_string> | default = '{{ if eq .Status \"firing\" }}danger{{ else }}good{{ end }}' ]\n[ username: <tmpl_string> | default = '{{ template \"slack.default.username\" . }}' ]\n[ title: <tmpl_string> | default = '{{ template \"slack.default.title\" . }}' ]\n[ title_link: <tmpl_string> | default = '{{ template \"slack.default.titlelink\" . }}' ]\n[ icon_emoji: <tmpl_string> ]\n[ icon_url: <tmpl_string> ]\n[ pretext: <tmpl_string> | default = '{{ template \"slack.default.pretext\" . }}' ]\n[ text: <tmpl_string> | default = '{{ template \"slack.default.text\" . }}' ]\n[ fallback: <tmpl_string> | default = '{{ template \"slack.default.fallback\" . }}' ]\n\n# The HTTP client's configuration.\n[ http_config: <http_config> | default = global.http_config ]\n```\n\n\n\n#### opsgenie_config ：\n\n​\t集成电话短信邮件等等\n\n#### victorops_config：\n\n​\t聊天应用\n\n#### http_config：\n\n​\tA `http_config` allows configuring the HTTP client that the receiver uses to communicate with HTTP-based API services.\n\n\n\n\n\n## 8 问题笔记\n\n### 8.1已解决\n\n1. prometheus浏览器查询不到exporter指标数据，但是浏览器exporter的mertic有指标数据。原因是时间不同步\n\n\n\n### 8.2 未解决\n\n","source":"_posts/prometheus.md","raw":"---\ntitle: Prometheus 监控体系\ndate: 2018-03-25 15:48:29\ntags: \n - Prometheus\n - Go\ncategories: 技术\n---\n## 1 概述\n\n### 1.1 主要功能\n\n- 多维 [数据模型](https://prometheus.io/docs/concepts/data_model/)（时序由 metric 名字和 k/v 的 labels 构成）。\n- 灵活的查询语句（[PromQL](https://prometheus.io/docs/querying/basics/)）。\n- 无依赖存储，支持 local 和 remote 不同模型。\n- 采用 http 协议，使用 pull 模式，拉取数据，简单易懂。\n- 监控目标，可以采用服务发现或静态配置的方式。\n- 支持多种统计数据模型，图形化友好。\n\n### 1.2 核心组件\n\n- [Prometheus Server](https://github.com/prometheus/prometheus)， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。\n- [client libraries](https://prometheus.io/docs/instrumenting/clientlibs/)，用于对接 Prometheus Server, 可以查询和上报数据。\n- [push gateway](https://github.com/prometheus/pushgateway) ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。\n- 各种汇报数据的 [exporters](https://prometheus.io/docs/instrumenting/exporters/) ，例如汇报机器数据的 node_exporter,  汇报 MongoDB 信息的 [MongoDB exporter](https://github.com/dcu/mongodb_exporter) 等等。\n- 用于告警通知管理的 [alertmanager](https://github.com/prometheus/alertmanager) 。\n\n### 1.3 基础架构\n\n一图胜千言，先来张官方的架构图\n\n![img](/img/prometheus1.png)\n\n<!-- more -->\n\n从这个架构图，也可以看出 Prometheus 的主要模块包含， Server,  Exporters, Pushgateway, PromQL, Alertmanager, WebUI 等。\n\n它大致使用逻辑是这样：\n\n1. Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。\n2. 当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。\n3. Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。\n4. Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。\n5. 可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。\n\n### 1.4 注意\n\n- Prometheus 的数据是基于时序的 float64 的值，如果你的数据值有更多类型，无法满足。\n- Prometheus 不适合做审计计费，因为它的数据是按一定时间采集的，关注的更多是系统的运行瞬时状态以及趋势，即使有少量数据没有采集也能容忍，但是审计计费需要记录每个请求，并且数据长期存储，这个和 Prometheus 无法满足，可能需要采用专门的审计系统。\n\n\n\n## 2 BO关注项\n\n### 2.1 数据收集方式\n\n使用 pull 模式，拉取数据。\n\n\n\n### 2.2 数据格式\n\nPrometheus 时序格式与 [OpenTSDB](http://opentsdb.net/) 相似：\n\n```\n<metric name>{<label name>=<label value>, ...}\n\n```\n\n其中包含时序名字以及时序的标签。\n\n\n\n#### 2.2.1 时序 4 种类型\n\nPrometheus 时序数据分为 [Counter](https://prometheus.io/docs/concepts/metric_types/#counter), [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge), [Histogram](https://prometheus.io/docs/concepts/metric_types/#histogram), [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) 四种类型。\n\n##### 2.2.1.1 Counter\n\nCounter 表示收集的数据是按照某个趋势（增加／减少）一直变化的，我们往往用它记录服务请求总量，错误总数等。\n\n例如 Prometheus server 中 `http_requests_total`,  表示 Prometheus 处理的 http 请求总数，我们可以使用 `delta`, 很容易得到任意区间数据的增量，这个会在 PromQL 一节中细讲。\n\n```\n# HELP http_requests_total Total number of HTTP requests made.\n# TYPE http_requests_total counter\nhttp_requests_total{code=\"200\",handler=\"alerts\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"config\",method=\"get\"} 1\nhttp_requests_total{code=\"200\",handler=\"flags\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"graph\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"label_values\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"prometheus\",method=\"get\"} 24755\nhttp_requests_total{code=\"200\",handler=\"query\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"static\",method=\"get\"} 6\nhttp_requests_total{code=\"200\",handler=\"status\",method=\"get\"} 2\nhttp_requests_total{code=\"200\",handler=\"targets\",method=\"get\"} 4\nhttp_requests_total{code=\"304\",handler=\"static\",method=\"get\"} 4\n\n```\n\n##### 2.2.1.2 Gauge\n\nGauge 表示搜集的数据是一个瞬时的，与时间没有关系，可以任意变高变低，往往可以用来记录内存使用率、磁盘使用率等。\n\n例如 Prometheus server 中 `go_goroutines`,  表示 Prometheus 当前 goroutines 的数量。\n\n```\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 100\n\n```\n\n##### 2.2.1.3 Histogram\n\nHistogram 由 `<basename>_bucket{le=\"<upper inclusive bound>\"}`，`<basename>_bucket{le=\"+Inf\"}`, `<basename>_sum`，`<basename>_count` 组成，主要用于表示一段时间范围内对数据进行采样，（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常我们用它计算分位数的直方图。\n\n例如 Prometheus server 中 `prometheus_local_storage_series_chunks_persisted`,  表示 Prometheus 中每个时序需要存储的 chunks 数量，我们可以用它计算待持久化的数据的分位数。\n\n```\n# HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction\n# TYPE prometheus_tsdb_compaction_chunk_range histogram\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"100\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"400\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1600\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6400\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"25600\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"102400\"} 0\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"409600\"} 605\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"1.6384e+06\"} 612\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"6.5536e+06\"} 126358\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"2.62144e+07\"} 126358\nprometheus_tsdb_compaction_chunk_range_bucket{le=\"+Inf\"} 126358\nprometheus_tsdb_compaction_chunk_range_sum 2.25313627417e+11\nprometheus_tsdb_compaction_chunk_range_count 126358\n\n```\n\n##### 2.2.1.4 Summary\n\nSummary 和 Histogram 类似，由 `<basename>{quantile=\"<φ>\"}`，`<basename>_sum`，`<basename>_count` 组成，主要用于表示一段时间内数据采样结果，（通常是请求持续时间或响应大小），它直接存储了 quantile 数据，而不是根据统计区间计算出来的。\n\n\n\n例如 Prometheus server 中 `prometheus_target_interval_length_seconds`。\n\n```\n# HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.\n# TYPE prometheus_target_interval_length_seconds summary\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.01\"} 14.999987534\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.05\"} 14.999987534\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.5\"} 15.000020575\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.9\"} 15.000045415\nprometheus_target_interval_length_seconds{interval=\"15s\",quantile=\"0.99\"} 15.000050555\nprometheus_target_interval_length_seconds_sum{interval=\"15s\"} 371280.61110144516\nprometheus_target_interval_length_seconds_count{interval=\"15s\"} 24752\n\n```\n\n##### 2.2.1.5 Histogram vs Summary\n\n- 都包含 `<basename>_sum`，`<basename>_count`\n- Histogram 需要通过 `<basename>_bucket` 计算 quantile, 而 Summary 直接存储了 quantile 的值。\n\n\n\n### 2.2.3 数据存储方式\n\n​\t数据存在promethues自身的数据库，以数据文件的形式存储，有自身的查询方式：promql；详见https://songjiayang.gitbooks.io/prometheus/content/promql/summary.html\n\n### 2.2.4 数据输出方式\n\n​\tagent：被动拉取；\n\n​\tpromethues server：主动拉取客户端的数据。promethues将拉取到的数据存到data/目录。（除了 promethues 前台的PromQ查询页面，应该有某种工具可以直接在命令行查询promethues的历史数据（暂未找到）；多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式（工具未研究过）。）\n\n### 2.2.5 agent部署方式\n\n​\tpromethues未提供自动部署agent的功能。\n\n### 2.2.6 任务下发方式\n\n​\tagent每个周期固定采集设备的指定指标，若要自定义采集某些指标则需要修改agent源码。\n\n​\tpromethues server拉取数据的任务在prometheus.yml配置。\n\n## 3 promethues组件及部署\n\n### 3.1 promethues server\n\n#### 3.1.1 部署\n\n​\ttar包解压即可用\n\n#### 3.1.2 prometheus.yml配置举例\n\n```\nglobal:\n  scrape_interval:     15s # By default, scrape targets every 15 seconds.\n  evaluation_interval: 15s # By default, scrape targets every 15 seconds.\n\nrule_files:\n  - \"rules/node.rules\"\n\nscrape_configs:\n  - job_name: 'prometheus'\n    scrape_interval: 5s\n    static_configs:\n      - targets: ['localhost:9090']\n\n  - job_name: 'node'\n    scrape_interval: 8s\n    static_configs:\n      - targets: ['127.0.0.1:9100', '127.0.0.12:9100']\n\n  - job_name: 'mysqld'\n    static_configs:\n      - targets: ['127.0.0.1:9104']\n  - job_name: 'memcached'\n    static_configs:\n      - targets: ['127.0.0.1:9150']\n\n```\n\n#### 3.1.3 命令\n\n[chenrj@kfapp01 prometheus-2.0.0.linux-amd64]$ ./prometheus -h\nusage: prometheus [<flags>]\n\nThe Prometheus monitoring server\n\nFlags:\n  -h, --help                     Show context-sensitive help (also try --help-long and --help-man).\n#### 3.1.4 前台地址\n\n​\thttp://192.168.7.40:9090/graph\n\n​\t默认9090端口\n\n### 3.2 grafana\n\n​       [http://192.168.7.40:3000](http://192.168.7.40:3000/)\n\n​       端口默认3000，\n\n​       用户密码： admin/admin\n\n​\t./grafana-server\n\n### 3.3 主机节点\n\n​\thttp://10.140.20.142:9100/metrics\n\n### 3.4 redis节点\n\n​\thttp://10.140.20.143:9121/metrics \n\n### 3.5 elasticsearch节点\n\n​\thttp://10.140.20.146:9108/metrics\n\n## 4 数据查询\n\n### 4.1 http方式查询promethues数据\n\n​\thttps://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata\n\n#### 4.1.1 即时查询\n\n```\nGET /api/v1/query\n\n```\n\n**URL查询参数：**\n\n- `query=<string>`：普罗米修斯表达查询字符串。\n- `time=<rfc3339 | unix_timestamp>`：评估时间戳。可选的。\n- `timeout=<duration>`：评价超时。可选的。默认为，并通过价值上限`-query.timeout`标志。\n\n若省略时间time测试，则默认使用服务器时间\n\n\n\n**例：**查询2018-01-16T03:12:51.781这个时刻go_memstats_frees_total的值\n\n[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl 'http://10.140.20.146:9090/api/v1/query?query=go_memstats_frees_total&time=2018-01-16T03:12:51.781Z'\n{\"status\":\"success\",\"data\":{\"resultType\":\"vector\",\"result\":[{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.142:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5599415948\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.143:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5152870637\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.143:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1385642849\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.143:9121\",\"job\":\"redis_exporter_143\"},\"value\":[1516072371.781,\"159639669\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.144:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5167404030\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.144:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1383957758\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.144:9121\",\"job\":\"redis_exporter_144\"},\"value\":[1516072371.781,\"373190465\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.145:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"5124941908\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.145:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1370943258\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.146:9100\",\"job\":\"node\"},\"value\":[1516072371.781,\"4850755799\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"10.140.20.146:9108\",\"job\":\"elasticsearch_exporter\"},\"value\":[1516072371.781,\"1370683906\"]},{\"metric\":{\"__name__\":\"go_memstats_frees_total\",\"instance\":\"localhost:9090\",\"job\":\"prometheus\"},\"value\":[1516072371.781,\"2299674805\"]}]}}\n\n**注：\"value\":[时间戳,\"对应值\"]**\n\n\n\n#### 4.1.2 范围查询\n\n```\nGET /api/v1/query_range\n\n```\n\n**URL查询参数：**\n\n- `query=<string>`：普罗米修斯表达查询字符串。\n- `start=<rfc3339 | unix_timestamp>`：开始时间戳。\n- `end=<rfc3339 | unix_timestamp>`：结束时间戳。\n- `step=<duration>`：查询分辨率步的宽度。\n- `timeout=<duration>`：评价超时。可选的。默认为，并通过价值上限`-query.timeout`标志。\n\n\n\n例：时间在2018-01-01T20:10:30.781到2018-01-01T20:11:00.781范围内，间隔15秒，up的数据\n\n[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl 'http://10.140.20.146:9090/api/v1/query_range?query=up&start=2018-01-01T20:10:30.781Z&end=2018-01-01T20:11:00.781Z&step=15s'\n{\"status\":\"success\",\"data\":{\"resultType\":\"matrix\",\"result\":[{\"metric\":{\"__name__\":\"up\",\"instance\":\"localhost:9090\",\"job\":\"prometheus\"},\"values\":[[1514837430.781,\"1\"],[1514837445.781,\"1\"],[1514837460.781,\"1\"]]},{\"metric\":{\"__name__\":\"up\",\"instance\":\"localhost:9100\",\"job\":\"node\"},\"values\":[[1514837430.781,\"0\"],[1514837445.781,\"0\"],[1514837460.781,\"0\"]]}]}}\n\n\n\n### 4.2 http查询方式作用未知系列？？\n\n#### Querying metadata\n\n##### Finding series by label matchers\n\nThe following endpoint returns the list of time series that match a certain label set.\n\n```\nGET /api/v1/series\n\n```\n\nURL query parameters:\n\n- `match[]=<series_selector>`: Repeated series selector argument that selects the series to return. At least one `match[]` argument must be provided.\n- `start=<rfc3339 | unix_timestamp>`: Start timestamp.\n- `end=<rfc3339 | unix_timestamp>`: End timestamp.\n\nThe `data` section of the query result consists of a list of objects that contain the label name/value pairs which identify each series.\n\nThe following example returns all series that match either of the selectors `up` or `process_start_time_seconds{job=\"prometheus\"}`:\n\n```\n$ curl -g 'http://localhost:9090/api/v1/series?match[]=up&match[]=process_start_time_seconds{job=\"prometheus\"}'\n{\n   \"status\" : \"success\",\n   \"data\" : [\n      {\n         \"__name__\" : \"up\",\n         \"job\" : \"prometheus\",\n         \"instance\" : \"localhost:9090\"\n      },\n      {\n         \"__name__\" : \"up\",\n         \"job\" : \"node\",\n         \"instance\" : \"localhost:9091\"\n      },\n      {\n         \"__name__\" : \"process_start_time_seconds\",\n         \"job\" : \"prometheus\",\n         \"instance\" : \"localhost:9090\"\n      }\n   ]\n}\n\n```\n\n##### Querying label values\n\nThe following endpoint returns a list of label values for a provided label name:\n\n```\nGET /api/v1/label/<label_name>/values\n\n```\n\nThe `data` section of the JSON response is a list of string label names.\n\nThis example queries for all label values for the `job` label:\n\n```\n$ curl http://localhost:9090/api/v1/label/job/values\n{\n   \"status\" : \"success\",\n   \"data\" : [\n      \"node\",\n      \"prometheus\"\n   ]\n}\n\n```\n\n#### Expression query result formats\n\nExpression queries may return the following response values in the `result` property of the `data` section. `<sample_value>` placeholders are numeric sample values. JSON does not support special float values such as `NaN`, `Inf`, and `-Inf`, so sample values are transferred as quoted JSON strings rather than raw numbers.\n\n##### Range vectors\n\nRange vectors are returned as result type `matrix`. The corresponding `result` property has the following format:\n\n```\n[\n  {\n    \"metric\": { \"<label_name>\": \"<label_value>\", ... },\n    \"values\": [ [ <unix_time>, \"<sample_value>\" ], ... ]\n  },\n  ...\n]\n\n```\n\n##### Instant vectors\n\nInstant vectors are returned as result type `vector`. The corresponding `result` property has the following format:\n\n```\n[\n  {\n    \"metric\": { \"<label_name>\": \"<label_value>\", ... },\n    \"value\": [ <unix_time>, \"<sample_value>\" ]\n  },\n  ...\n]\n\n```\n\n##### Scalars\n\nScalar results are returned as result type `scalar`. The corresponding `result` property has the following format:\n\n```\n[ <unix_time>, \"<scalar_value>\" ]\n\n```\n\n##### Strings\n\nString results are returned as result type `string`. The corresponding `result` property has the following format:\n\n```\n[ <unix_time>, \"<string_value>\" ]\n\n```\n\n#### Targets\n\n> This API is experimental as it is intended to be extended with targets dropped due to relabelling in the future.\n\nThe following endpoint returns an overview of the current state of the Prometheus target discovery:\n\n```\nGET /api/v1/targets\n\n```\n\nCurrently only the active targets are part of the response.\n\n```\n$ curl http://localhost:9090/api/v1/targets\n{\n  \"status\": \"success\",                                                                                                                                [3/11]\n  \"data\": {\n    \"activeTargets\": [\n      {\n        \"discoveredLabels\": {\n          \"__address__\": \"127.0.0.1:9090\",\n          \"__metrics_path__\": \"/metrics\",\n          \"__scheme__\": \"http\",\n          \"job\": \"prometheus\"\n        },\n        \"labels\": {\n          \"instance\": \"127.0.0.1:9090\",\n          \"job\": \"prometheus\"\n        },\n        \"scrapeUrl\": \"http://127.0.0.1:9090/metrics\",\n        \"lastError\": \"\",\n        \"lastScrape\": \"2017-01-17T15:07:44.723715405+01:00\",\n        \"health\": \"up\"\n      }\n    ]\n  }\n}\n\n```\n\n#### Alertmanagers\n\n> This API is experimental as it is intended to be extended with Alertmanagers dropped due to relabelling in the future.\n\nThe following endpoint returns an overview of the current state of the Prometheus alertmanager discovery:\n\n```\nGET /api/v1/alertmanagers\n\n```\n\nCurrently only the active Alertmanagers are part of the response.\n\n```\n$ curl http://localhost:9090/api/v1/alertmanagers\n{\n  \"status\": \"success\",\n  \"data\": {\n    \"activeAlertmanagers\": [\n      {\n        \"url\": \"http://127.0.0.1:9090/api/v1/alerts\"\n      }\n    ]\n  }\n}\n```\n\n\n\n\n\n查询指标标签：\tcurl -g 'http://192.168.7.40:9090/api/v1/series?match[]=up&match[]=process_start_time_seconds{job=\"prometheus\"}'\n\n\n\n查询标签 {\"status\":\"success\",\"data\":[]}[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl http://10.140.20.146:9090/api/v1/label/job/values\n{\"status\":\"success\",\"data\":[\"elasticsearch_exporter\",\"node\",\"prometheus\",\"redis_exporter\",\"redis_exporter_143\",\"redis_exporter_144\"]}\n\n\n\n\n\n### 4.3 查询节点数据\n\n​\t查询节点exporter的所有数据：curl -s http://192.168.7.40:9100/metrics\n\n\n\n## 5 exporter格式\n\n基于协议缓冲区格式 和 文本格式\n\n客户端可以暴露promethues无法解析的其他格式\n\n\n\n### 5.1 基于协议缓冲区格式 和 文本格式 的区别\n\n|                                    | Protocol buffer format                   | Text format                              |\n| ---------------------------------- | ---------------------------------------- | ---------------------------------------- |\n| **Inception**                      | April 2014                               | April 2014                               |\n| **Supported in**                   | Prometheus version `>=0.4.0`             | Prometheus version `>=0.4.0`             |\n| **Transmission**                   | HTTP                                     | HTTP                                     |\n| **Encoding**                       | [32-bit varint-encoded record length-delimited](https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/AbstractMessageLite#writeDelimitedTo(java.io.OutputStream)) Protocol Buffer messages of type [io.prometheus.client.MetricFamily](https://github.com/prometheus/client_model/blob/086fe7ca28bde6cec2acd5223423c1475a362858/metrics.proto#L76-%20%20L81) | UTF-8, `\\n` line endings                 |\n| **HTTP Content-Type**              | `application/vnd.google.protobuf; proto=io.prometheus.client.MetricFamily; encoding=delimited` | `text/plain; version=0.0.4` (A missing `version` value will lead to a fall-back to the most recent text format version.) |\n| **Optional HTTP Content-Encoding** | `gzip`                                   | `gzip`                                   |\n| **Advantages**                     | Cross-platformSizeEncoding and decoding costsStrict schemaSupports concatenation and theoretically streaming (only server-side behavior would need to change) | Human-readableEasy to assemble, especially for minimalistic cases (no nesting required)Readable line by line (with the exception of type hints and docstrings) |\n| **Limitations**                    | Not human-readable                       | VerboseTypes and docstrings not integral part of the syntax, meaning little-to-nonexistent metric contract validationParsing cost |\n| **Supported metric primitives**    | CounterGaugeHistogramSummaryUntyped      | CounterGaugeHistogramSummaryUntyped      |\n| **Compatibility**                  | Version `0.0.3` protocol buffers are also valid version `0.0.4` protocol buffers. | none                                     |\n\n\n\n### 5.2 基于协议缓冲区格式\n\n​\tReproducible sorting of the protocol buffer fields in repeated expositions is preferred but not required, i.e. do not sort if the computational cost is prohibitive.\n\n​\tEach `MetricFamily` within the same exposition must have a unique name. Each `Metric` within the same `MetricFamily` must have a unique set of `LabelPair` fields. Otherwise, the ingestion behavior is undefined.\n\n### 5.3 文本类型格式\n\n​\t＃打头的是注释行（除非＃之后的第一个标记是HELP或TYPE）。\n\n​\tHELP行：可能包含任何UTF-8字符序列（在指标名称之后），但反斜杠和换行字符必须分别转义为`\\\\`和`\\ n`。对于相同的指标名称，只能有一条HELP行，一个指标只能有一个HELP行。\n\nTYPE行：TPYE后的第一个参数是指标名，第二个参数是数据类型（可以是counter, gauge, histogram, summary,  untyped）。相同的指标名称，只能有一个TYPE行。如果指标名称没有TYPE行，则该类型设置为无类型。\n\n格式：\n\n```\nmetric_name [\n  \"{\" label_name \"=\" `\"` label_value `\"` { \",\" label_name \"=\" `\"` label_value `\"` } [ \",\" ] \"}\"\n] value [ timestamp ]\n```\n\nlabel_value可以是任何UTF-8格式的内容，但反斜杠、双引号、换行符 必须转义成\n\n```\n\\\\  \\\"  \\\\n\n```\n\nhistogram（直方图）  summary（汇总）类型的特别格式：\n\n1. 需要单独一行xxx_sum；\n2. 需要单独一行xxx_count；\n3. Each quantile of a summary named x is given as a separate sample line with the same name x and a label {quantile=\"y\"}；\n4. A histogram must have a bucket with {le=\"+Inf\"}. Its value must be identical to the value of x_count；\n5. histogram类型必须要有{le=\"+Inf\"}，并且值要和xxx_count一致；\n\n\n\n### 5.4 文本类型格式举例\n\n```\n# HELP http_requests_total The total number of HTTP requests.\n# TYPE http_requests_total counter\nhttp_requests_total{method=\"post\",code=\"200\"} 1027 1395066363000\nhttp_requests_total{method=\"post\",code=\"400\"}    3 1395066363000\n\n# Escaping in label values:\nmsdos_file_access_time_seconds{path=\"C:\\\\DIR\\\\FILE.TXT\",error=\"Cannot find file:\\n\\\"FILE.TXT\\\"\"} 1.458255915e9\n\n# Minimalistic line:\nmetric_without_timestamp_and_labels 12.47\n\n# A weird metric from before the epoch:\nsomething_weird{problem=\"division by zero\"} +Inf -3982045\n\n# A histogram, which has a pretty complex representation in the text format:\n# HELP http_request_duration_seconds A histogram of the request duration.\n# TYPE http_request_duration_seconds histogram\nhttp_request_duration_seconds_bucket{le=\"0.05\"} 24054\nhttp_request_duration_seconds_bucket{le=\"0.1\"} 33444\nhttp_request_duration_seconds_bucket{le=\"0.2\"} 100392\nhttp_request_duration_seconds_bucket{le=\"0.5\"} 129389\nhttp_request_duration_seconds_bucket{le=\"1\"} 133988\nhttp_request_duration_seconds_bucket{le=\"+Inf\"} 144320\nhttp_request_duration_seconds_sum 53423\nhttp_request_duration_seconds_count 144320\n\n# Finally a summary, which has a complex representation, too:\n# HELP rpc_duration_seconds A summary of the RPC duration in seconds.\n# TYPE rpc_duration_seconds summary\nrpc_duration_seconds{quantile=\"0.01\"} 3102\nrpc_duration_seconds{quantile=\"0.05\"} 3272\nrpc_duration_seconds{quantile=\"0.5\"} 4773\nrpc_duration_seconds{quantile=\"0.9\"} 9001\nrpc_duration_seconds{quantile=\"0.99\"} 76656\nrpc_duration_seconds_sum 1.7560473e+07\nrpc_duration_seconds_count 2693\n```\n\n\n\n## 6 导出器exporter\n\n### 6.1 概述\n\n​\t指标名，一般为导出程序名称作为前缀，例如， haproxy_up；\n\n​\t度量标准必须使用基本单位（例如秒，字节），并保留将其转换为更具可读性的图形工具；\n\n \t指标有效字符：`[a-zA-Z0-9:_]` ，其他任何字符都要用下划线_代替；\n\n​\t指标后缀`_sum`, `_count`, `_bucket` and `_total` 只可用在Summaries、 Histograms 、 Counters\n\n\n\n## 7 告警alertmanager程序\n\n​\t概述：\n\n​\t\tpromethues：根据配置文件prometheus.yml的rule_files告警规则，将告警信息存到promethues的磁盘，供promethues的前台页面查看；根据配置文件prometheus.yml的alerting（配置altermanager进程的ip 端口信息），将告警信息发送altermanager进程上。\n\n​\t\taltermanager：接收promethues发来的告警信息，存在磁盘中供altermanager进程的前台查看；同时根据altermanager的告警配置文件simple.yml发送邮件等提醒。\n\n\n\n### 7.1 promethues告警配置举例\n\n![](/img/promethues-alarm.png)\n\n### 7.2 promethues告警规则配置文件举例\n\n![](/img/rule_file.png)\n\nalert：自定义的告警含义简写\n\nexpor：告警条件，如上图的node_forks为具体mertics里的指标\n\nfor：周期\n\nlabels：severity，在alertmanager前台页面可以根据severity条件来查询告警信息\n\nannotations：summary写些较详细的告警信息\n\n### 7.3 alertmanager告警发送邮件提示\n\n![](/img/email_1.png)\n\n![](/img/email_2.png)\n\n\n\n### 7.4 启动alertmanager\n\n nohup ./alertmanager --config.file=simple.yml &\n\nalertmanager前台：http://192.168.7.176:9093/\n\n### 7.5通过其他方式告警\n\n#### hipchat_config：\n\n​\t是一款能够在苹果mac平台上运行的社交聊天软件，HipChat的功能和QQ相似，集聊天、视频、语音等功能于一身，不同之处在于HipChat界面更加的简洁、操作更加的流畅。\n\n#### pagerduty_config：\n\n​\t是一款能够在服务器出问题时发送提醒的软件。在发生问题时，提醒的方式包括屏幕显示、电话呼叫、短信通知、电邮通知等，而且在无人应答时还会自动将提醒级别提高。PagerDuty 不是免费的。\n\n#### pushover_config：\n\n​\t是一款网络通知推送服务，类似ifttt或脚本服务，你可以将需要推送的服务设置好后，遇到情况将把通知自动推送到你的[安卓手机](http://www.onlinedown.net/soft/222292.htm)。\n\n#### slack_config：\n\n​\tslack是聊天群组 + 大规模工具集成 + 文件整合 + 统一搜索。截至2014年底，Slack 已经整合了电子邮件、短信、[Google](https://baike.baidu.com/item/Google) Drives、[Twitter](https://baike.baidu.com/item/Twitter)、Trello、Asana、[GitHub](https://baike.baidu.com/item/GitHub) 等 65 种工具和服务，可以把各种碎片化的企业沟通和协作集中到一起。\n\n```\n# Whether or not to notify about resolved alerts.\n[ send_resolved: <boolean> | default = false ]\n\n# The Slack webhook URL.\n[ api_url: <secret> | default = global.slack_api_url ]\n\n# The channel or user to send notifications to.\nchannel: <tmpl_string>\n\n# API request data as defined by the Slack webhook API.\n[ color: <tmpl_string> | default = '{{ if eq .Status \"firing\" }}danger{{ else }}good{{ end }}' ]\n[ username: <tmpl_string> | default = '{{ template \"slack.default.username\" . }}' ]\n[ title: <tmpl_string> | default = '{{ template \"slack.default.title\" . }}' ]\n[ title_link: <tmpl_string> | default = '{{ template \"slack.default.titlelink\" . }}' ]\n[ icon_emoji: <tmpl_string> ]\n[ icon_url: <tmpl_string> ]\n[ pretext: <tmpl_string> | default = '{{ template \"slack.default.pretext\" . }}' ]\n[ text: <tmpl_string> | default = '{{ template \"slack.default.text\" . }}' ]\n[ fallback: <tmpl_string> | default = '{{ template \"slack.default.fallback\" . }}' ]\n\n# The HTTP client's configuration.\n[ http_config: <http_config> | default = global.http_config ]\n```\n\n\n\n#### opsgenie_config ：\n\n​\t集成电话短信邮件等等\n\n#### victorops_config：\n\n​\t聊天应用\n\n#### http_config：\n\n​\tA `http_config` allows configuring the HTTP client that the receiver uses to communicate with HTTP-based API services.\n\n\n\n\n\n## 8 问题笔记\n\n### 8.1已解决\n\n1. prometheus浏览器查询不到exporter指标数据，但是浏览器exporter的mertic有指标数据。原因是时间不同步\n\n\n\n### 8.2 未解决\n\n","slug":"prometheus","published":1,"updated":"2018-04-27T06:14:35.031Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczp50011e4rwtcresxyd","content":"<h2 id=\"1-概述\"><a href=\"#1-概述\" class=\"headerlink\" title=\"1 概述\"></a>1 概述</h2><h3 id=\"1-1-主要功能\"><a href=\"#1-1-主要功能\" class=\"headerlink\" title=\"1.1 主要功能\"></a>1.1 主要功能</h3><ul>\n<li>多维 <a href=\"https://prometheus.io/docs/concepts/data_model/\" target=\"_blank\" rel=\"external\">数据模型</a>（时序由 metric 名字和 k/v 的 labels 构成）。</li>\n<li>灵活的查询语句（<a href=\"https://prometheus.io/docs/querying/basics/\" target=\"_blank\" rel=\"external\">PromQL</a>）。</li>\n<li>无依赖存储，支持 local 和 remote 不同模型。</li>\n<li>采用 http 协议，使用 pull 模式，拉取数据，简单易懂。</li>\n<li>监控目标，可以采用服务发现或静态配置的方式。</li>\n<li>支持多种统计数据模型，图形化友好。</li>\n</ul>\n<h3 id=\"1-2-核心组件\"><a href=\"#1-2-核心组件\" class=\"headerlink\" title=\"1.2 核心组件\"></a>1.2 核心组件</h3><ul>\n<li><a href=\"https://github.com/prometheus/prometheus\" target=\"_blank\" rel=\"external\">Prometheus Server</a>， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。</li>\n<li><a href=\"https://prometheus.io/docs/instrumenting/clientlibs/\" target=\"_blank\" rel=\"external\">client libraries</a>，用于对接 Prometheus Server, 可以查询和上报数据。</li>\n<li><a href=\"https://github.com/prometheus/pushgateway\" target=\"_blank\" rel=\"external\">push gateway</a> ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。</li>\n<li>各种汇报数据的 <a href=\"https://prometheus.io/docs/instrumenting/exporters/\" target=\"_blank\" rel=\"external\">exporters</a> ，例如汇报机器数据的 node_exporter,  汇报 MongoDB 信息的 <a href=\"https://github.com/dcu/mongodb_exporter\" target=\"_blank\" rel=\"external\">MongoDB exporter</a> 等等。</li>\n<li>用于告警通知管理的 <a href=\"https://github.com/prometheus/alertmanager\" target=\"_blank\" rel=\"external\">alertmanager</a> 。</li>\n</ul>\n<h3 id=\"1-3-基础架构\"><a href=\"#1-3-基础架构\" class=\"headerlink\" title=\"1.3 基础架构\"></a>1.3 基础架构</h3><p>一图胜千言，先来张官方的架构图</p>\n<p><img src=\"/img/prometheus1.png\" alt=\"img\"></p>\n<a id=\"more\"></a>\n<p>从这个架构图，也可以看出 Prometheus 的主要模块包含， Server,  Exporters, Pushgateway, PromQL, Alertmanager, WebUI 等。</p>\n<p>它大致使用逻辑是这样：</p>\n<ol>\n<li>Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。</li>\n<li>当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。</li>\n<li>Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。</li>\n<li>Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。</li>\n<li>可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。</li>\n</ol>\n<h3 id=\"1-4-注意\"><a href=\"#1-4-注意\" class=\"headerlink\" title=\"1.4 注意\"></a>1.4 注意</h3><ul>\n<li>Prometheus 的数据是基于时序的 float64 的值，如果你的数据值有更多类型，无法满足。</li>\n<li>Prometheus 不适合做审计计费，因为它的数据是按一定时间采集的，关注的更多是系统的运行瞬时状态以及趋势，即使有少量数据没有采集也能容忍，但是审计计费需要记录每个请求，并且数据长期存储，这个和 Prometheus 无法满足，可能需要采用专门的审计系统。</li>\n</ul>\n<h2 id=\"2-BO关注项\"><a href=\"#2-BO关注项\" class=\"headerlink\" title=\"2 BO关注项\"></a>2 BO关注项</h2><h3 id=\"2-1-数据收集方式\"><a href=\"#2-1-数据收集方式\" class=\"headerlink\" title=\"2.1 数据收集方式\"></a>2.1 数据收集方式</h3><p>使用 pull 模式，拉取数据。</p>\n<h3 id=\"2-2-数据格式\"><a href=\"#2-2-数据格式\" class=\"headerlink\" title=\"2.2 数据格式\"></a>2.2 数据格式</h3><p>Prometheus 时序格式与 <a href=\"http://opentsdb.net/\" target=\"_blank\" rel=\"external\">OpenTSDB</a> 相似：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;</div></pre></td></tr></table></figure>\n<p>其中包含时序名字以及时序的标签。</p>\n<h4 id=\"2-2-1-时序-4-种类型\"><a href=\"#2-2-1-时序-4-种类型\" class=\"headerlink\" title=\"2.2.1 时序 4 种类型\"></a>2.2.1 时序 4 种类型</h4><p>Prometheus 时序数据分为 <a href=\"https://prometheus.io/docs/concepts/metric_types/#counter\" target=\"_blank\" rel=\"external\">Counter</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#gauge\" target=\"_blank\" rel=\"external\">Gauge</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#histogram\" target=\"_blank\" rel=\"external\">Histogram</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#summary\" target=\"_blank\" rel=\"external\">Summary</a> 四种类型。</p>\n<h5 id=\"2-2-1-1-Counter\"><a href=\"#2-2-1-1-Counter\" class=\"headerlink\" title=\"2.2.1.1 Counter\"></a>2.2.1.1 Counter</h5><p>Counter 表示收集的数据是按照某个趋势（增加／减少）一直变化的，我们往往用它记录服务请求总量，错误总数等。</p>\n<p>例如 Prometheus server 中 <code>http_requests_total</code>,  表示 Prometheus 处理的 http 请求总数，我们可以使用 <code>delta</code>, 很容易得到任意区间数据的增量，这个会在 PromQL 一节中细讲。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP http_requests_total Total number of HTTP requests made.</div><div class=\"line\"># TYPE http_requests_total counter</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;alerts&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;config&quot;,method=&quot;get&quot;&#125; 1</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;flags&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;graph&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;label_values&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;prometheus&quot;,method=&quot;get&quot;&#125; 24755</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;query&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;static&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;status&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;targets&quot;,method=&quot;get&quot;&#125; 4</div><div class=\"line\">http_requests_total&#123;code=&quot;304&quot;,handler=&quot;static&quot;,method=&quot;get&quot;&#125; 4</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-2-Gauge\"><a href=\"#2-2-1-2-Gauge\" class=\"headerlink\" title=\"2.2.1.2 Gauge\"></a>2.2.1.2 Gauge</h5><p>Gauge 表示搜集的数据是一个瞬时的，与时间没有关系，可以任意变高变低，往往可以用来记录内存使用率、磁盘使用率等。</p>\n<p>例如 Prometheus server 中 <code>go_goroutines</code>,  表示 Prometheus 当前 goroutines 的数量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP go_goroutines Number of goroutines that currently exist.</div><div class=\"line\"># TYPE go_goroutines gauge</div><div class=\"line\">go_goroutines 100</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-3-Histogram\"><a href=\"#2-2-1-3-Histogram\" class=\"headerlink\" title=\"2.2.1.3 Histogram\"></a>2.2.1.3 Histogram</h5><p>Histogram 由 <code>&lt;basename&gt;_bucket{le=&quot;&lt;upper inclusive bound&gt;&quot;}</code>，<code>&lt;basename&gt;_bucket{le=&quot;+Inf&quot;}</code>, <code>&lt;basename&gt;_sum</code>，<code>&lt;basename&gt;_count</code> 组成，主要用于表示一段时间范围内对数据进行采样，（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常我们用它计算分位数的直方图。</p>\n<p>例如 Prometheus server 中 <code>prometheus_local_storage_series_chunks_persisted</code>,  表示 Prometheus 中每个时序需要存储的 chunks 数量，我们可以用它计算待持久化的数据的分位数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction</div><div class=\"line\"># TYPE prometheus_tsdb_compaction_chunk_range histogram</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;100&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;400&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1600&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6400&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;25600&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;102400&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;409600&quot;&#125; 605</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1.6384e+06&quot;&#125; 612</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6.5536e+06&quot;&#125; 126358</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;2.62144e+07&quot;&#125; 126358</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;+Inf&quot;&#125; 126358</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_sum 2.25313627417e+11</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_count 126358</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-4-Summary\"><a href=\"#2-2-1-4-Summary\" class=\"headerlink\" title=\"2.2.1.4 Summary\"></a>2.2.1.4 Summary</h5><p>Summary 和 Histogram 类似，由 <code>&lt;basename&gt;{quantile=&quot;&lt;φ&gt;&quot;}</code>，<code>&lt;basename&gt;_sum</code>，<code>&lt;basename&gt;_count</code> 组成，主要用于表示一段时间内数据采样结果，（通常是请求持续时间或响应大小），它直接存储了 quantile 数据，而不是根据统计区间计算出来的。</p>\n<p>例如 Prometheus server 中 <code>prometheus_target_interval_length_seconds</code>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.</div><div class=\"line\"># TYPE prometheus_target_interval_length_seconds summary</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.01&quot;&#125; 14.999987534</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.05&quot;&#125; 14.999987534</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.5&quot;&#125; 15.000020575</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.9&quot;&#125; 15.000045415</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.99&quot;&#125; 15.000050555</div><div class=\"line\">prometheus_target_interval_length_seconds_sum&#123;interval=&quot;15s&quot;&#125; 371280.61110144516</div><div class=\"line\">prometheus_target_interval_length_seconds_count&#123;interval=&quot;15s&quot;&#125; 24752</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-5-Histogram-vs-Summary\"><a href=\"#2-2-1-5-Histogram-vs-Summary\" class=\"headerlink\" title=\"2.2.1.5 Histogram vs Summary\"></a>2.2.1.5 Histogram vs Summary</h5><ul>\n<li>都包含 <code>&lt;basename&gt;_sum</code>，<code>&lt;basename&gt;_count</code></li>\n<li>Histogram 需要通过 <code>&lt;basename&gt;_bucket</code> 计算 quantile, 而 Summary 直接存储了 quantile 的值。</li>\n</ul>\n<h3 id=\"2-2-3-数据存储方式\"><a href=\"#2-2-3-数据存储方式\" class=\"headerlink\" title=\"2.2.3 数据存储方式\"></a>2.2.3 数据存储方式</h3><p>​    数据存在promethues自身的数据库，以数据文件的形式存储，有自身的查询方式：promql；详见<a href=\"https://songjiayang.gitbooks.io/prometheus/content/promql/summary.html\" target=\"_blank\" rel=\"external\">https://songjiayang.gitbooks.io/prometheus/content/promql/summary.html</a></p>\n<h3 id=\"2-2-4-数据输出方式\"><a href=\"#2-2-4-数据输出方式\" class=\"headerlink\" title=\"2.2.4 数据输出方式\"></a>2.2.4 数据输出方式</h3><p>​    agent：被动拉取；</p>\n<p>​    promethues server：主动拉取客户端的数据。promethues将拉取到的数据存到data/目录。（除了 promethues 前台的PromQ查询页面，应该有某种工具可以直接在命令行查询promethues的历史数据（暂未找到）；多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式（工具未研究过）。）</p>\n<h3 id=\"2-2-5-agent部署方式\"><a href=\"#2-2-5-agent部署方式\" class=\"headerlink\" title=\"2.2.5 agent部署方式\"></a>2.2.5 agent部署方式</h3><p>​    promethues未提供自动部署agent的功能。</p>\n<h3 id=\"2-2-6-任务下发方式\"><a href=\"#2-2-6-任务下发方式\" class=\"headerlink\" title=\"2.2.6 任务下发方式\"></a>2.2.6 任务下发方式</h3><p>​    agent每个周期固定采集设备的指定指标，若要自定义采集某些指标则需要修改agent源码。</p>\n<p>​    promethues server拉取数据的任务在prometheus.yml配置。</p>\n<h2 id=\"3-promethues组件及部署\"><a href=\"#3-promethues组件及部署\" class=\"headerlink\" title=\"3 promethues组件及部署\"></a>3 promethues组件及部署</h2><h3 id=\"3-1-promethues-server\"><a href=\"#3-1-promethues-server\" class=\"headerlink\" title=\"3.1 promethues server\"></a>3.1 promethues server</h3><h4 id=\"3-1-1-部署\"><a href=\"#3-1-1-部署\" class=\"headerlink\" title=\"3.1.1 部署\"></a>3.1.1 部署</h4><p>​    tar包解压即可用</p>\n<h4 id=\"3-1-2-prometheus-yml配置举例\"><a href=\"#3-1-2-prometheus-yml配置举例\" class=\"headerlink\" title=\"3.1.2 prometheus.yml配置举例\"></a>3.1.2 prometheus.yml配置举例</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">global:</div><div class=\"line\">  scrape_interval:     15s # By default, scrape targets every 15 seconds.</div><div class=\"line\">  evaluation_interval: 15s # By default, scrape targets every 15 seconds.</div><div class=\"line\"></div><div class=\"line\">rule_files:</div><div class=\"line\">  - &quot;rules/node.rules&quot;</div><div class=\"line\"></div><div class=\"line\">scrape_configs:</div><div class=\"line\">  - job_name: &apos;prometheus&apos;</div><div class=\"line\">    scrape_interval: 5s</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;localhost:9090&apos;]</div><div class=\"line\"></div><div class=\"line\">  - job_name: &apos;node&apos;</div><div class=\"line\">    scrape_interval: 8s</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;127.0.0.1:9100&apos;, &apos;127.0.0.12:9100&apos;]</div><div class=\"line\"></div><div class=\"line\">  - job_name: &apos;mysqld&apos;</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;127.0.0.1:9104&apos;]</div><div class=\"line\">  - job_name: &apos;memcached&apos;</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;127.0.0.1:9150&apos;]</div></pre></td></tr></table></figure>\n<h4 id=\"3-1-3-命令\"><a href=\"#3-1-3-命令\" class=\"headerlink\" title=\"3.1.3 命令\"></a>3.1.3 命令</h4><p>[chenrj@kfapp01 prometheus-2.0.0.linux-amd64]$ ./prometheus -h<br>usage: prometheus [<flags>]</flags></p>\n<p>The Prometheus monitoring server</p>\n<p>Flags:<br>  -h, –help                     Show context-sensitive help (also try –help-long and –help-man).</p>\n<h4 id=\"3-1-4-前台地址\"><a href=\"#3-1-4-前台地址\" class=\"headerlink\" title=\"3.1.4 前台地址\"></a>3.1.4 前台地址</h4><p>​    <a href=\"http://192.168.7.40:9090/graph\" target=\"_blank\" rel=\"external\">http://192.168.7.40:9090/graph</a></p>\n<p>​    默认9090端口</p>\n<h3 id=\"3-2-grafana\"><a href=\"#3-2-grafana\" class=\"headerlink\" title=\"3.2 grafana\"></a>3.2 grafana</h3><p>​       <a href=\"http://192.168.7.40:3000/\" target=\"_blank\" rel=\"external\">http://192.168.7.40:3000</a></p>\n<p>​       端口默认3000，</p>\n<p>​       用户密码： admin/admin</p>\n<p>​    ./grafana-server</p>\n<h3 id=\"3-3-主机节点\"><a href=\"#3-3-主机节点\" class=\"headerlink\" title=\"3.3 主机节点\"></a>3.3 主机节点</h3><p>​    <a href=\"http://10.140.20.142:9100/metrics\" target=\"_blank\" rel=\"external\">http://10.140.20.142:9100/metrics</a></p>\n<h3 id=\"3-4-redis节点\"><a href=\"#3-4-redis节点\" class=\"headerlink\" title=\"3.4 redis节点\"></a>3.4 redis节点</h3><p>​    <a href=\"http://10.140.20.143:9121/metrics\" target=\"_blank\" rel=\"external\">http://10.140.20.143:9121/metrics</a> </p>\n<h3 id=\"3-5-elasticsearch节点\"><a href=\"#3-5-elasticsearch节点\" class=\"headerlink\" title=\"3.5 elasticsearch节点\"></a>3.5 elasticsearch节点</h3><p>​    <a href=\"http://10.140.20.146:9108/metrics\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9108/metrics</a></p>\n<h2 id=\"4-数据查询\"><a href=\"#4-数据查询\" class=\"headerlink\" title=\"4 数据查询\"></a>4 数据查询</h2><h3 id=\"4-1-http方式查询promethues数据\"><a href=\"#4-1-http方式查询promethues数据\" class=\"headerlink\" title=\"4.1 http方式查询promethues数据\"></a>4.1 http方式查询promethues数据</h3><p>​    <a href=\"https://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata\" target=\"_blank\" rel=\"external\">https://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata</a></p>\n<h4 id=\"4-1-1-即时查询\"><a href=\"#4-1-1-即时查询\" class=\"headerlink\" title=\"4.1.1 即时查询\"></a>4.1.1 即时查询</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/query</div></pre></td></tr></table></figure>\n<p><strong>URL查询参数：</strong></p>\n<ul>\n<li><code>query=&lt;string&gt;</code>：普罗米修斯表达查询字符串。</li>\n<li><code>time=&lt;rfc3339 | unix_timestamp&gt;</code>：评估时间戳。可选的。</li>\n<li><code>timeout=&lt;duration&gt;</code>：评价超时。可选的。默认为，并通过价值上限<code>-query.timeout</code>标志。</li>\n</ul>\n<p>若省略时间time测试，则默认使用服务器时间</p>\n<p><strong>例：</strong>查询2018-01-16T03:12:51.781这个时刻go_memstats_frees_total的值</p>\n<p>[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl ‘<a href=\"http://10.140.20.146:9090/api/v1/query?query=go_memstats_frees_total&amp;time=2018-01-16T03:12:51.781Z\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9090/api/v1/query?query=go_memstats_frees_total&amp;time=2018-01-16T03:12:51.781Z</a>‘<br>{“status”:”success”,”data”:{“resultType”:”vector”,”result”:[{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.142:9100”,”job”:”node”},”value”:[1516072371.781,”5599415948”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.143:9100”,”job”:”node”},”value”:[1516072371.781,”5152870637”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.143:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1385642849”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.143:9121”,”job”:”redis_exporter_143”},”value”:[1516072371.781,”159639669”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.144:9100”,”job”:”node”},”value”:[1516072371.781,”5167404030”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.144:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1383957758”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.144:9121”,”job”:”redis_exporter_144”},”value”:[1516072371.781,”373190465”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.145:9100”,”job”:”node”},”value”:[1516072371.781,”5124941908”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.145:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1370943258”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.146:9100”,”job”:”node”},”value”:[1516072371.781,”4850755799”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.146:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1370683906”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”localhost:9090”,”job”:”prometheus”},”value”:[1516072371.781,”2299674805”]}]}}</p>\n<p><strong>注：”value”:[时间戳,”对应值”]</strong></p>\n<h4 id=\"4-1-2-范围查询\"><a href=\"#4-1-2-范围查询\" class=\"headerlink\" title=\"4.1.2 范围查询\"></a>4.1.2 范围查询</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/query_range</div></pre></td></tr></table></figure>\n<p><strong>URL查询参数：</strong></p>\n<ul>\n<li><code>query=&lt;string&gt;</code>：普罗米修斯表达查询字符串。</li>\n<li><code>start=&lt;rfc3339 | unix_timestamp&gt;</code>：开始时间戳。</li>\n<li><code>end=&lt;rfc3339 | unix_timestamp&gt;</code>：结束时间戳。</li>\n<li><code>step=&lt;duration&gt;</code>：查询分辨率步的宽度。</li>\n<li><code>timeout=&lt;duration&gt;</code>：评价超时。可选的。默认为，并通过价值上限<code>-query.timeout</code>标志。</li>\n</ul>\n<p>例：时间在2018-01-01T20:10:30.781到2018-01-01T20:11:00.781范围内，间隔15秒，up的数据</p>\n<p>[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl ‘<a href=\"http://10.140.20.146:9090/api/v1/query_range?query=up&amp;start=2018-01-01T20:10:30.781Z&amp;end=2018-01-01T20:11:00.781Z&amp;step=15s\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9090/api/v1/query_range?query=up&amp;start=2018-01-01T20:10:30.781Z&amp;end=2018-01-01T20:11:00.781Z&amp;step=15s</a>‘<br>{“status”:”success”,”data”:{“resultType”:”matrix”,”result”:[{“metric”:{“<strong>name</strong>“:”up”,”instance”:”localhost:9090”,”job”:”prometheus”},”values”:[[1514837430.781,”1”],[1514837445.781,”1”],[1514837460.781,”1”]]},{“metric”:{“<strong>name</strong>“:”up”,”instance”:”localhost:9100”,”job”:”node”},”values”:[[1514837430.781,”0”],[1514837445.781,”0”],[1514837460.781,”0”]]}]}}</p>\n<h3 id=\"4-2-http查询方式作用未知系列？？\"><a href=\"#4-2-http查询方式作用未知系列？？\" class=\"headerlink\" title=\"4.2 http查询方式作用未知系列？？\"></a>4.2 http查询方式作用未知系列？？</h3><h4 id=\"Querying-metadata\"><a href=\"#Querying-metadata\" class=\"headerlink\" title=\"Querying metadata\"></a>Querying metadata</h4><h5 id=\"Finding-series-by-label-matchers\"><a href=\"#Finding-series-by-label-matchers\" class=\"headerlink\" title=\"Finding series by label matchers\"></a>Finding series by label matchers</h5><p>The following endpoint returns the list of time series that match a certain label set.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/series</div></pre></td></tr></table></figure>\n<p>URL query parameters:</p>\n<ul>\n<li><code>match[]=&lt;series_selector&gt;</code>: Repeated series selector argument that selects the series to return. At least one <code>match[]</code> argument must be provided.</li>\n<li><code>start=&lt;rfc3339 | unix_timestamp&gt;</code>: Start timestamp.</li>\n<li><code>end=&lt;rfc3339 | unix_timestamp&gt;</code>: End timestamp.</li>\n</ul>\n<p>The <code>data</code> section of the query result consists of a list of objects that contain the label name/value pairs which identify each series.</p>\n<p>The following example returns all series that match either of the selectors <code>up</code> or <code>process_start_time_seconds{job=&quot;prometheus&quot;}</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl -g &apos;http://localhost:9090/api/v1/series?match[]=up&amp;match[]=process_start_time_seconds&#123;job=&quot;prometheus&quot;&#125;&apos;</div><div class=\"line\">&#123;</div><div class=\"line\">   &quot;status&quot; : &quot;success&quot;,</div><div class=\"line\">   &quot;data&quot; : [</div><div class=\"line\">      &#123;</div><div class=\"line\">         &quot;__name__&quot; : &quot;up&quot;,</div><div class=\"line\">         &quot;job&quot; : &quot;prometheus&quot;,</div><div class=\"line\">         &quot;instance&quot; : &quot;localhost:9090&quot;</div><div class=\"line\">      &#125;,</div><div class=\"line\">      &#123;</div><div class=\"line\">         &quot;__name__&quot; : &quot;up&quot;,</div><div class=\"line\">         &quot;job&quot; : &quot;node&quot;,</div><div class=\"line\">         &quot;instance&quot; : &quot;localhost:9091&quot;</div><div class=\"line\">      &#125;,</div><div class=\"line\">      &#123;</div><div class=\"line\">         &quot;__name__&quot; : &quot;process_start_time_seconds&quot;,</div><div class=\"line\">         &quot;job&quot; : &quot;prometheus&quot;,</div><div class=\"line\">         &quot;instance&quot; : &quot;localhost:9090&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">   ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"Querying-label-values\"><a href=\"#Querying-label-values\" class=\"headerlink\" title=\"Querying label values\"></a>Querying label values</h5><p>The following endpoint returns a list of label values for a provided label name:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/label/&lt;label_name&gt;/values</div></pre></td></tr></table></figure>\n<p>The <code>data</code> section of the JSON response is a list of string label names.</p>\n<p>This example queries for all label values for the <code>job</code> label:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl http://localhost:9090/api/v1/label/job/values</div><div class=\"line\">&#123;</div><div class=\"line\">   &quot;status&quot; : &quot;success&quot;,</div><div class=\"line\">   &quot;data&quot; : [</div><div class=\"line\">      &quot;node&quot;,</div><div class=\"line\">      &quot;prometheus&quot;</div><div class=\"line\">   ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"Expression-query-result-formats\"><a href=\"#Expression-query-result-formats\" class=\"headerlink\" title=\"Expression query result formats\"></a>Expression query result formats</h4><p>Expression queries may return the following response values in the <code>result</code> property of the <code>data</code> section. <code>&lt;sample_value&gt;</code> placeholders are numeric sample values. JSON does not support special float values such as <code>NaN</code>, <code>Inf</code>, and <code>-Inf</code>, so sample values are transferred as quoted JSON strings rather than raw numbers.</p>\n<h5 id=\"Range-vectors\"><a href=\"#Range-vectors\" class=\"headerlink\" title=\"Range vectors\"></a>Range vectors</h5><p>Range vectors are returned as result type <code>matrix</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">[</div><div class=\"line\">  &#123;</div><div class=\"line\">    &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;,</div><div class=\"line\">    &quot;values&quot;: [ [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ], ... ]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  ...</div><div class=\"line\">]</div></pre></td></tr></table></figure>\n<h5 id=\"Instant-vectors\"><a href=\"#Instant-vectors\" class=\"headerlink\" title=\"Instant vectors\"></a>Instant vectors</h5><p>Instant vectors are returned as result type <code>vector</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">[</div><div class=\"line\">  &#123;</div><div class=\"line\">    &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;,</div><div class=\"line\">    &quot;value&quot;: [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  ...</div><div class=\"line\">]</div></pre></td></tr></table></figure>\n<h5 id=\"Scalars\"><a href=\"#Scalars\" class=\"headerlink\" title=\"Scalars\"></a>Scalars</h5><p>Scalar results are returned as result type <code>scalar</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[ &lt;unix_time&gt;, &quot;&lt;scalar_value&gt;&quot; ]</div></pre></td></tr></table></figure>\n<h5 id=\"Strings\"><a href=\"#Strings\" class=\"headerlink\" title=\"Strings\"></a>Strings</h5><p>String results are returned as result type <code>string</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[ &lt;unix_time&gt;, &quot;&lt;string_value&gt;&quot; ]</div></pre></td></tr></table></figure>\n<h4 id=\"Targets\"><a href=\"#Targets\" class=\"headerlink\" title=\"Targets\"></a>Targets</h4><blockquote>\n<p>This API is experimental as it is intended to be extended with targets dropped due to relabelling in the future.</p>\n</blockquote>\n<p>The following endpoint returns an overview of the current state of the Prometheus target discovery:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/targets</div></pre></td></tr></table></figure>\n<p>Currently only the active targets are part of the response.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl http://localhost:9090/api/v1/targets</div><div class=\"line\">&#123;</div><div class=\"line\">  &quot;status&quot;: &quot;success&quot;,                                                                                                                                [3/11]</div><div class=\"line\">  &quot;data&quot;: &#123;</div><div class=\"line\">    &quot;activeTargets&quot;: [</div><div class=\"line\">      &#123;</div><div class=\"line\">        &quot;discoveredLabels&quot;: &#123;</div><div class=\"line\">          &quot;__address__&quot;: &quot;127.0.0.1:9090&quot;,</div><div class=\"line\">          &quot;__metrics_path__&quot;: &quot;/metrics&quot;,</div><div class=\"line\">          &quot;__scheme__&quot;: &quot;http&quot;,</div><div class=\"line\">          &quot;job&quot;: &quot;prometheus&quot;</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;labels&quot;: &#123;</div><div class=\"line\">          &quot;instance&quot;: &quot;127.0.0.1:9090&quot;,</div><div class=\"line\">          &quot;job&quot;: &quot;prometheus&quot;</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;scrapeUrl&quot;: &quot;http://127.0.0.1:9090/metrics&quot;,</div><div class=\"line\">        &quot;lastError&quot;: &quot;&quot;,</div><div class=\"line\">        &quot;lastScrape&quot;: &quot;2017-01-17T15:07:44.723715405+01:00&quot;,</div><div class=\"line\">        &quot;health&quot;: &quot;up&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    ]</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"Alertmanagers\"><a href=\"#Alertmanagers\" class=\"headerlink\" title=\"Alertmanagers\"></a>Alertmanagers</h4><blockquote>\n<p>This API is experimental as it is intended to be extended with Alertmanagers dropped due to relabelling in the future.</p>\n</blockquote>\n<p>The following endpoint returns an overview of the current state of the Prometheus alertmanager discovery:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/alertmanagers</div></pre></td></tr></table></figure>\n<p>Currently only the active Alertmanagers are part of the response.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl http://localhost:9090/api/v1/alertmanagers</div><div class=\"line\">&#123;</div><div class=\"line\">  &quot;status&quot;: &quot;success&quot;,</div><div class=\"line\">  &quot;data&quot;: &#123;</div><div class=\"line\">    &quot;activeAlertmanagers&quot;: [</div><div class=\"line\">      &#123;</div><div class=\"line\">        &quot;url&quot;: &quot;http://127.0.0.1:9090/api/v1/alerts&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    ]</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>查询指标标签：    curl -g ‘<a href=\"http://192.168.7.40:9090/api/v1/series?match[]=up&amp;match[]=process_start_time_seconds{job=&quot;prometheus&quot;}\" target=\"_blank\" rel=\"external\">http://192.168.7.40:9090/api/v1/series?match[]=up&amp;match[]=process_start_time_seconds{job=&quot;prometheus&quot;}</a>‘</p>\n<p>查询标签 {“status”:”success”,”data”:[]}[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl <a href=\"http://10.140.20.146:9090/api/v1/label/job/values\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9090/api/v1/label/job/values</a><br>{“status”:”success”,”data”:[“elasticsearch_exporter”,”node”,”prometheus”,”redis_exporter”,”redis_exporter_143”,”redis_exporter_144”]}</p>\n<h3 id=\"4-3-查询节点数据\"><a href=\"#4-3-查询节点数据\" class=\"headerlink\" title=\"4.3 查询节点数据\"></a>4.3 查询节点数据</h3><p>​    查询节点exporter的所有数据：curl -s <a href=\"http://192.168.7.40:9100/metrics\" target=\"_blank\" rel=\"external\">http://192.168.7.40:9100/metrics</a></p>\n<h2 id=\"5-exporter格式\"><a href=\"#5-exporter格式\" class=\"headerlink\" title=\"5 exporter格式\"></a>5 exporter格式</h2><p>基于协议缓冲区格式 和 文本格式</p>\n<p>客户端可以暴露promethues无法解析的其他格式</p>\n<h3 id=\"5-1-基于协议缓冲区格式-和-文本格式-的区别\"><a href=\"#5-1-基于协议缓冲区格式-和-文本格式-的区别\" class=\"headerlink\" title=\"5.1 基于协议缓冲区格式 和 文本格式 的区别\"></a>5.1 基于协议缓冲区格式 和 文本格式 的区别</h3><table>\n<thead>\n<tr>\n<th></th>\n<th>Protocol buffer format</th>\n<th>Text format</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Inception</strong></td>\n<td>April 2014</td>\n<td>April 2014</td>\n</tr>\n<tr>\n<td><strong>Supported in</strong></td>\n<td>Prometheus version <code>&gt;=0.4.0</code></td>\n<td>Prometheus version <code>&gt;=0.4.0</code></td>\n</tr>\n<tr>\n<td><strong>Transmission</strong></td>\n<td>HTTP</td>\n<td>HTTP</td>\n</tr>\n<tr>\n<td><strong>Encoding</strong></td>\n<td><a href=\"https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/AbstractMessageLite#writeDelimitedTo(java.io.OutputStream\" target=\"_blank\" rel=\"external\">32-bit varint-encoded record length-delimited</a>) Protocol Buffer messages of type <a href=\"https://github.com/prometheus/client_model/blob/086fe7ca28bde6cec2acd5223423c1475a362858/metrics.proto#L76-%20%20L81\" target=\"_blank\" rel=\"external\">io.prometheus.client.MetricFamily</a></td>\n<td>UTF-8, <code>\\n</code> line endings</td>\n</tr>\n<tr>\n<td><strong>HTTP Content-Type</strong></td>\n<td><code>application/vnd.google.protobuf; proto=io.prometheus.client.MetricFamily; encoding=delimited</code></td>\n<td><code>text/plain; version=0.0.4</code> (A missing <code>version</code> value will lead to a fall-back to the most recent text format version.)</td>\n</tr>\n<tr>\n<td><strong>Optional HTTP Content-Encoding</strong></td>\n<td><code>gzip</code></td>\n<td><code>gzip</code></td>\n</tr>\n<tr>\n<td><strong>Advantages</strong></td>\n<td>Cross-platformSizeEncoding and decoding costsStrict schemaSupports concatenation and theoretically streaming (only server-side behavior would need to change)</td>\n<td>Human-readableEasy to assemble, especially for minimalistic cases (no nesting required)Readable line by line (with the exception of type hints and docstrings)</td>\n</tr>\n<tr>\n<td><strong>Limitations</strong></td>\n<td>Not human-readable</td>\n<td>VerboseTypes and docstrings not integral part of the syntax, meaning little-to-nonexistent metric contract validationParsing cost</td>\n</tr>\n<tr>\n<td><strong>Supported metric primitives</strong></td>\n<td>CounterGaugeHistogramSummaryUntyped</td>\n<td>CounterGaugeHistogramSummaryUntyped</td>\n</tr>\n<tr>\n<td><strong>Compatibility</strong></td>\n<td>Version <code>0.0.3</code> protocol buffers are also valid version <code>0.0.4</code> protocol buffers.</td>\n<td>none</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"5-2-基于协议缓冲区格式\"><a href=\"#5-2-基于协议缓冲区格式\" class=\"headerlink\" title=\"5.2 基于协议缓冲区格式\"></a>5.2 基于协议缓冲区格式</h3><p>​    Reproducible sorting of the protocol buffer fields in repeated expositions is preferred but not required, i.e. do not sort if the computational cost is prohibitive.</p>\n<p>​    Each <code>MetricFamily</code> within the same exposition must have a unique name. Each <code>Metric</code> within the same <code>MetricFamily</code> must have a unique set of <code>LabelPair</code> fields. Otherwise, the ingestion behavior is undefined.</p>\n<h3 id=\"5-3-文本类型格式\"><a href=\"#5-3-文本类型格式\" class=\"headerlink\" title=\"5.3 文本类型格式\"></a>5.3 文本类型格式</h3><p>​    ＃打头的是注释行（除非＃之后的第一个标记是HELP或TYPE）。</p>\n<p>​    HELP行：可能包含任何UTF-8字符序列（在指标名称之后），但反斜杠和换行字符必须分别转义为<code>\\\\</code>和<code>\\ n</code>。对于相同的指标名称，只能有一条HELP行，一个指标只能有一个HELP行。</p>\n<p>TYPE行：TPYE后的第一个参数是指标名，第二个参数是数据类型（可以是counter, gauge, histogram, summary,  untyped）。相同的指标名称，只能有一个TYPE行。如果指标名称没有TYPE行，则该类型设置为无类型。</p>\n<p>格式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">metric_name [</div><div class=\"line\">  &quot;&#123;&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#123; &quot;,&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#125; [ &quot;,&quot; ] &quot;&#125;&quot;</div><div class=\"line\">] value [ timestamp ]</div></pre></td></tr></table></figure>\n<p>label_value可以是任何UTF-8格式的内容，但反斜杠、双引号、换行符 必须转义成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\\\  \\&quot;  \\\\n</div></pre></td></tr></table></figure>\n<p>histogram（直方图）  summary（汇总）类型的特别格式：</p>\n<ol>\n<li>需要单独一行xxx_sum；</li>\n<li>需要单独一行xxx_count；</li>\n<li>Each quantile of a summary named x is given as a separate sample line with the same name x and a label {quantile=”y”}；</li>\n<li>A histogram must have a bucket with {le=”+Inf”}. Its value must be identical to the value of x_count；</li>\n<li>histogram类型必须要有{le=”+Inf”}，并且值要和xxx_count一致；</li>\n</ol>\n<h3 id=\"5-4-文本类型格式举例\"><a href=\"#5-4-文本类型格式举例\" class=\"headerlink\" title=\"5.4 文本类型格式举例\"></a>5.4 文本类型格式举例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP http_requests_total The total number of HTTP requests.</div><div class=\"line\"># TYPE http_requests_total counter</div><div class=\"line\">http_requests_total&#123;method=&quot;post&quot;,code=&quot;200&quot;&#125; 1027 1395066363000</div><div class=\"line\">http_requests_total&#123;method=&quot;post&quot;,code=&quot;400&quot;&#125;    3 1395066363000</div><div class=\"line\"></div><div class=\"line\"># Escaping in label values:</div><div class=\"line\">msdos_file_access_time_seconds&#123;path=&quot;C:\\\\DIR\\\\FILE.TXT&quot;,error=&quot;Cannot find file:\\n\\&quot;FILE.TXT\\&quot;&quot;&#125; 1.458255915e9</div><div class=\"line\"></div><div class=\"line\"># Minimalistic line:</div><div class=\"line\">metric_without_timestamp_and_labels 12.47</div><div class=\"line\"></div><div class=\"line\"># A weird metric from before the epoch:</div><div class=\"line\">something_weird&#123;problem=&quot;division by zero&quot;&#125; +Inf -3982045</div><div class=\"line\"></div><div class=\"line\"># A histogram, which has a pretty complex representation in the text format:</div><div class=\"line\"># HELP http_request_duration_seconds A histogram of the request duration.</div><div class=\"line\"># TYPE http_request_duration_seconds histogram</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.05&quot;&#125; 24054</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.1&quot;&#125; 33444</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.2&quot;&#125; 100392</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.5&quot;&#125; 129389</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;1&quot;&#125; 133988</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;+Inf&quot;&#125; 144320</div><div class=\"line\">http_request_duration_seconds_sum 53423</div><div class=\"line\">http_request_duration_seconds_count 144320</div><div class=\"line\"></div><div class=\"line\"># Finally a summary, which has a complex representation, too:</div><div class=\"line\"># HELP rpc_duration_seconds A summary of the RPC duration in seconds.</div><div class=\"line\"># TYPE rpc_duration_seconds summary</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.01&quot;&#125; 3102</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.05&quot;&#125; 3272</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 4773</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.9&quot;&#125; 9001</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.99&quot;&#125; 76656</div><div class=\"line\">rpc_duration_seconds_sum 1.7560473e+07</div><div class=\"line\">rpc_duration_seconds_count 2693</div></pre></td></tr></table></figure>\n<h2 id=\"6-导出器exporter\"><a href=\"#6-导出器exporter\" class=\"headerlink\" title=\"6 导出器exporter\"></a>6 导出器exporter</h2><h3 id=\"6-1-概述\"><a href=\"#6-1-概述\" class=\"headerlink\" title=\"6.1 概述\"></a>6.1 概述</h3><p>​    指标名，一般为导出程序名称作为前缀，例如， haproxy_up；</p>\n<p>​    度量标准必须使用基本单位（例如秒，字节），并保留将其转换为更具可读性的图形工具；</p>\n<pre><code>指标有效字符：`[a-zA-Z0-9:_]` ，其他任何字符都要用下划线_代替；\n</code></pre><p>​    指标后缀<code>_sum</code>, <code>_count</code>, <code>_bucket</code> and <code>_total</code> 只可用在Summaries、 Histograms 、 Counters</p>\n<h2 id=\"7-告警alertmanager程序\"><a href=\"#7-告警alertmanager程序\" class=\"headerlink\" title=\"7 告警alertmanager程序\"></a>7 告警alertmanager程序</h2><p>​    概述：</p>\n<p>​        promethues：根据配置文件prometheus.yml的rule_files告警规则，将告警信息存到promethues的磁盘，供promethues的前台页面查看；根据配置文件prometheus.yml的alerting（配置altermanager进程的ip 端口信息），将告警信息发送altermanager进程上。</p>\n<p>​        altermanager：接收promethues发来的告警信息，存在磁盘中供altermanager进程的前台查看；同时根据altermanager的告警配置文件simple.yml发送邮件等提醒。</p>\n<h3 id=\"7-1-promethues告警配置举例\"><a href=\"#7-1-promethues告警配置举例\" class=\"headerlink\" title=\"7.1 promethues告警配置举例\"></a>7.1 promethues告警配置举例</h3><p><img src=\"/img/promethues-alarm.png\" alt=\"\"></p>\n<h3 id=\"7-2-promethues告警规则配置文件举例\"><a href=\"#7-2-promethues告警规则配置文件举例\" class=\"headerlink\" title=\"7.2 promethues告警规则配置文件举例\"></a>7.2 promethues告警规则配置文件举例</h3><p><img src=\"/img/rule_file.png\" alt=\"\"></p>\n<p>alert：自定义的告警含义简写</p>\n<p>expor：告警条件，如上图的node_forks为具体mertics里的指标</p>\n<p>for：周期</p>\n<p>labels：severity，在alertmanager前台页面可以根据severity条件来查询告警信息</p>\n<p>annotations：summary写些较详细的告警信息</p>\n<h3 id=\"7-3-alertmanager告警发送邮件提示\"><a href=\"#7-3-alertmanager告警发送邮件提示\" class=\"headerlink\" title=\"7.3 alertmanager告警发送邮件提示\"></a>7.3 alertmanager告警发送邮件提示</h3><p><img src=\"/img/email_1.png\" alt=\"\"></p>\n<p><img src=\"/img/email_2.png\" alt=\"\"></p>\n<h3 id=\"7-4-启动alertmanager\"><a href=\"#7-4-启动alertmanager\" class=\"headerlink\" title=\"7.4 启动alertmanager\"></a>7.4 启动alertmanager</h3><p> nohup ./alertmanager –config.file=simple.yml &amp;</p>\n<p>alertmanager前台：<a href=\"http://192.168.7.176:9093/\" target=\"_blank\" rel=\"external\">http://192.168.7.176:9093/</a></p>\n<h3 id=\"7-5通过其他方式告警\"><a href=\"#7-5通过其他方式告警\" class=\"headerlink\" title=\"7.5通过其他方式告警\"></a>7.5通过其他方式告警</h3><h4 id=\"hipchat-config：\"><a href=\"#hipchat-config：\" class=\"headerlink\" title=\"hipchat_config：\"></a>hipchat_config：</h4><p>​    是一款能够在苹果mac平台上运行的社交聊天软件，HipChat的功能和QQ相似，集聊天、视频、语音等功能于一身，不同之处在于HipChat界面更加的简洁、操作更加的流畅。</p>\n<h4 id=\"pagerduty-config：\"><a href=\"#pagerduty-config：\" class=\"headerlink\" title=\"pagerduty_config：\"></a>pagerduty_config：</h4><p>​    是一款能够在服务器出问题时发送提醒的软件。在发生问题时，提醒的方式包括屏幕显示、电话呼叫、短信通知、电邮通知等，而且在无人应答时还会自动将提醒级别提高。PagerDuty 不是免费的。</p>\n<h4 id=\"pushover-config：\"><a href=\"#pushover-config：\" class=\"headerlink\" title=\"pushover_config：\"></a>pushover_config：</h4><p>​    是一款网络通知推送服务，类似ifttt或脚本服务，你可以将需要推送的服务设置好后，遇到情况将把通知自动推送到你的<a href=\"http://www.onlinedown.net/soft/222292.htm\" target=\"_blank\" rel=\"external\">安卓手机</a>。</p>\n<h4 id=\"slack-config：\"><a href=\"#slack-config：\" class=\"headerlink\" title=\"slack_config：\"></a>slack_config：</h4><p>​    slack是聊天群组 + 大规模工具集成 + 文件整合 + 统一搜索。截至2014年底，Slack 已经整合了电子邮件、短信、<a href=\"https://baike.baidu.com/item/Google\" target=\"_blank\" rel=\"external\">Google</a> Drives、<a href=\"https://baike.baidu.com/item/Twitter\" target=\"_blank\" rel=\"external\">Twitter</a>、Trello、Asana、<a href=\"https://baike.baidu.com/item/GitHub\" target=\"_blank\" rel=\"external\">GitHub</a> 等 65 种工具和服务，可以把各种碎片化的企业沟通和协作集中到一起。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Whether or not to notify about resolved alerts.</div><div class=\"line\">[ send_resolved: &lt;boolean&gt; | default = false ]</div><div class=\"line\"></div><div class=\"line\"># The Slack webhook URL.</div><div class=\"line\">[ api_url: &lt;secret&gt; | default = global.slack_api_url ]</div><div class=\"line\"></div><div class=\"line\"># The channel or user to send notifications to.</div><div class=\"line\">channel: &lt;tmpl_string&gt;</div><div class=\"line\"></div><div class=\"line\"># API request data as defined by the Slack webhook API.</div><div class=\"line\">[ color: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;danger&#123;&#123; else &#125;&#125;good&#123;&#123; end &#125;&#125;&apos; ]</div><div class=\"line\">[ username: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.username&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ title: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.title&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ title_link: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.titlelink&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ icon_emoji: &lt;tmpl_string&gt; ]</div><div class=\"line\">[ icon_url: &lt;tmpl_string&gt; ]</div><div class=\"line\">[ pretext: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.pretext&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ text: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.text&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ fallback: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.fallback&quot; . &#125;&#125;&apos; ]</div><div class=\"line\"></div><div class=\"line\"># The HTTP client&apos;s configuration.</div><div class=\"line\">[ http_config: &lt;http_config&gt; | default = global.http_config ]</div></pre></td></tr></table></figure>\n<h4 id=\"opsgenie-config-：\"><a href=\"#opsgenie-config-：\" class=\"headerlink\" title=\"opsgenie_config ：\"></a>opsgenie_config ：</h4><p>​    集成电话短信邮件等等</p>\n<h4 id=\"victorops-config：\"><a href=\"#victorops-config：\" class=\"headerlink\" title=\"victorops_config：\"></a>victorops_config：</h4><p>​    聊天应用</p>\n<h4 id=\"http-config：\"><a href=\"#http-config：\" class=\"headerlink\" title=\"http_config：\"></a>http_config：</h4><p>​    A <code>http_config</code> allows configuring the HTTP client that the receiver uses to communicate with HTTP-based API services.</p>\n<h2 id=\"8-问题笔记\"><a href=\"#8-问题笔记\" class=\"headerlink\" title=\"8 问题笔记\"></a>8 问题笔记</h2><h3 id=\"8-1已解决\"><a href=\"#8-1已解决\" class=\"headerlink\" title=\"8.1已解决\"></a>8.1已解决</h3><ol>\n<li>prometheus浏览器查询不到exporter指标数据，但是浏览器exporter的mertic有指标数据。原因是时间不同步</li>\n</ol>\n<h3 id=\"8-2-未解决\"><a href=\"#8-2-未解决\" class=\"headerlink\" title=\"8.2 未解决\"></a>8.2 未解决</h3>","site":{"data":{}},"excerpt":"<h2 id=\"1-概述\"><a href=\"#1-概述\" class=\"headerlink\" title=\"1 概述\"></a>1 概述</h2><h3 id=\"1-1-主要功能\"><a href=\"#1-1-主要功能\" class=\"headerlink\" title=\"1.1 主要功能\"></a>1.1 主要功能</h3><ul>\n<li>多维 <a href=\"https://prometheus.io/docs/concepts/data_model/\" target=\"_blank\" rel=\"external\">数据模型</a>（时序由 metric 名字和 k/v 的 labels 构成）。</li>\n<li>灵活的查询语句（<a href=\"https://prometheus.io/docs/querying/basics/\" target=\"_blank\" rel=\"external\">PromQL</a>）。</li>\n<li>无依赖存储，支持 local 和 remote 不同模型。</li>\n<li>采用 http 协议，使用 pull 模式，拉取数据，简单易懂。</li>\n<li>监控目标，可以采用服务发现或静态配置的方式。</li>\n<li>支持多种统计数据模型，图形化友好。</li>\n</ul>\n<h3 id=\"1-2-核心组件\"><a href=\"#1-2-核心组件\" class=\"headerlink\" title=\"1.2 核心组件\"></a>1.2 核心组件</h3><ul>\n<li><a href=\"https://github.com/prometheus/prometheus\" target=\"_blank\" rel=\"external\">Prometheus Server</a>， 主要用于抓取数据和存储时序数据，另外还提供查询和 Alert Rule 配置管理。</li>\n<li><a href=\"https://prometheus.io/docs/instrumenting/clientlibs/\" target=\"_blank\" rel=\"external\">client libraries</a>，用于对接 Prometheus Server, 可以查询和上报数据。</li>\n<li><a href=\"https://github.com/prometheus/pushgateway\" target=\"_blank\" rel=\"external\">push gateway</a> ，用于批量，短期的监控数据的汇总节点，主要用于业务数据汇报等。</li>\n<li>各种汇报数据的 <a href=\"https://prometheus.io/docs/instrumenting/exporters/\" target=\"_blank\" rel=\"external\">exporters</a> ，例如汇报机器数据的 node_exporter,  汇报 MongoDB 信息的 <a href=\"https://github.com/dcu/mongodb_exporter\" target=\"_blank\" rel=\"external\">MongoDB exporter</a> 等等。</li>\n<li>用于告警通知管理的 <a href=\"https://github.com/prometheus/alertmanager\" target=\"_blank\" rel=\"external\">alertmanager</a> 。</li>\n</ul>\n<h3 id=\"1-3-基础架构\"><a href=\"#1-3-基础架构\" class=\"headerlink\" title=\"1.3 基础架构\"></a>1.3 基础架构</h3><p>一图胜千言，先来张官方的架构图</p>\n<p><img src=\"/img/prometheus1.png\" alt=\"img\"></p>","more":"<p>从这个架构图，也可以看出 Prometheus 的主要模块包含， Server,  Exporters, Pushgateway, PromQL, Alertmanager, WebUI 等。</p>\n<p>它大致使用逻辑是这样：</p>\n<ol>\n<li>Prometheus server 定期从静态配置的 targets 或者服务发现的 targets 拉取数据。</li>\n<li>当新拉取的数据大于配置内存缓存区的时候，Prometheus 会将数据持久化到磁盘（如果使用 remote storage 将持久化到云端）。</li>\n<li>Prometheus 可以配置 rules，然后定时查询数据，当条件触发的时候，会将 alert 推送到配置的 Alertmanager。</li>\n<li>Alertmanager 收到警告的时候，可以根据配置，聚合，去重，降噪，最后发送警告。</li>\n<li>可以使用 API， Prometheus Console 或者 Grafana 查询和聚合数据。</li>\n</ol>\n<h3 id=\"1-4-注意\"><a href=\"#1-4-注意\" class=\"headerlink\" title=\"1.4 注意\"></a>1.4 注意</h3><ul>\n<li>Prometheus 的数据是基于时序的 float64 的值，如果你的数据值有更多类型，无法满足。</li>\n<li>Prometheus 不适合做审计计费，因为它的数据是按一定时间采集的，关注的更多是系统的运行瞬时状态以及趋势，即使有少量数据没有采集也能容忍，但是审计计费需要记录每个请求，并且数据长期存储，这个和 Prometheus 无法满足，可能需要采用专门的审计系统。</li>\n</ul>\n<h2 id=\"2-BO关注项\"><a href=\"#2-BO关注项\" class=\"headerlink\" title=\"2 BO关注项\"></a>2 BO关注项</h2><h3 id=\"2-1-数据收集方式\"><a href=\"#2-1-数据收集方式\" class=\"headerlink\" title=\"2.1 数据收集方式\"></a>2.1 数据收集方式</h3><p>使用 pull 模式，拉取数据。</p>\n<h3 id=\"2-2-数据格式\"><a href=\"#2-2-数据格式\" class=\"headerlink\" title=\"2.2 数据格式\"></a>2.2 数据格式</h3><p>Prometheus 时序格式与 <a href=\"http://opentsdb.net/\" target=\"_blank\" rel=\"external\">OpenTSDB</a> 相似：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;metric name&gt;&#123;&lt;label name&gt;=&lt;label value&gt;, ...&#125;</div></pre></td></tr></table></figure>\n<p>其中包含时序名字以及时序的标签。</p>\n<h4 id=\"2-2-1-时序-4-种类型\"><a href=\"#2-2-1-时序-4-种类型\" class=\"headerlink\" title=\"2.2.1 时序 4 种类型\"></a>2.2.1 时序 4 种类型</h4><p>Prometheus 时序数据分为 <a href=\"https://prometheus.io/docs/concepts/metric_types/#counter\" target=\"_blank\" rel=\"external\">Counter</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#gauge\" target=\"_blank\" rel=\"external\">Gauge</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#histogram\" target=\"_blank\" rel=\"external\">Histogram</a>, <a href=\"https://prometheus.io/docs/concepts/metric_types/#summary\" target=\"_blank\" rel=\"external\">Summary</a> 四种类型。</p>\n<h5 id=\"2-2-1-1-Counter\"><a href=\"#2-2-1-1-Counter\" class=\"headerlink\" title=\"2.2.1.1 Counter\"></a>2.2.1.1 Counter</h5><p>Counter 表示收集的数据是按照某个趋势（增加／减少）一直变化的，我们往往用它记录服务请求总量，错误总数等。</p>\n<p>例如 Prometheus server 中 <code>http_requests_total</code>,  表示 Prometheus 处理的 http 请求总数，我们可以使用 <code>delta</code>, 很容易得到任意区间数据的增量，这个会在 PromQL 一节中细讲。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP http_requests_total Total number of HTTP requests made.</div><div class=\"line\"># TYPE http_requests_total counter</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;alerts&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;config&quot;,method=&quot;get&quot;&#125; 1</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;flags&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;graph&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;label_values&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;prometheus&quot;,method=&quot;get&quot;&#125; 24755</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;query&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;static&quot;,method=&quot;get&quot;&#125; 6</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;status&quot;,method=&quot;get&quot;&#125; 2</div><div class=\"line\">http_requests_total&#123;code=&quot;200&quot;,handler=&quot;targets&quot;,method=&quot;get&quot;&#125; 4</div><div class=\"line\">http_requests_total&#123;code=&quot;304&quot;,handler=&quot;static&quot;,method=&quot;get&quot;&#125; 4</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-2-Gauge\"><a href=\"#2-2-1-2-Gauge\" class=\"headerlink\" title=\"2.2.1.2 Gauge\"></a>2.2.1.2 Gauge</h5><p>Gauge 表示搜集的数据是一个瞬时的，与时间没有关系，可以任意变高变低，往往可以用来记录内存使用率、磁盘使用率等。</p>\n<p>例如 Prometheus server 中 <code>go_goroutines</code>,  表示 Prometheus 当前 goroutines 的数量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP go_goroutines Number of goroutines that currently exist.</div><div class=\"line\"># TYPE go_goroutines gauge</div><div class=\"line\">go_goroutines 100</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-3-Histogram\"><a href=\"#2-2-1-3-Histogram\" class=\"headerlink\" title=\"2.2.1.3 Histogram\"></a>2.2.1.3 Histogram</h5><p>Histogram 由 <code>&lt;basename&gt;_bucket{le=&quot;&lt;upper inclusive bound&gt;&quot;}</code>，<code>&lt;basename&gt;_bucket{le=&quot;+Inf&quot;}</code>, <code>&lt;basename&gt;_sum</code>，<code>&lt;basename&gt;_count</code> 组成，主要用于表示一段时间范围内对数据进行采样，（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常我们用它计算分位数的直方图。</p>\n<p>例如 Prometheus server 中 <code>prometheus_local_storage_series_chunks_persisted</code>,  表示 Prometheus 中每个时序需要存储的 chunks 数量，我们可以用它计算待持久化的数据的分位数。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction</div><div class=\"line\"># TYPE prometheus_tsdb_compaction_chunk_range histogram</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;100&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;400&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1600&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6400&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;25600&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;102400&quot;&#125; 0</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;409600&quot;&#125; 605</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;1.6384e+06&quot;&#125; 612</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;6.5536e+06&quot;&#125; 126358</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;2.62144e+07&quot;&#125; 126358</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_bucket&#123;le=&quot;+Inf&quot;&#125; 126358</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_sum 2.25313627417e+11</div><div class=\"line\">prometheus_tsdb_compaction_chunk_range_count 126358</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-4-Summary\"><a href=\"#2-2-1-4-Summary\" class=\"headerlink\" title=\"2.2.1.4 Summary\"></a>2.2.1.4 Summary</h5><p>Summary 和 Histogram 类似，由 <code>&lt;basename&gt;{quantile=&quot;&lt;φ&gt;&quot;}</code>，<code>&lt;basename&gt;_sum</code>，<code>&lt;basename&gt;_count</code> 组成，主要用于表示一段时间内数据采样结果，（通常是请求持续时间或响应大小），它直接存储了 quantile 数据，而不是根据统计区间计算出来的。</p>\n<p>例如 Prometheus server 中 <code>prometheus_target_interval_length_seconds</code>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.</div><div class=\"line\"># TYPE prometheus_target_interval_length_seconds summary</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.01&quot;&#125; 14.999987534</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.05&quot;&#125; 14.999987534</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.5&quot;&#125; 15.000020575</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.9&quot;&#125; 15.000045415</div><div class=\"line\">prometheus_target_interval_length_seconds&#123;interval=&quot;15s&quot;,quantile=&quot;0.99&quot;&#125; 15.000050555</div><div class=\"line\">prometheus_target_interval_length_seconds_sum&#123;interval=&quot;15s&quot;&#125; 371280.61110144516</div><div class=\"line\">prometheus_target_interval_length_seconds_count&#123;interval=&quot;15s&quot;&#125; 24752</div></pre></td></tr></table></figure>\n<h5 id=\"2-2-1-5-Histogram-vs-Summary\"><a href=\"#2-2-1-5-Histogram-vs-Summary\" class=\"headerlink\" title=\"2.2.1.5 Histogram vs Summary\"></a>2.2.1.5 Histogram vs Summary</h5><ul>\n<li>都包含 <code>&lt;basename&gt;_sum</code>，<code>&lt;basename&gt;_count</code></li>\n<li>Histogram 需要通过 <code>&lt;basename&gt;_bucket</code> 计算 quantile, 而 Summary 直接存储了 quantile 的值。</li>\n</ul>\n<h3 id=\"2-2-3-数据存储方式\"><a href=\"#2-2-3-数据存储方式\" class=\"headerlink\" title=\"2.2.3 数据存储方式\"></a>2.2.3 数据存储方式</h3><p>​    数据存在promethues自身的数据库，以数据文件的形式存储，有自身的查询方式：promql；详见<a href=\"https://songjiayang.gitbooks.io/prometheus/content/promql/summary.html\" target=\"_blank\" rel=\"external\">https://songjiayang.gitbooks.io/prometheus/content/promql/summary.html</a></p>\n<h3 id=\"2-2-4-数据输出方式\"><a href=\"#2-2-4-数据输出方式\" class=\"headerlink\" title=\"2.2.4 数据输出方式\"></a>2.2.4 数据输出方式</h3><p>​    agent：被动拉取；</p>\n<p>​    promethues server：主动拉取客户端的数据。promethues将拉取到的数据存到data/目录。（除了 promethues 前台的PromQ查询页面，应该有某种工具可以直接在命令行查询promethues的历史数据（暂未找到）；多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式（工具未研究过）。）</p>\n<h3 id=\"2-2-5-agent部署方式\"><a href=\"#2-2-5-agent部署方式\" class=\"headerlink\" title=\"2.2.5 agent部署方式\"></a>2.2.5 agent部署方式</h3><p>​    promethues未提供自动部署agent的功能。</p>\n<h3 id=\"2-2-6-任务下发方式\"><a href=\"#2-2-6-任务下发方式\" class=\"headerlink\" title=\"2.2.6 任务下发方式\"></a>2.2.6 任务下发方式</h3><p>​    agent每个周期固定采集设备的指定指标，若要自定义采集某些指标则需要修改agent源码。</p>\n<p>​    promethues server拉取数据的任务在prometheus.yml配置。</p>\n<h2 id=\"3-promethues组件及部署\"><a href=\"#3-promethues组件及部署\" class=\"headerlink\" title=\"3 promethues组件及部署\"></a>3 promethues组件及部署</h2><h3 id=\"3-1-promethues-server\"><a href=\"#3-1-promethues-server\" class=\"headerlink\" title=\"3.1 promethues server\"></a>3.1 promethues server</h3><h4 id=\"3-1-1-部署\"><a href=\"#3-1-1-部署\" class=\"headerlink\" title=\"3.1.1 部署\"></a>3.1.1 部署</h4><p>​    tar包解压即可用</p>\n<h4 id=\"3-1-2-prometheus-yml配置举例\"><a href=\"#3-1-2-prometheus-yml配置举例\" class=\"headerlink\" title=\"3.1.2 prometheus.yml配置举例\"></a>3.1.2 prometheus.yml配置举例</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">global:</div><div class=\"line\">  scrape_interval:     15s # By default, scrape targets every 15 seconds.</div><div class=\"line\">  evaluation_interval: 15s # By default, scrape targets every 15 seconds.</div><div class=\"line\"></div><div class=\"line\">rule_files:</div><div class=\"line\">  - &quot;rules/node.rules&quot;</div><div class=\"line\"></div><div class=\"line\">scrape_configs:</div><div class=\"line\">  - job_name: &apos;prometheus&apos;</div><div class=\"line\">    scrape_interval: 5s</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;localhost:9090&apos;]</div><div class=\"line\"></div><div class=\"line\">  - job_name: &apos;node&apos;</div><div class=\"line\">    scrape_interval: 8s</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;127.0.0.1:9100&apos;, &apos;127.0.0.12:9100&apos;]</div><div class=\"line\"></div><div class=\"line\">  - job_name: &apos;mysqld&apos;</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;127.0.0.1:9104&apos;]</div><div class=\"line\">  - job_name: &apos;memcached&apos;</div><div class=\"line\">    static_configs:</div><div class=\"line\">      - targets: [&apos;127.0.0.1:9150&apos;]</div></pre></td></tr></table></figure>\n<h4 id=\"3-1-3-命令\"><a href=\"#3-1-3-命令\" class=\"headerlink\" title=\"3.1.3 命令\"></a>3.1.3 命令</h4><p>[chenrj@kfapp01 prometheus-2.0.0.linux-amd64]$ ./prometheus -h<br>usage: prometheus [<flags>]</flags></p>\n<p>The Prometheus monitoring server</p>\n<p>Flags:<br>  -h, –help                     Show context-sensitive help (also try –help-long and –help-man).</p>\n<h4 id=\"3-1-4-前台地址\"><a href=\"#3-1-4-前台地址\" class=\"headerlink\" title=\"3.1.4 前台地址\"></a>3.1.4 前台地址</h4><p>​    <a href=\"http://192.168.7.40:9090/graph\" target=\"_blank\" rel=\"external\">http://192.168.7.40:9090/graph</a></p>\n<p>​    默认9090端口</p>\n<h3 id=\"3-2-grafana\"><a href=\"#3-2-grafana\" class=\"headerlink\" title=\"3.2 grafana\"></a>3.2 grafana</h3><p>​       <a href=\"http://192.168.7.40:3000/\" target=\"_blank\" rel=\"external\">http://192.168.7.40:3000</a></p>\n<p>​       端口默认3000，</p>\n<p>​       用户密码： admin/admin</p>\n<p>​    ./grafana-server</p>\n<h3 id=\"3-3-主机节点\"><a href=\"#3-3-主机节点\" class=\"headerlink\" title=\"3.3 主机节点\"></a>3.3 主机节点</h3><p>​    <a href=\"http://10.140.20.142:9100/metrics\" target=\"_blank\" rel=\"external\">http://10.140.20.142:9100/metrics</a></p>\n<h3 id=\"3-4-redis节点\"><a href=\"#3-4-redis节点\" class=\"headerlink\" title=\"3.4 redis节点\"></a>3.4 redis节点</h3><p>​    <a href=\"http://10.140.20.143:9121/metrics\" target=\"_blank\" rel=\"external\">http://10.140.20.143:9121/metrics</a> </p>\n<h3 id=\"3-5-elasticsearch节点\"><a href=\"#3-5-elasticsearch节点\" class=\"headerlink\" title=\"3.5 elasticsearch节点\"></a>3.5 elasticsearch节点</h3><p>​    <a href=\"http://10.140.20.146:9108/metrics\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9108/metrics</a></p>\n<h2 id=\"4-数据查询\"><a href=\"#4-数据查询\" class=\"headerlink\" title=\"4 数据查询\"></a>4 数据查询</h2><h3 id=\"4-1-http方式查询promethues数据\"><a href=\"#4-1-http方式查询promethues数据\" class=\"headerlink\" title=\"4.1 http方式查询promethues数据\"></a>4.1 http方式查询promethues数据</h3><p>​    <a href=\"https://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata\" target=\"_blank\" rel=\"external\">https://prometheus.io/docs/prometheus/latest/querying/api/#querying-metadata</a></p>\n<h4 id=\"4-1-1-即时查询\"><a href=\"#4-1-1-即时查询\" class=\"headerlink\" title=\"4.1.1 即时查询\"></a>4.1.1 即时查询</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/query</div></pre></td></tr></table></figure>\n<p><strong>URL查询参数：</strong></p>\n<ul>\n<li><code>query=&lt;string&gt;</code>：普罗米修斯表达查询字符串。</li>\n<li><code>time=&lt;rfc3339 | unix_timestamp&gt;</code>：评估时间戳。可选的。</li>\n<li><code>timeout=&lt;duration&gt;</code>：评价超时。可选的。默认为，并通过价值上限<code>-query.timeout</code>标志。</li>\n</ul>\n<p>若省略时间time测试，则默认使用服务器时间</p>\n<p><strong>例：</strong>查询2018-01-16T03:12:51.781这个时刻go_memstats_frees_total的值</p>\n<p>[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl ‘<a href=\"http://10.140.20.146:9090/api/v1/query?query=go_memstats_frees_total&amp;time=2018-01-16T03:12:51.781Z\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9090/api/v1/query?query=go_memstats_frees_total&amp;time=2018-01-16T03:12:51.781Z</a>‘<br>{“status”:”success”,”data”:{“resultType”:”vector”,”result”:[{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.142:9100”,”job”:”node”},”value”:[1516072371.781,”5599415948”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.143:9100”,”job”:”node”},”value”:[1516072371.781,”5152870637”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.143:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1385642849”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.143:9121”,”job”:”redis_exporter_143”},”value”:[1516072371.781,”159639669”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.144:9100”,”job”:”node”},”value”:[1516072371.781,”5167404030”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.144:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1383957758”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.144:9121”,”job”:”redis_exporter_144”},”value”:[1516072371.781,”373190465”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.145:9100”,”job”:”node”},”value”:[1516072371.781,”5124941908”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.145:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1370943258”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.146:9100”,”job”:”node”},”value”:[1516072371.781,”4850755799”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”10.140.20.146:9108”,”job”:”elasticsearch_exporter”},”value”:[1516072371.781,”1370683906”]},{“metric”:{“<strong>name</strong>“:”go_memstats_frees_total”,”instance”:”localhost:9090”,”job”:”prometheus”},”value”:[1516072371.781,”2299674805”]}]}}</p>\n<p><strong>注：”value”:[时间戳,”对应值”]</strong></p>\n<h4 id=\"4-1-2-范围查询\"><a href=\"#4-1-2-范围查询\" class=\"headerlink\" title=\"4.1.2 范围查询\"></a>4.1.2 范围查询</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/query_range</div></pre></td></tr></table></figure>\n<p><strong>URL查询参数：</strong></p>\n<ul>\n<li><code>query=&lt;string&gt;</code>：普罗米修斯表达查询字符串。</li>\n<li><code>start=&lt;rfc3339 | unix_timestamp&gt;</code>：开始时间戳。</li>\n<li><code>end=&lt;rfc3339 | unix_timestamp&gt;</code>：结束时间戳。</li>\n<li><code>step=&lt;duration&gt;</code>：查询分辨率步的宽度。</li>\n<li><code>timeout=&lt;duration&gt;</code>：评价超时。可选的。默认为，并通过价值上限<code>-query.timeout</code>标志。</li>\n</ul>\n<p>例：时间在2018-01-01T20:10:30.781到2018-01-01T20:11:00.781范围内，间隔15秒，up的数据</p>\n<p>[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl ‘<a href=\"http://10.140.20.146:9090/api/v1/query_range?query=up&amp;start=2018-01-01T20:10:30.781Z&amp;end=2018-01-01T20:11:00.781Z&amp;step=15s\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9090/api/v1/query_range?query=up&amp;start=2018-01-01T20:10:30.781Z&amp;end=2018-01-01T20:11:00.781Z&amp;step=15s</a>‘<br>{“status”:”success”,”data”:{“resultType”:”matrix”,”result”:[{“metric”:{“<strong>name</strong>“:”up”,”instance”:”localhost:9090”,”job”:”prometheus”},”values”:[[1514837430.781,”1”],[1514837445.781,”1”],[1514837460.781,”1”]]},{“metric”:{“<strong>name</strong>“:”up”,”instance”:”localhost:9100”,”job”:”node”},”values”:[[1514837430.781,”0”],[1514837445.781,”0”],[1514837460.781,”0”]]}]}}</p>\n<h3 id=\"4-2-http查询方式作用未知系列？？\"><a href=\"#4-2-http查询方式作用未知系列？？\" class=\"headerlink\" title=\"4.2 http查询方式作用未知系列？？\"></a>4.2 http查询方式作用未知系列？？</h3><h4 id=\"Querying-metadata\"><a href=\"#Querying-metadata\" class=\"headerlink\" title=\"Querying metadata\"></a>Querying metadata</h4><h5 id=\"Finding-series-by-label-matchers\"><a href=\"#Finding-series-by-label-matchers\" class=\"headerlink\" title=\"Finding series by label matchers\"></a>Finding series by label matchers</h5><p>The following endpoint returns the list of time series that match a certain label set.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/series</div></pre></td></tr></table></figure>\n<p>URL query parameters:</p>\n<ul>\n<li><code>match[]=&lt;series_selector&gt;</code>: Repeated series selector argument that selects the series to return. At least one <code>match[]</code> argument must be provided.</li>\n<li><code>start=&lt;rfc3339 | unix_timestamp&gt;</code>: Start timestamp.</li>\n<li><code>end=&lt;rfc3339 | unix_timestamp&gt;</code>: End timestamp.</li>\n</ul>\n<p>The <code>data</code> section of the query result consists of a list of objects that contain the label name/value pairs which identify each series.</p>\n<p>The following example returns all series that match either of the selectors <code>up</code> or <code>process_start_time_seconds{job=&quot;prometheus&quot;}</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl -g &apos;http://localhost:9090/api/v1/series?match[]=up&amp;match[]=process_start_time_seconds&#123;job=&quot;prometheus&quot;&#125;&apos;</div><div class=\"line\">&#123;</div><div class=\"line\">   &quot;status&quot; : &quot;success&quot;,</div><div class=\"line\">   &quot;data&quot; : [</div><div class=\"line\">      &#123;</div><div class=\"line\">         &quot;__name__&quot; : &quot;up&quot;,</div><div class=\"line\">         &quot;job&quot; : &quot;prometheus&quot;,</div><div class=\"line\">         &quot;instance&quot; : &quot;localhost:9090&quot;</div><div class=\"line\">      &#125;,</div><div class=\"line\">      &#123;</div><div class=\"line\">         &quot;__name__&quot; : &quot;up&quot;,</div><div class=\"line\">         &quot;job&quot; : &quot;node&quot;,</div><div class=\"line\">         &quot;instance&quot; : &quot;localhost:9091&quot;</div><div class=\"line\">      &#125;,</div><div class=\"line\">      &#123;</div><div class=\"line\">         &quot;__name__&quot; : &quot;process_start_time_seconds&quot;,</div><div class=\"line\">         &quot;job&quot; : &quot;prometheus&quot;,</div><div class=\"line\">         &quot;instance&quot; : &quot;localhost:9090&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">   ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"Querying-label-values\"><a href=\"#Querying-label-values\" class=\"headerlink\" title=\"Querying label values\"></a>Querying label values</h5><p>The following endpoint returns a list of label values for a provided label name:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/label/&lt;label_name&gt;/values</div></pre></td></tr></table></figure>\n<p>The <code>data</code> section of the JSON response is a list of string label names.</p>\n<p>This example queries for all label values for the <code>job</code> label:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl http://localhost:9090/api/v1/label/job/values</div><div class=\"line\">&#123;</div><div class=\"line\">   &quot;status&quot; : &quot;success&quot;,</div><div class=\"line\">   &quot;data&quot; : [</div><div class=\"line\">      &quot;node&quot;,</div><div class=\"line\">      &quot;prometheus&quot;</div><div class=\"line\">   ]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"Expression-query-result-formats\"><a href=\"#Expression-query-result-formats\" class=\"headerlink\" title=\"Expression query result formats\"></a>Expression query result formats</h4><p>Expression queries may return the following response values in the <code>result</code> property of the <code>data</code> section. <code>&lt;sample_value&gt;</code> placeholders are numeric sample values. JSON does not support special float values such as <code>NaN</code>, <code>Inf</code>, and <code>-Inf</code>, so sample values are transferred as quoted JSON strings rather than raw numbers.</p>\n<h5 id=\"Range-vectors\"><a href=\"#Range-vectors\" class=\"headerlink\" title=\"Range vectors\"></a>Range vectors</h5><p>Range vectors are returned as result type <code>matrix</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">[</div><div class=\"line\">  &#123;</div><div class=\"line\">    &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;,</div><div class=\"line\">    &quot;values&quot;: [ [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ], ... ]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  ...</div><div class=\"line\">]</div></pre></td></tr></table></figure>\n<h5 id=\"Instant-vectors\"><a href=\"#Instant-vectors\" class=\"headerlink\" title=\"Instant vectors\"></a>Instant vectors</h5><p>Instant vectors are returned as result type <code>vector</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">[</div><div class=\"line\">  &#123;</div><div class=\"line\">    &quot;metric&quot;: &#123; &quot;&lt;label_name&gt;&quot;: &quot;&lt;label_value&gt;&quot;, ... &#125;,</div><div class=\"line\">    &quot;value&quot;: [ &lt;unix_time&gt;, &quot;&lt;sample_value&gt;&quot; ]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  ...</div><div class=\"line\">]</div></pre></td></tr></table></figure>\n<h5 id=\"Scalars\"><a href=\"#Scalars\" class=\"headerlink\" title=\"Scalars\"></a>Scalars</h5><p>Scalar results are returned as result type <code>scalar</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[ &lt;unix_time&gt;, &quot;&lt;scalar_value&gt;&quot; ]</div></pre></td></tr></table></figure>\n<h5 id=\"Strings\"><a href=\"#Strings\" class=\"headerlink\" title=\"Strings\"></a>Strings</h5><p>String results are returned as result type <code>string</code>. The corresponding <code>result</code> property has the following format:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">[ &lt;unix_time&gt;, &quot;&lt;string_value&gt;&quot; ]</div></pre></td></tr></table></figure>\n<h4 id=\"Targets\"><a href=\"#Targets\" class=\"headerlink\" title=\"Targets\"></a>Targets</h4><blockquote>\n<p>This API is experimental as it is intended to be extended with targets dropped due to relabelling in the future.</p>\n</blockquote>\n<p>The following endpoint returns an overview of the current state of the Prometheus target discovery:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/targets</div></pre></td></tr></table></figure>\n<p>Currently only the active targets are part of the response.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl http://localhost:9090/api/v1/targets</div><div class=\"line\">&#123;</div><div class=\"line\">  &quot;status&quot;: &quot;success&quot;,                                                                                                                                [3/11]</div><div class=\"line\">  &quot;data&quot;: &#123;</div><div class=\"line\">    &quot;activeTargets&quot;: [</div><div class=\"line\">      &#123;</div><div class=\"line\">        &quot;discoveredLabels&quot;: &#123;</div><div class=\"line\">          &quot;__address__&quot;: &quot;127.0.0.1:9090&quot;,</div><div class=\"line\">          &quot;__metrics_path__&quot;: &quot;/metrics&quot;,</div><div class=\"line\">          &quot;__scheme__&quot;: &quot;http&quot;,</div><div class=\"line\">          &quot;job&quot;: &quot;prometheus&quot;</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;labels&quot;: &#123;</div><div class=\"line\">          &quot;instance&quot;: &quot;127.0.0.1:9090&quot;,</div><div class=\"line\">          &quot;job&quot;: &quot;prometheus&quot;</div><div class=\"line\">        &#125;,</div><div class=\"line\">        &quot;scrapeUrl&quot;: &quot;http://127.0.0.1:9090/metrics&quot;,</div><div class=\"line\">        &quot;lastError&quot;: &quot;&quot;,</div><div class=\"line\">        &quot;lastScrape&quot;: &quot;2017-01-17T15:07:44.723715405+01:00&quot;,</div><div class=\"line\">        &quot;health&quot;: &quot;up&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    ]</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"Alertmanagers\"><a href=\"#Alertmanagers\" class=\"headerlink\" title=\"Alertmanagers\"></a>Alertmanagers</h4><blockquote>\n<p>This API is experimental as it is intended to be extended with Alertmanagers dropped due to relabelling in the future.</p>\n</blockquote>\n<p>The following endpoint returns an overview of the current state of the Prometheus alertmanager discovery:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">GET /api/v1/alertmanagers</div></pre></td></tr></table></figure>\n<p>Currently only the active Alertmanagers are part of the response.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl http://localhost:9090/api/v1/alertmanagers</div><div class=\"line\">&#123;</div><div class=\"line\">  &quot;status&quot;: &quot;success&quot;,</div><div class=\"line\">  &quot;data&quot;: &#123;</div><div class=\"line\">    &quot;activeAlertmanagers&quot;: [</div><div class=\"line\">      &#123;</div><div class=\"line\">        &quot;url&quot;: &quot;http://127.0.0.1:9090/api/v1/alerts&quot;</div><div class=\"line\">      &#125;</div><div class=\"line\">    ]</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>查询指标标签：    curl -g ‘<a href=\"http://192.168.7.40:9090/api/v1/series?match[]=up&amp;match[]=process_start_time_seconds{job=&quot;prometheus&quot;}\" target=\"_blank\" rel=\"external\">http://192.168.7.40:9090/api/v1/series?match[]=up&amp;match[]=process_start_time_seconds{job=&quot;prometheus&quot;}</a>‘</p>\n<p>查询标签 {“status”:”success”,”data”:[]}[logstash@CP-ITSM-OMC-ZSC05 supervisor]$ curl <a href=\"http://10.140.20.146:9090/api/v1/label/job/values\" target=\"_blank\" rel=\"external\">http://10.140.20.146:9090/api/v1/label/job/values</a><br>{“status”:”success”,”data”:[“elasticsearch_exporter”,”node”,”prometheus”,”redis_exporter”,”redis_exporter_143”,”redis_exporter_144”]}</p>\n<h3 id=\"4-3-查询节点数据\"><a href=\"#4-3-查询节点数据\" class=\"headerlink\" title=\"4.3 查询节点数据\"></a>4.3 查询节点数据</h3><p>​    查询节点exporter的所有数据：curl -s <a href=\"http://192.168.7.40:9100/metrics\" target=\"_blank\" rel=\"external\">http://192.168.7.40:9100/metrics</a></p>\n<h2 id=\"5-exporter格式\"><a href=\"#5-exporter格式\" class=\"headerlink\" title=\"5 exporter格式\"></a>5 exporter格式</h2><p>基于协议缓冲区格式 和 文本格式</p>\n<p>客户端可以暴露promethues无法解析的其他格式</p>\n<h3 id=\"5-1-基于协议缓冲区格式-和-文本格式-的区别\"><a href=\"#5-1-基于协议缓冲区格式-和-文本格式-的区别\" class=\"headerlink\" title=\"5.1 基于协议缓冲区格式 和 文本格式 的区别\"></a>5.1 基于协议缓冲区格式 和 文本格式 的区别</h3><table>\n<thead>\n<tr>\n<th></th>\n<th>Protocol buffer format</th>\n<th>Text format</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Inception</strong></td>\n<td>April 2014</td>\n<td>April 2014</td>\n</tr>\n<tr>\n<td><strong>Supported in</strong></td>\n<td>Prometheus version <code>&gt;=0.4.0</code></td>\n<td>Prometheus version <code>&gt;=0.4.0</code></td>\n</tr>\n<tr>\n<td><strong>Transmission</strong></td>\n<td>HTTP</td>\n<td>HTTP</td>\n</tr>\n<tr>\n<td><strong>Encoding</strong></td>\n<td><a href=\"https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/AbstractMessageLite#writeDelimitedTo(java.io.OutputStream\" target=\"_blank\" rel=\"external\">32-bit varint-encoded record length-delimited</a>) Protocol Buffer messages of type <a href=\"https://github.com/prometheus/client_model/blob/086fe7ca28bde6cec2acd5223423c1475a362858/metrics.proto#L76-%20%20L81\" target=\"_blank\" rel=\"external\">io.prometheus.client.MetricFamily</a></td>\n<td>UTF-8, <code>\\n</code> line endings</td>\n</tr>\n<tr>\n<td><strong>HTTP Content-Type</strong></td>\n<td><code>application/vnd.google.protobuf; proto=io.prometheus.client.MetricFamily; encoding=delimited</code></td>\n<td><code>text/plain; version=0.0.4</code> (A missing <code>version</code> value will lead to a fall-back to the most recent text format version.)</td>\n</tr>\n<tr>\n<td><strong>Optional HTTP Content-Encoding</strong></td>\n<td><code>gzip</code></td>\n<td><code>gzip</code></td>\n</tr>\n<tr>\n<td><strong>Advantages</strong></td>\n<td>Cross-platformSizeEncoding and decoding costsStrict schemaSupports concatenation and theoretically streaming (only server-side behavior would need to change)</td>\n<td>Human-readableEasy to assemble, especially for minimalistic cases (no nesting required)Readable line by line (with the exception of type hints and docstrings)</td>\n</tr>\n<tr>\n<td><strong>Limitations</strong></td>\n<td>Not human-readable</td>\n<td>VerboseTypes and docstrings not integral part of the syntax, meaning little-to-nonexistent metric contract validationParsing cost</td>\n</tr>\n<tr>\n<td><strong>Supported metric primitives</strong></td>\n<td>CounterGaugeHistogramSummaryUntyped</td>\n<td>CounterGaugeHistogramSummaryUntyped</td>\n</tr>\n<tr>\n<td><strong>Compatibility</strong></td>\n<td>Version <code>0.0.3</code> protocol buffers are also valid version <code>0.0.4</code> protocol buffers.</td>\n<td>none</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"5-2-基于协议缓冲区格式\"><a href=\"#5-2-基于协议缓冲区格式\" class=\"headerlink\" title=\"5.2 基于协议缓冲区格式\"></a>5.2 基于协议缓冲区格式</h3><p>​    Reproducible sorting of the protocol buffer fields in repeated expositions is preferred but not required, i.e. do not sort if the computational cost is prohibitive.</p>\n<p>​    Each <code>MetricFamily</code> within the same exposition must have a unique name. Each <code>Metric</code> within the same <code>MetricFamily</code> must have a unique set of <code>LabelPair</code> fields. Otherwise, the ingestion behavior is undefined.</p>\n<h3 id=\"5-3-文本类型格式\"><a href=\"#5-3-文本类型格式\" class=\"headerlink\" title=\"5.3 文本类型格式\"></a>5.3 文本类型格式</h3><p>​    ＃打头的是注释行（除非＃之后的第一个标记是HELP或TYPE）。</p>\n<p>​    HELP行：可能包含任何UTF-8字符序列（在指标名称之后），但反斜杠和换行字符必须分别转义为<code>\\\\</code>和<code>\\ n</code>。对于相同的指标名称，只能有一条HELP行，一个指标只能有一个HELP行。</p>\n<p>TYPE行：TPYE后的第一个参数是指标名，第二个参数是数据类型（可以是counter, gauge, histogram, summary,  untyped）。相同的指标名称，只能有一个TYPE行。如果指标名称没有TYPE行，则该类型设置为无类型。</p>\n<p>格式：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">metric_name [</div><div class=\"line\">  &quot;&#123;&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#123; &quot;,&quot; label_name &quot;=&quot; `&quot;` label_value `&quot;` &#125; [ &quot;,&quot; ] &quot;&#125;&quot;</div><div class=\"line\">] value [ timestamp ]</div></pre></td></tr></table></figure>\n<p>label_value可以是任何UTF-8格式的内容，但反斜杠、双引号、换行符 必须转义成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">\\\\  \\&quot;  \\\\n</div></pre></td></tr></table></figure>\n<p>histogram（直方图）  summary（汇总）类型的特别格式：</p>\n<ol>\n<li>需要单独一行xxx_sum；</li>\n<li>需要单独一行xxx_count；</li>\n<li>Each quantile of a summary named x is given as a separate sample line with the same name x and a label {quantile=”y”}；</li>\n<li>A histogram must have a bucket with {le=”+Inf”}. Its value must be identical to the value of x_count；</li>\n<li>histogram类型必须要有{le=”+Inf”}，并且值要和xxx_count一致；</li>\n</ol>\n<h3 id=\"5-4-文本类型格式举例\"><a href=\"#5-4-文本类型格式举例\" class=\"headerlink\" title=\"5.4 文本类型格式举例\"></a>5.4 文本类型格式举例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div></pre></td><td class=\"code\"><pre><div class=\"line\"># HELP http_requests_total The total number of HTTP requests.</div><div class=\"line\"># TYPE http_requests_total counter</div><div class=\"line\">http_requests_total&#123;method=&quot;post&quot;,code=&quot;200&quot;&#125; 1027 1395066363000</div><div class=\"line\">http_requests_total&#123;method=&quot;post&quot;,code=&quot;400&quot;&#125;    3 1395066363000</div><div class=\"line\"></div><div class=\"line\"># Escaping in label values:</div><div class=\"line\">msdos_file_access_time_seconds&#123;path=&quot;C:\\\\DIR\\\\FILE.TXT&quot;,error=&quot;Cannot find file:\\n\\&quot;FILE.TXT\\&quot;&quot;&#125; 1.458255915e9</div><div class=\"line\"></div><div class=\"line\"># Minimalistic line:</div><div class=\"line\">metric_without_timestamp_and_labels 12.47</div><div class=\"line\"></div><div class=\"line\"># A weird metric from before the epoch:</div><div class=\"line\">something_weird&#123;problem=&quot;division by zero&quot;&#125; +Inf -3982045</div><div class=\"line\"></div><div class=\"line\"># A histogram, which has a pretty complex representation in the text format:</div><div class=\"line\"># HELP http_request_duration_seconds A histogram of the request duration.</div><div class=\"line\"># TYPE http_request_duration_seconds histogram</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.05&quot;&#125; 24054</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.1&quot;&#125; 33444</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.2&quot;&#125; 100392</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;0.5&quot;&#125; 129389</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;1&quot;&#125; 133988</div><div class=\"line\">http_request_duration_seconds_bucket&#123;le=&quot;+Inf&quot;&#125; 144320</div><div class=\"line\">http_request_duration_seconds_sum 53423</div><div class=\"line\">http_request_duration_seconds_count 144320</div><div class=\"line\"></div><div class=\"line\"># Finally a summary, which has a complex representation, too:</div><div class=\"line\"># HELP rpc_duration_seconds A summary of the RPC duration in seconds.</div><div class=\"line\"># TYPE rpc_duration_seconds summary</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.01&quot;&#125; 3102</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.05&quot;&#125; 3272</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 4773</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.9&quot;&#125; 9001</div><div class=\"line\">rpc_duration_seconds&#123;quantile=&quot;0.99&quot;&#125; 76656</div><div class=\"line\">rpc_duration_seconds_sum 1.7560473e+07</div><div class=\"line\">rpc_duration_seconds_count 2693</div></pre></td></tr></table></figure>\n<h2 id=\"6-导出器exporter\"><a href=\"#6-导出器exporter\" class=\"headerlink\" title=\"6 导出器exporter\"></a>6 导出器exporter</h2><h3 id=\"6-1-概述\"><a href=\"#6-1-概述\" class=\"headerlink\" title=\"6.1 概述\"></a>6.1 概述</h3><p>​    指标名，一般为导出程序名称作为前缀，例如， haproxy_up；</p>\n<p>​    度量标准必须使用基本单位（例如秒，字节），并保留将其转换为更具可读性的图形工具；</p>\n<pre><code>指标有效字符：`[a-zA-Z0-9:_]` ，其他任何字符都要用下划线_代替；\n</code></pre><p>​    指标后缀<code>_sum</code>, <code>_count</code>, <code>_bucket</code> and <code>_total</code> 只可用在Summaries、 Histograms 、 Counters</p>\n<h2 id=\"7-告警alertmanager程序\"><a href=\"#7-告警alertmanager程序\" class=\"headerlink\" title=\"7 告警alertmanager程序\"></a>7 告警alertmanager程序</h2><p>​    概述：</p>\n<p>​        promethues：根据配置文件prometheus.yml的rule_files告警规则，将告警信息存到promethues的磁盘，供promethues的前台页面查看；根据配置文件prometheus.yml的alerting（配置altermanager进程的ip 端口信息），将告警信息发送altermanager进程上。</p>\n<p>​        altermanager：接收promethues发来的告警信息，存在磁盘中供altermanager进程的前台查看；同时根据altermanager的告警配置文件simple.yml发送邮件等提醒。</p>\n<h3 id=\"7-1-promethues告警配置举例\"><a href=\"#7-1-promethues告警配置举例\" class=\"headerlink\" title=\"7.1 promethues告警配置举例\"></a>7.1 promethues告警配置举例</h3><p><img src=\"/img/promethues-alarm.png\" alt=\"\"></p>\n<h3 id=\"7-2-promethues告警规则配置文件举例\"><a href=\"#7-2-promethues告警规则配置文件举例\" class=\"headerlink\" title=\"7.2 promethues告警规则配置文件举例\"></a>7.2 promethues告警规则配置文件举例</h3><p><img src=\"/img/rule_file.png\" alt=\"\"></p>\n<p>alert：自定义的告警含义简写</p>\n<p>expor：告警条件，如上图的node_forks为具体mertics里的指标</p>\n<p>for：周期</p>\n<p>labels：severity，在alertmanager前台页面可以根据severity条件来查询告警信息</p>\n<p>annotations：summary写些较详细的告警信息</p>\n<h3 id=\"7-3-alertmanager告警发送邮件提示\"><a href=\"#7-3-alertmanager告警发送邮件提示\" class=\"headerlink\" title=\"7.3 alertmanager告警发送邮件提示\"></a>7.3 alertmanager告警发送邮件提示</h3><p><img src=\"/img/email_1.png\" alt=\"\"></p>\n<p><img src=\"/img/email_2.png\" alt=\"\"></p>\n<h3 id=\"7-4-启动alertmanager\"><a href=\"#7-4-启动alertmanager\" class=\"headerlink\" title=\"7.4 启动alertmanager\"></a>7.4 启动alertmanager</h3><p> nohup ./alertmanager –config.file=simple.yml &amp;</p>\n<p>alertmanager前台：<a href=\"http://192.168.7.176:9093/\" target=\"_blank\" rel=\"external\">http://192.168.7.176:9093/</a></p>\n<h3 id=\"7-5通过其他方式告警\"><a href=\"#7-5通过其他方式告警\" class=\"headerlink\" title=\"7.5通过其他方式告警\"></a>7.5通过其他方式告警</h3><h4 id=\"hipchat-config：\"><a href=\"#hipchat-config：\" class=\"headerlink\" title=\"hipchat_config：\"></a>hipchat_config：</h4><p>​    是一款能够在苹果mac平台上运行的社交聊天软件，HipChat的功能和QQ相似，集聊天、视频、语音等功能于一身，不同之处在于HipChat界面更加的简洁、操作更加的流畅。</p>\n<h4 id=\"pagerduty-config：\"><a href=\"#pagerduty-config：\" class=\"headerlink\" title=\"pagerduty_config：\"></a>pagerduty_config：</h4><p>​    是一款能够在服务器出问题时发送提醒的软件。在发生问题时，提醒的方式包括屏幕显示、电话呼叫、短信通知、电邮通知等，而且在无人应答时还会自动将提醒级别提高。PagerDuty 不是免费的。</p>\n<h4 id=\"pushover-config：\"><a href=\"#pushover-config：\" class=\"headerlink\" title=\"pushover_config：\"></a>pushover_config：</h4><p>​    是一款网络通知推送服务，类似ifttt或脚本服务，你可以将需要推送的服务设置好后，遇到情况将把通知自动推送到你的<a href=\"http://www.onlinedown.net/soft/222292.htm\" target=\"_blank\" rel=\"external\">安卓手机</a>。</p>\n<h4 id=\"slack-config：\"><a href=\"#slack-config：\" class=\"headerlink\" title=\"slack_config：\"></a>slack_config：</h4><p>​    slack是聊天群组 + 大规模工具集成 + 文件整合 + 统一搜索。截至2014年底，Slack 已经整合了电子邮件、短信、<a href=\"https://baike.baidu.com/item/Google\" target=\"_blank\" rel=\"external\">Google</a> Drives、<a href=\"https://baike.baidu.com/item/Twitter\" target=\"_blank\" rel=\"external\">Twitter</a>、Trello、Asana、<a href=\"https://baike.baidu.com/item/GitHub\" target=\"_blank\" rel=\"external\">GitHub</a> 等 65 种工具和服务，可以把各种碎片化的企业沟通和协作集中到一起。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Whether or not to notify about resolved alerts.</div><div class=\"line\">[ send_resolved: &lt;boolean&gt; | default = false ]</div><div class=\"line\"></div><div class=\"line\"># The Slack webhook URL.</div><div class=\"line\">[ api_url: &lt;secret&gt; | default = global.slack_api_url ]</div><div class=\"line\"></div><div class=\"line\"># The channel or user to send notifications to.</div><div class=\"line\">channel: &lt;tmpl_string&gt;</div><div class=\"line\"></div><div class=\"line\"># API request data as defined by the Slack webhook API.</div><div class=\"line\">[ color: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;danger&#123;&#123; else &#125;&#125;good&#123;&#123; end &#125;&#125;&apos; ]</div><div class=\"line\">[ username: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.username&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ title: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.title&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ title_link: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.titlelink&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ icon_emoji: &lt;tmpl_string&gt; ]</div><div class=\"line\">[ icon_url: &lt;tmpl_string&gt; ]</div><div class=\"line\">[ pretext: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.pretext&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ text: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.text&quot; . &#125;&#125;&apos; ]</div><div class=\"line\">[ fallback: &lt;tmpl_string&gt; | default = &apos;&#123;&#123; template &quot;slack.default.fallback&quot; . &#125;&#125;&apos; ]</div><div class=\"line\"></div><div class=\"line\"># The HTTP client&apos;s configuration.</div><div class=\"line\">[ http_config: &lt;http_config&gt; | default = global.http_config ]</div></pre></td></tr></table></figure>\n<h4 id=\"opsgenie-config-：\"><a href=\"#opsgenie-config-：\" class=\"headerlink\" title=\"opsgenie_config ：\"></a>opsgenie_config ：</h4><p>​    集成电话短信邮件等等</p>\n<h4 id=\"victorops-config：\"><a href=\"#victorops-config：\" class=\"headerlink\" title=\"victorops_config：\"></a>victorops_config：</h4><p>​    聊天应用</p>\n<h4 id=\"http-config：\"><a href=\"#http-config：\" class=\"headerlink\" title=\"http_config：\"></a>http_config：</h4><p>​    A <code>http_config</code> allows configuring the HTTP client that the receiver uses to communicate with HTTP-based API services.</p>\n<h2 id=\"8-问题笔记\"><a href=\"#8-问题笔记\" class=\"headerlink\" title=\"8 问题笔记\"></a>8 问题笔记</h2><h3 id=\"8-1已解决\"><a href=\"#8-1已解决\" class=\"headerlink\" title=\"8.1已解决\"></a>8.1已解决</h3><ol>\n<li>prometheus浏览器查询不到exporter指标数据，但是浏览器exporter的mertic有指标数据。原因是时间不同步</li>\n</ol>\n<h3 id=\"8-2-未解决\"><a href=\"#8-2-未解决\" class=\"headerlink\" title=\"8.2 未解决\"></a>8.2 未解决</h3>"},{"title":"Python编程环境搭建","date":"2016-08-19T14:13:30.000Z","_content":"\n# 简介  #\n假如新建了一台CentOs虚拟机，作为纯净的操作系统，我们需要搭建基本的开发环境。CentOs6.x一般都是java1.5版本，python2.6，并且很多开发工具都是没有默认安装的，比如gcc。下面重点介绍Python环境的搭建，主要涉及Python升级，pip安装，virtualenv安装。\n# yum #\nyum 源更新，可选操作，可替换国内的yum源。\nyum groupinstall 。必选操作，编译python需要编译工具。还有一些必要的库文件需要安装，例如openssl,zlib,这些都需要额外安装。pip要安装python2.7版本，因此需要zlib需要更新到最新版本1.2.8，而CentOs默认是1.2.3。否则会报错，错误信息后面提示。\n```\n[root@jinqiu opt]# yum -y update\n[root@jinqiu opt]# yum groupinstall \"Development tools\"\n[root@jinqiu opt]# yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n```\n顺便简单提下，快速免验证安装jdk\n```\n1. wget --no-check-certificate --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm  \n2. rpm -ivh jdk-8u131-linux-x64.rpm\n```\n# python #\n保存2.6版本的python\n下载2.7版本的python源码文件，解压，然后配置，编译，安装\n```\n[root@jinqiu~]$ cd /opt\n[root@jinqiuopt]$ sudo wget --no-check-certificate https://www.python.org/ftp/python/2.7.6/Python-2.7.6.tar.xz\n[root@jinqiuopt]$ sudo tar xf Python-2.7.6.tar.xz \n[root@jinqiuopt]$ cd Python-2.7.6\n[root@jinqiuPython-2.7.6]$ sudo ./configure --prefix=/usr/local\n[root@jinqiuPython-2.7.6]$ sudo make && sudo make altinstall\n```\n<!-- more -->\n\n创建软链接到2.7版本的python\n修改yum文件，由于yum只支持2.6版本的python，因此需要将/usr/bin/yum中的默认python解释器修改为2.6版本。\n```\n[root@jinqiu opt]# mv /usr/bin/python /usr/bin/python2.6\n[root@jinqiu opt]# ln -s /usr/bin/python2.7  /usr/bin/python\n```\n\n从一开始，如果要做一些实际Python开发，你一定会用到一些第三方包。\n在Linux系统上至少有3种安装第三方包的方法。\n* 使用系统自带的包管理系统(deb, rpm, 等)\n* 通过社区开发的各种工具，例如 pip ， easy_install 等\n* 从源文件安装\n这三个方面，几乎完成同样的事情。即：安装依赖，编译代码（如果需要的话），将一个包含模块的包复制的标准软件包搜索位置。\n\n# 安装pip #\n```\n[root@jinqiu opt]# yum install python-pip\n[root@jinqiu opt]# pip install --upgrade pip\n```\n通过yum安装，可能安装的pip版本比较低。因此也可以通过网络上最新的pip源进行安装\n```\ncurl https://raw.githubusercontent.com/pypa/pip/master/contrib/get-pip.py | python2.7 -\n```\npip用法这里不再赘述，man pip 即可。\n\n# virtualenv #\n安装virtualenv，virtualenv作为python环境的隔离器，可以保证在这个环境下安装的第三方python库，都是在这个环境下的，而不会安装到系统路径上面去。\n我们需要处理的基本问题是包的依赖、版本和间接权限问题。想象一下，你有两个应用，一个应用需要libfoo的版本1，而另一应用需要版本2。如何才能同时使用这些应用程序？如果您安装到的/usr/lib/python2.7/site-packages（或任何平台的标准位置）的一切，在这种情况下，您可能会不小心升级不应该升级的应用程序。\n```\nsudo pip install virtualenv\nmkdir my_project_venv\nvirtualenv --distribute my_project_venv\n```\n** The output will something like:**\nNew python executable in my_project_venv/bin/python\nInstalling distribute.............................................done.\nInstalling pip.....................done.\n\n这里只列出了将被讨论的目录和文件\n```\n|-- bin\n|   |-- activate  # <-- 这个virtualenv的激活文件\n|   |-- pip       # <-- 这个virtualenv的独立pip\n|   |-- python    # <-- python解释器的一个副本\n|-- lib\n|-- python2.7 # <-- 所有的新包会被存在这\n```\n通过下面的命令激活这个virtualenv：\n```\ncd my_project_venv\nsource bin/activate\n```\n执行完毕后，提示可能是这个样子的：\n```\n(my_project_venv)$ # the virtualenv name prepended to the prompt\n通过 deactivate 命令离开virtualenv环境\n(my_project_venv)$ deactivate\n```\n注意：一定要先进行yum步骤的操作，安装必要的openssl库和zlib库，否则在编译之后的python2.7，会有问题。例如pip2.7会报错，zlib异常。\n\n# 异常处理：\npythonImportError: No module named zlib2.7，报错如下：\nTraceback (most recent call last):\nFile \"/usr/local/bin/pip\", line 9, in <module>\n   load_entry_point('pip==1.4.1', 'console_scripts', 'pip')()\nFile \"build/bdist.linux-x86_64/egg/pkg_resources.py\", line 378, in load_entry_point\nFile \"build/bdist.linux-x86_64/egg/pkg_resources.py\", line 2566, in load_entry_point\nFile \"build/bdist.linux-x86_64/egg/pkg_resources.py\", line 2260, in load\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/__init__.py\", line 10, in <module>\n   from pip.util import get_installed_distributions, get_prog\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/util.py\", line 17, in <module>\n   from pip.vendor.distlib import version\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/version.py\", line 13, in <module>\n   from .compat import string_types\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/compat.py\", line 31, in <module>\n   from urllib2 import (Request, urlopen, URLError, HTTPError,\nImportError: cannot import name HTTPSHandle\n类似的错误还有：\nImportError: No module named zlib\nTraceback (most recent call last):\n  File \"/usr/bin/pip\", line 5, in <module>\n    from pkg_resources import load_entry_point\nImportError: No module named pkg_resources\n都是因为前面最早没有对系统进行升级，要进行Yum install openssl 和zlib 的安装升级。然后再重新安装python2.7，这样高版本的python 才不会有问题。\n","source":"_posts/python-build.md","raw":"---\ntitle: Python编程环境搭建\ndate: 2016-08-19 22:13:30\ntags: Python\ncategories: 技术\n---\n\n# 简介  #\n假如新建了一台CentOs虚拟机，作为纯净的操作系统，我们需要搭建基本的开发环境。CentOs6.x一般都是java1.5版本，python2.6，并且很多开发工具都是没有默认安装的，比如gcc。下面重点介绍Python环境的搭建，主要涉及Python升级，pip安装，virtualenv安装。\n# yum #\nyum 源更新，可选操作，可替换国内的yum源。\nyum groupinstall 。必选操作，编译python需要编译工具。还有一些必要的库文件需要安装，例如openssl,zlib,这些都需要额外安装。pip要安装python2.7版本，因此需要zlib需要更新到最新版本1.2.8，而CentOs默认是1.2.3。否则会报错，错误信息后面提示。\n```\n[root@jinqiu opt]# yum -y update\n[root@jinqiu opt]# yum groupinstall \"Development tools\"\n[root@jinqiu opt]# yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel\n```\n顺便简单提下，快速免验证安装jdk\n```\n1. wget --no-check-certificate --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm  \n2. rpm -ivh jdk-8u131-linux-x64.rpm\n```\n# python #\n保存2.6版本的python\n下载2.7版本的python源码文件，解压，然后配置，编译，安装\n```\n[root@jinqiu~]$ cd /opt\n[root@jinqiuopt]$ sudo wget --no-check-certificate https://www.python.org/ftp/python/2.7.6/Python-2.7.6.tar.xz\n[root@jinqiuopt]$ sudo tar xf Python-2.7.6.tar.xz \n[root@jinqiuopt]$ cd Python-2.7.6\n[root@jinqiuPython-2.7.6]$ sudo ./configure --prefix=/usr/local\n[root@jinqiuPython-2.7.6]$ sudo make && sudo make altinstall\n```\n<!-- more -->\n\n创建软链接到2.7版本的python\n修改yum文件，由于yum只支持2.6版本的python，因此需要将/usr/bin/yum中的默认python解释器修改为2.6版本。\n```\n[root@jinqiu opt]# mv /usr/bin/python /usr/bin/python2.6\n[root@jinqiu opt]# ln -s /usr/bin/python2.7  /usr/bin/python\n```\n\n从一开始，如果要做一些实际Python开发，你一定会用到一些第三方包。\n在Linux系统上至少有3种安装第三方包的方法。\n* 使用系统自带的包管理系统(deb, rpm, 等)\n* 通过社区开发的各种工具，例如 pip ， easy_install 等\n* 从源文件安装\n这三个方面，几乎完成同样的事情。即：安装依赖，编译代码（如果需要的话），将一个包含模块的包复制的标准软件包搜索位置。\n\n# 安装pip #\n```\n[root@jinqiu opt]# yum install python-pip\n[root@jinqiu opt]# pip install --upgrade pip\n```\n通过yum安装，可能安装的pip版本比较低。因此也可以通过网络上最新的pip源进行安装\n```\ncurl https://raw.githubusercontent.com/pypa/pip/master/contrib/get-pip.py | python2.7 -\n```\npip用法这里不再赘述，man pip 即可。\n\n# virtualenv #\n安装virtualenv，virtualenv作为python环境的隔离器，可以保证在这个环境下安装的第三方python库，都是在这个环境下的，而不会安装到系统路径上面去。\n我们需要处理的基本问题是包的依赖、版本和间接权限问题。想象一下，你有两个应用，一个应用需要libfoo的版本1，而另一应用需要版本2。如何才能同时使用这些应用程序？如果您安装到的/usr/lib/python2.7/site-packages（或任何平台的标准位置）的一切，在这种情况下，您可能会不小心升级不应该升级的应用程序。\n```\nsudo pip install virtualenv\nmkdir my_project_venv\nvirtualenv --distribute my_project_venv\n```\n** The output will something like:**\nNew python executable in my_project_venv/bin/python\nInstalling distribute.............................................done.\nInstalling pip.....................done.\n\n这里只列出了将被讨论的目录和文件\n```\n|-- bin\n|   |-- activate  # <-- 这个virtualenv的激活文件\n|   |-- pip       # <-- 这个virtualenv的独立pip\n|   |-- python    # <-- python解释器的一个副本\n|-- lib\n|-- python2.7 # <-- 所有的新包会被存在这\n```\n通过下面的命令激活这个virtualenv：\n```\ncd my_project_venv\nsource bin/activate\n```\n执行完毕后，提示可能是这个样子的：\n```\n(my_project_venv)$ # the virtualenv name prepended to the prompt\n通过 deactivate 命令离开virtualenv环境\n(my_project_venv)$ deactivate\n```\n注意：一定要先进行yum步骤的操作，安装必要的openssl库和zlib库，否则在编译之后的python2.7，会有问题。例如pip2.7会报错，zlib异常。\n\n# 异常处理：\npythonImportError: No module named zlib2.7，报错如下：\nTraceback (most recent call last):\nFile \"/usr/local/bin/pip\", line 9, in <module>\n   load_entry_point('pip==1.4.1', 'console_scripts', 'pip')()\nFile \"build/bdist.linux-x86_64/egg/pkg_resources.py\", line 378, in load_entry_point\nFile \"build/bdist.linux-x86_64/egg/pkg_resources.py\", line 2566, in load_entry_point\nFile \"build/bdist.linux-x86_64/egg/pkg_resources.py\", line 2260, in load\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/__init__.py\", line 10, in <module>\n   from pip.util import get_installed_distributions, get_prog\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/util.py\", line 17, in <module>\n   from pip.vendor.distlib import version\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/version.py\", line 13, in <module>\n   from .compat import string_types\nFile \"/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/compat.py\", line 31, in <module>\n   from urllib2 import (Request, urlopen, URLError, HTTPError,\nImportError: cannot import name HTTPSHandle\n类似的错误还有：\nImportError: No module named zlib\nTraceback (most recent call last):\n  File \"/usr/bin/pip\", line 5, in <module>\n    from pkg_resources import load_entry_point\nImportError: No module named pkg_resources\n都是因为前面最早没有对系统进行升级，要进行Yum install openssl 和zlib 的安装升级。然后再重新安装python2.7，这样高版本的python 才不会有问题。\n","slug":"python-build","published":1,"updated":"2018-04-27T04:11:03.367Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczp70014e4rwpju9ryqs","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>假如新建了一台CentOs虚拟机，作为纯净的操作系统，我们需要搭建基本的开发环境。CentOs6.x一般都是java1.5版本，python2.6，并且很多开发工具都是没有默认安装的，比如gcc。下面重点介绍Python环境的搭建，主要涉及Python升级，pip安装，virtualenv安装。</p>\n<h1 id=\"yum\"><a href=\"#yum\" class=\"headerlink\" title=\"yum\"></a>yum</h1><p>yum 源更新，可选操作，可替换国内的yum源。<br>yum groupinstall 。必选操作，编译python需要编译工具。还有一些必要的库文件需要安装，例如openssl,zlib,这些都需要额外安装。pip要安装python2.7版本，因此需要zlib需要更新到最新版本1.2.8，而CentOs默认是1.2.3。否则会报错，错误信息后面提示。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu opt]# yum -y update</div><div class=\"line\">[root@jinqiu opt]# yum groupinstall &quot;Development tools&quot;</div><div class=\"line\">[root@jinqiu opt]# yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div></pre></td></tr></table></figure></p>\n<p>顺便简单提下，快速免验证安装jdk<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm  </div><div class=\"line\">2. rpm -ivh jdk-8u131-linux-x64.rpm</div></pre></td></tr></table></figure></p>\n<h1 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h1><p>保存2.6版本的python<br>下载2.7版本的python源码文件，解压，然后配置，编译，安装<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu~]$ cd /opt</div><div class=\"line\">[root@jinqiuopt]$ sudo wget --no-check-certificate https://www.python.org/ftp/python/2.7.6/Python-2.7.6.tar.xz</div><div class=\"line\">[root@jinqiuopt]$ sudo tar xf Python-2.7.6.tar.xz </div><div class=\"line\">[root@jinqiuopt]$ cd Python-2.7.6</div><div class=\"line\">[root@jinqiuPython-2.7.6]$ sudo ./configure --prefix=/usr/local</div><div class=\"line\">[root@jinqiuPython-2.7.6]$ sudo make &amp;&amp; sudo make altinstall</div></pre></td></tr></table></figure></p>\n<a id=\"more\"></a>\n<p>创建软链接到2.7版本的python<br>修改yum文件，由于yum只支持2.6版本的python，因此需要将/usr/bin/yum中的默认python解释器修改为2.6版本。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu opt]# mv /usr/bin/python /usr/bin/python2.6</div><div class=\"line\">[root@jinqiu opt]# ln -s /usr/bin/python2.7  /usr/bin/python</div></pre></td></tr></table></figure></p>\n<p>从一开始，如果要做一些实际Python开发，你一定会用到一些第三方包。<br>在Linux系统上至少有3种安装第三方包的方法。</p>\n<ul>\n<li>使用系统自带的包管理系统(deb, rpm, 等)</li>\n<li>通过社区开发的各种工具，例如 pip ， easy_install 等</li>\n<li>从源文件安装<br>这三个方面，几乎完成同样的事情。即：安装依赖，编译代码（如果需要的话），将一个包含模块的包复制的标准软件包搜索位置。</li>\n</ul>\n<h1 id=\"安装pip\"><a href=\"#安装pip\" class=\"headerlink\" title=\"安装pip\"></a>安装pip</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu opt]# yum install python-pip</div><div class=\"line\">[root@jinqiu opt]# pip install --upgrade pip</div></pre></td></tr></table></figure>\n<p>通过yum安装，可能安装的pip版本比较低。因此也可以通过网络上最新的pip源进行安装<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl https://raw.githubusercontent.com/pypa/pip/master/contrib/get-pip.py | python2.7 -</div></pre></td></tr></table></figure></p>\n<p>pip用法这里不再赘述，man pip 即可。</p>\n<h1 id=\"virtualenv\"><a href=\"#virtualenv\" class=\"headerlink\" title=\"virtualenv\"></a>virtualenv</h1><p>安装virtualenv，virtualenv作为python环境的隔离器，可以保证在这个环境下安装的第三方python库，都是在这个环境下的，而不会安装到系统路径上面去。<br>我们需要处理的基本问题是包的依赖、版本和间接权限问题。想象一下，你有两个应用，一个应用需要libfoo的版本1，而另一应用需要版本2。如何才能同时使用这些应用程序？如果您安装到的/usr/lib/python2.7/site-packages（或任何平台的标准位置）的一切，在这种情况下，您可能会不小心升级不应该升级的应用程序。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo pip install virtualenv</div><div class=\"line\">mkdir my_project_venv</div><div class=\"line\">virtualenv --distribute my_project_venv</div></pre></td></tr></table></figure></p>\n<p><strong> The output will something like:</strong><br>New python executable in my_project_venv/bin/python<br>Installing distribute………………………………………done.<br>Installing pip…………………done.</p>\n<p>这里只列出了将被讨论的目录和文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">|-- bin</div><div class=\"line\">|   |-- activate  # &lt;-- 这个virtualenv的激活文件</div><div class=\"line\">|   |-- pip       # &lt;-- 这个virtualenv的独立pip</div><div class=\"line\">|   |-- python    # &lt;-- python解释器的一个副本</div><div class=\"line\">|-- lib</div><div class=\"line\">|-- python2.7 # &lt;-- 所有的新包会被存在这</div></pre></td></tr></table></figure></p>\n<p>通过下面的命令激活这个virtualenv：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd my_project_venv</div><div class=\"line\">source bin/activate</div></pre></td></tr></table></figure></p>\n<p>执行完毕后，提示可能是这个样子的：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">(my_project_venv)$ # the virtualenv name prepended to the prompt</div><div class=\"line\">通过 deactivate 命令离开virtualenv环境</div><div class=\"line\">(my_project_venv)$ deactivate</div></pre></td></tr></table></figure></p>\n<p>注意：一定要先进行yum步骤的操作，安装必要的openssl库和zlib库，否则在编译之后的python2.7，会有问题。例如pip2.7会报错，zlib异常。</p>\n<h1 id=\"异常处理：\"><a href=\"#异常处理：\" class=\"headerlink\" title=\"异常处理：\"></a>异常处理：</h1><p>pythonImportError: No module named zlib2.7，报错如下：<br>Traceback (most recent call last):<br>File “/usr/local/bin/pip”, line 9, in <module><br>   load_entry_point(‘pip==1.4.1’, ‘console_scripts’, ‘pip’)()<br>File “build/bdist.linux-x86_64/egg/pkg_resources.py”, line 378, in load_entry_point<br>File “build/bdist.linux-x86_64/egg/pkg_resources.py”, line 2566, in load_entry_point<br>File “build/bdist.linux-x86_64/egg/pkg_resources.py”, line 2260, in load<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/<strong>init</strong>.py”, line 10, in <module><br>   from pip.util import get_installed_distributions, get_prog<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/util.py”, line 17, in <module><br>   from pip.vendor.distlib import version<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/version.py”, line 13, in <module><br>   from .compat import string_types<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/compat.py”, line 31, in <module><br>   from urllib2 import (Request, urlopen, URLError, HTTPError,<br>ImportError: cannot import name HTTPSHandle<br>类似的错误还有：<br>ImportError: No module named zlib<br>Traceback (most recent call last):<br>  File “/usr/bin/pip”, line 5, in <module><br>    from pkg_resources import load_entry_point<br>ImportError: No module named pkg_resources<br>都是因为前面最早没有对系统进行升级，要进行Yum install openssl 和zlib 的安装升级。然后再重新安装python2.7，这样高版本的python 才不会有问题。</module></module></module></module></module></module></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>假如新建了一台CentOs虚拟机，作为纯净的操作系统，我们需要搭建基本的开发环境。CentOs6.x一般都是java1.5版本，python2.6，并且很多开发工具都是没有默认安装的，比如gcc。下面重点介绍Python环境的搭建，主要涉及Python升级，pip安装，virtualenv安装。</p>\n<h1 id=\"yum\"><a href=\"#yum\" class=\"headerlink\" title=\"yum\"></a>yum</h1><p>yum 源更新，可选操作，可替换国内的yum源。<br>yum groupinstall 。必选操作，编译python需要编译工具。还有一些必要的库文件需要安装，例如openssl,zlib,这些都需要额外安装。pip要安装python2.7版本，因此需要zlib需要更新到最新版本1.2.8，而CentOs默认是1.2.3。否则会报错，错误信息后面提示。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu opt]# yum -y update</div><div class=\"line\">[root@jinqiu opt]# yum groupinstall &quot;Development tools&quot;</div><div class=\"line\">[root@jinqiu opt]# yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel</div></pre></td></tr></table></figure></p>\n<p>顺便简单提下，快速免验证安装jdk<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">1. wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm  </div><div class=\"line\">2. rpm -ivh jdk-8u131-linux-x64.rpm</div></pre></td></tr></table></figure></p>\n<h1 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h1><p>保存2.6版本的python<br>下载2.7版本的python源码文件，解压，然后配置，编译，安装<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu~]$ cd /opt</div><div class=\"line\">[root@jinqiuopt]$ sudo wget --no-check-certificate https://www.python.org/ftp/python/2.7.6/Python-2.7.6.tar.xz</div><div class=\"line\">[root@jinqiuopt]$ sudo tar xf Python-2.7.6.tar.xz </div><div class=\"line\">[root@jinqiuopt]$ cd Python-2.7.6</div><div class=\"line\">[root@jinqiuPython-2.7.6]$ sudo ./configure --prefix=/usr/local</div><div class=\"line\">[root@jinqiuPython-2.7.6]$ sudo make &amp;&amp; sudo make altinstall</div></pre></td></tr></table></figure></p>","more":"<p>创建软链接到2.7版本的python<br>修改yum文件，由于yum只支持2.6版本的python，因此需要将/usr/bin/yum中的默认python解释器修改为2.6版本。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu opt]# mv /usr/bin/python /usr/bin/python2.6</div><div class=\"line\">[root@jinqiu opt]# ln -s /usr/bin/python2.7  /usr/bin/python</div></pre></td></tr></table></figure></p>\n<p>从一开始，如果要做一些实际Python开发，你一定会用到一些第三方包。<br>在Linux系统上至少有3种安装第三方包的方法。</p>\n<ul>\n<li>使用系统自带的包管理系统(deb, rpm, 等)</li>\n<li>通过社区开发的各种工具，例如 pip ， easy_install 等</li>\n<li>从源文件安装<br>这三个方面，几乎完成同样的事情。即：安装依赖，编译代码（如果需要的话），将一个包含模块的包复制的标准软件包搜索位置。</li>\n</ul>\n<h1 id=\"安装pip\"><a href=\"#安装pip\" class=\"headerlink\" title=\"安装pip\"></a>安装pip</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@jinqiu opt]# yum install python-pip</div><div class=\"line\">[root@jinqiu opt]# pip install --upgrade pip</div></pre></td></tr></table></figure>\n<p>通过yum安装，可能安装的pip版本比较低。因此也可以通过网络上最新的pip源进行安装<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl https://raw.githubusercontent.com/pypa/pip/master/contrib/get-pip.py | python2.7 -</div></pre></td></tr></table></figure></p>\n<p>pip用法这里不再赘述，man pip 即可。</p>\n<h1 id=\"virtualenv\"><a href=\"#virtualenv\" class=\"headerlink\" title=\"virtualenv\"></a>virtualenv</h1><p>安装virtualenv，virtualenv作为python环境的隔离器，可以保证在这个环境下安装的第三方python库，都是在这个环境下的，而不会安装到系统路径上面去。<br>我们需要处理的基本问题是包的依赖、版本和间接权限问题。想象一下，你有两个应用，一个应用需要libfoo的版本1，而另一应用需要版本2。如何才能同时使用这些应用程序？如果您安装到的/usr/lib/python2.7/site-packages（或任何平台的标准位置）的一切，在这种情况下，您可能会不小心升级不应该升级的应用程序。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">sudo pip install virtualenv</div><div class=\"line\">mkdir my_project_venv</div><div class=\"line\">virtualenv --distribute my_project_venv</div></pre></td></tr></table></figure></p>\n<p><strong> The output will something like:</strong><br>New python executable in my_project_venv/bin/python<br>Installing distribute………………………………………done.<br>Installing pip…………………done.</p>\n<p>这里只列出了将被讨论的目录和文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">|-- bin</div><div class=\"line\">|   |-- activate  # &lt;-- 这个virtualenv的激活文件</div><div class=\"line\">|   |-- pip       # &lt;-- 这个virtualenv的独立pip</div><div class=\"line\">|   |-- python    # &lt;-- python解释器的一个副本</div><div class=\"line\">|-- lib</div><div class=\"line\">|-- python2.7 # &lt;-- 所有的新包会被存在这</div></pre></td></tr></table></figure></p>\n<p>通过下面的命令激活这个virtualenv：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">cd my_project_venv</div><div class=\"line\">source bin/activate</div></pre></td></tr></table></figure></p>\n<p>执行完毕后，提示可能是这个样子的：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">(my_project_venv)$ # the virtualenv name prepended to the prompt</div><div class=\"line\">通过 deactivate 命令离开virtualenv环境</div><div class=\"line\">(my_project_venv)$ deactivate</div></pre></td></tr></table></figure></p>\n<p>注意：一定要先进行yum步骤的操作，安装必要的openssl库和zlib库，否则在编译之后的python2.7，会有问题。例如pip2.7会报错，zlib异常。</p>\n<h1 id=\"异常处理：\"><a href=\"#异常处理：\" class=\"headerlink\" title=\"异常处理：\"></a>异常处理：</h1><p>pythonImportError: No module named zlib2.7，报错如下：<br>Traceback (most recent call last):<br>File “/usr/local/bin/pip”, line 9, in <module><br>   load_entry_point(‘pip==1.4.1’, ‘console_scripts’, ‘pip’)()<br>File “build/bdist.linux-x86_64/egg/pkg_resources.py”, line 378, in load_entry_point<br>File “build/bdist.linux-x86_64/egg/pkg_resources.py”, line 2566, in load_entry_point<br>File “build/bdist.linux-x86_64/egg/pkg_resources.py”, line 2260, in load<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/<strong>init</strong>.py”, line 10, in <module><br>   from pip.util import get_installed_distributions, get_prog<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/util.py”, line 17, in <module><br>   from pip.vendor.distlib import version<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/version.py”, line 13, in <module><br>   from .compat import string_types<br>File “/usr/local/lib/python2.7/site-packages/pip-1.4.1-py2.7.egg/pip/vendor/distlib/compat.py”, line 31, in <module><br>   from urllib2 import (Request, urlopen, URLError, HTTPError,<br>ImportError: cannot import name HTTPSHandle<br>类似的错误还有：<br>ImportError: No module named zlib<br>Traceback (most recent call last):<br>  File “/usr/bin/pip”, line 5, in <module><br>    from pkg_resources import load_entry_point<br>ImportError: No module named pkg_resources<br>都是因为前面最早没有对系统进行升级，要进行Yum install openssl 和zlib 的安装升级。然后再重新安装python2.7，这样高版本的python 才不会有问题。</module></module></module></module></module></module></p>"},{"title":"TICK 监控体系","date":"2018-02-27T04:33:38.000Z","_content":"\n## 1.Tick安装部署\n\n### Tick简介\n\nTICK 是由 InfluxData 开发的一套运维工具栈，由 Telegraf, InfluxDB, Chronograf, Kapacitor 四个工具的首字母组成。\n这一套组件将收集数据和入库、数据库存储、展示、告警四者囊括了。\n\n![TICK框架图](/img/tick.png \"TICK\") \n\n<!-- more -->\n\nTelegraf\n\n是一个数据收集和入库的工具。提供了很多 input 和 output 插件，比如收集本地的 cpu、load、网络流量等数据，然后写入 InfluxDB 、Kafka或者OpenTSDB等。相当于ELK栈中的 logstash 功能。\n\nInfluxDB\n\nInfluxDB 是一个开源的GO语言为基础的数据库, 用来处理时间序列数据,提供了较高的可用性。与opentsdb类似，支持HTTP API方式，写入和读取数据。相当于ELK栈中的elasticsearch功能。\n\nChronograf\n\n从InfluxDB时间序列数据的数据可视化工具，负责从InfluxDB收集数据，并将数据图表以web的形式发布。它使用简单,包括模板和库可以快速构建实时数据的可视化仪表板，轻松地创建报警和自动化的规则。相当于ELK栈中的kibana功能。\n\nKapacitor\n\nKapacitor是InfluxDB的数据处理引擎，主要作用是时间序列数据处理、监视和警报。\n\n### TICK安装（DOCKER版）\n\n[官方安装介绍](https://portal.influxdata.com/downloads)\n\n本地安装版本分别是telegraf1.5,influxdb1.42,chronograf1.4,kapacitor1.4\n\n```\ndocker pull telegraf\ndocker pull influxdb\ndocker pull quay.io/influxdb/chronograf\ndocker pull kapacitor\n```\n\n\n\n### TICK配置与运行\n\n[TICK Docker file](https://github.com/influxdata/influxdata-docker)\n\n\n\n#### InfluxDB\n\n[How to run](https://github.com/docker-library/docs/blob/master/influxdb/README.md)\n\n参数介绍：\n\n- 8086 HTTP API port\n- 8083 Administrator interface port, if it is enabled\n- 2003 Graphite support, if it is enabled\n\n启动server 可修改默认配置文件等，详见[How to run]\n\n```bash\ndocker run --name influxdb -d -p 8086:8086 -p 8083:8083  -e INFLUXDB_ADMIN_ENABLED=true  -v /var/lib/influxdb:/var/lib/influxdb  influxdb\n```\n\n初始化数据库\n\n```bash\ndocker run --rm \\\n      -e INFLUXDB_DB=db0 -e INFLUXDB_ADMIN_ENABLED=true \\\n      -e INFLUXDB_ADMIN_USER=admin -e INFLUXDB_ADMIN_USER=admin \\\n      -e INFLUXDB_USER=telegraf -e INFLUXDB_USER_PASSWORD=telegraf \\\n      -v /var/lib/influxdb:/var/lib/influxdb \\\n      influxdb /init-influxdb.sh\n```\n\n启动client\n\n```bash\ndocker run --rm --link=influxdb -it influxdb influx -host influxdb\n```\n\n其他命令\n\n创建数据库\n\n```shell\ncurl -G http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE mydb\"\n```\n\n插入数据\n\n```shell\ncurl -XPOST \"http://localhost:8086/write?db=mydb\" \\\n-d 'cpu,host=server01,region=uswest load=42 1434055562000000000'\n\ncurl -XPOST \"http://localhost:8086/write?db=mydb\" \\\n-d 'cpu,host=server02,region=uswest load=78 1434055562000000000'\n\ncurl -XPOST \"http://localhost:8086/write?db=mydb\" \\\n-d 'cpu,host=server03,region=useast load=15.4 1434055562000000000'\n```\n\n查询数据\n\n```shell\ncurl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\\n--data-urlencode \"q=SELECT * FROM cpu WHERE host='server01' AND time < now() - 1d\"\n```\n\n分析数据\n\n```shell\ncurl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\\n--data-urlencode \"q=SELECT mean(load) FROM cpu WHERE region='uswest'\"\n```\n\n[InfluxDB概念介绍](https://docs.influxdata.com/influxdb/v1.4/concepts/key_concepts/#field-key)\n\n#### Telegraf\n\n[Telegraf Docker file](https://github.com/influxdata/influxdata-docker/blob/ae56003075c8f39b6c265294ca8235c2c5235cc6/telegraf/1.5/alpine/Dockerfile)\n[How to run](https://github.com/docker-library/docs/blob/master/telegraf/content.md)\n\n参数介绍：\n\n- 8125 StatsD\n- 8092 UDP\n- 8094 TCP\n\n```bash\ndocker run --name telegraf -d -p 8125:8125 -p 8092:8092 -p 8094:8094  -v ~/telegraf.conf:/etc/telegraf/telegraf.conf telegraf\n```\n\n#### Chronograf\n\nExposed Ports\n\n- 8888TCP -- Listen  endpoint\n\n```shell\ndocker run -d --name chronograf -p 8888:8888 -v /var/lib/chronograf:/var/lib/chronograf quay.io/influxdb/chronograf chronograf\n```\n\n\n\n#### Kapacitor\n\nExposed Ports\n\n- 9092 TCP -- HTTP API endpoint\n\n需要修改默认的kapacitor.conf url地址，默认是配置localhost，而容器进程肯定不是localhost.\n\n```shell\ndocker run -d --name kapacitor -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor \n```\n\n查看帮助\n\n```shell\ndocker exec  kapacitor kapacitor help\ndocker exec  kapacitor kapacitor list tasks \ndocker exec  kapacitor kapacitor show CPURule\n\n```\n\n常见问题：\n\n容器告警因为ip原因无法，注册到influxdb时，ip是容器id，如下，导致Influxdb 无法识别该地址，性能数据无法发送到kapacitor。因此临时解决方案是修改容器的hostname\n\n```\n> show SUBSCRIPTIONS\nname: telegraf\nretention_policy name                                           mode destinations\n---------------- ----                                           ---- ------------\nautogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]\n\nname: _internal\nretention_policy name                                           mode destinations\n---------------- ----                                           ---- ------------\nmonitor          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]\n\nname: chronograf\nretention_policy name                                           mode destinations\n---------------- ----                                           ---- ------------\nautogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]\n\n```\n\n\n\n```\n docker run -d --name kapacitor -e KAPACITOR_HOSTNAME=192.168.14.165 -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor\n```\n\n\n\n## 2.Telgraf重点介绍\n\nTelegraf是一个用Go编写的代理程序，用于收集，处理，汇总和编写度量标准。\n\nTelegraf是插件驱动，并有4个不同的插件的概念：\n\n1. [输入插件](https://github.com/influxdata/telegraf#input-plugins)从系统，服务或第三方API收集指标。\n2. [处理器插件](https://github.com/influxdata/telegraf#processor-plugins)转换，修饰和/或过滤度量标准\n3. [聚合器插件](https://github.com/influxdata/telegraf#aggregator-plugins)创建聚合度量（例如平均值，最小值，最大值，分位数等）\n4. [输出插件](https://github.com/influxdata/telegraf#output-plugins)将指标写入各个目标\n\nTelegraf 二进制文件包含对所有支持的采集对象的采集功能，只是可以通过配置选择性的开启。如果更新某个对象的采集指标，则需要重新编译整个二进制文件。\n\n\n\n### 测试数据/帮助命令\n\n~/telegraf.conf 测试用配置文件，可定义输入插件\n\n```shell\ndocker run -v ~/telegraf.conf:/etc/telegraf/telegraf.conf --rm telegraf telegraf --config /etc/telegraf/telegraf.conf  --test\n```\n\n```\ndocker run --rm telegraf telegraf --help\n```\n\n### 数据收集方式\n\npush 模式，由telegraf 根据input配置主动采集并发送到output配置的后端。一般是InfluxDB数据库。TICK并无服务端的概念，在TICK监控部署文档的架构图中可知。\n\n[input-output-plugins](https://github.com/influxdata/telegraf/blob/master/README.md)\n\n\n\n### InfluxDB Line Protocol 数据格式\n\nInfluxDB Line Protocol 格式\n\nTelegraf metrics, like InfluxDB [points](https://docs.influxdata.com/influxdb/v0.10/write_protocols/line/), are a combination of four basic parts:\n\n```shell\nmeasurement_name[,tag1=val1,...]  field1=val1,field2=val2,...\n```\n\n1. Measurement Name\n\n2. Tags\n\n3. Fields\n\n4. Timestamp\n\n   ​\n\n### 输入数据格式\n\n[telegraf有六种采集数据输入格式](https://docs.influxdata.com/telegraf/v1.5/concepts/data_formats_input/)\n\nTelegraf is able to parse the following input data formats into metrics:\n\n1. [InfluxDB Line Protocol](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#influx)\n2. [JSON](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#json)\n3. [Graphite](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite)\n4. [Value](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#value), ie: 45 or \"booyah\"\n5. [Nagios](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#nagios) (exec input only)\n6. [Collectd](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#collectd)\n\n默认是第一种：InfluxDB Line Protocol。Graphite、Nagios、Collected都是其他开源监控项目，其中Nagios是比较完整的监控系统，其格式只能用在exec输入插件中；Collected一般用作系统守护进程，采集系统统计信息，并且通过网络开放数据；Graphite则是另外一套监控系统，也是C-S模式。\n\n如果是配置成其他格式，那么采集回来的数据（受限于采集方可吐出的数据），将会被Telegraf  转换为其可识别的InfluxDB Line Protocol。\n\n\n\n### 输出数据格式\n\n[telegraf有三种采集数据输出格式](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md)\n\nTelegraf is able to serialize metrics into the following output data formats:\n\n1. [InfluxDB Line Protocol](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#influx)\n2. [JSON](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#json)\n3. [Graphite](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#graphite)\n\n一般而言，输出格式如果是其他格式，例如Json，那么输出的对象则一般为file类型。从实际应用中来看，即通过telegraf采集回数据，生成json文件，发送至其他系统进行处理。\n\n以下是采集结果示例\n\n```shell\n* Plugin: inputs.cpu, Collection 1\n* Plugin: inputs.cpu, Collection 2\n> cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000\n> cpu,cpu=cpu1,host=0336dcb23579 usage_user=0,usage_guest_nice=0,usage_steal=0,usage_guest=0,usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_softirq=0 1515338025000000000\n> cpu,cpu=cpu2,host=0336dcb23579 usage_idle=100,usage_nice=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_irq=0,usage_softirq=0,usage_guest_nice=0 1515338025000000000\n> cpu,host=0336dcb23579,cpu=cpu3 usage_softirq=0,usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0 1515338025000000000\n> cpu,cpu=cpu-total,host=0336dcb23579 usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000\n\n```\n\ncpu：measurements ，类似oracle的表名\n\ncpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；\n\nusage_guest_nice=0,usage_idle=100,usage_nice=0... : usage_guest_nice等为field，即被采集的指标字段。field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面\n\n1515338025000000000： time 时间戳\n\n\n\n### 数据过滤/聚合\n\nMeasurement Filtering\n\n![数据处理](/img/agg-pro.jpg)\n\nFilters can be configured per input, output, processor, or aggregator, see below for examples.\n\n- **namepass**: An array of glob pattern strings. Only points whose measurement name matches a pattern in this list are emitted.\n- **namedrop**: The inverse of `namepass`. If a match is found the point is discarded. This is tested on points after they have passed the `namepass` test.\n- **fieldpass**: An array of glob pattern strings. Only fields whose field key matches a pattern in this list are emitted. Not available for outputs.\n- **fielddrop**: The inverse of `fieldpass`. Fields with a field key matching one of the patterns will be discarded from the point. This is tested on points after they have passed the `fieldpass` test. Not available for outputs.\n- **tagpass**: A table mapping tag keys to arrays of glob pattern strings. Only points that contain a tag key in the table and a tag value matching one of its patterns is emitted.\n- **tagdrop**: The inverse of `tagpass`. If a match is found the point is discarded. This is tested on points after they have passed the `tagpass` test.\n- **taginclude**: An array of glob pattern strings. Only tags with a tag key matching one of the patterns are emitted. In contrast to `tagpass`, which will pass an entire point based on its tag, `taginclude` removes all non matching tags from the point. This filter can be used on both inputs & outputs, but it is *recommended* to be used on inputs, as it is more efficient to filter out tags at the ingestion point.\n- **tagexclude**: The inverse of `taginclude`. Tags with a tag key matching one of the patterns will be discarded from the point.\n\n输入数据示例\n\n```shell\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = false\n  fielddrop = [\"cpu_time\"]\n  # Don't collect CPU data for cpu6 & cpu7\n  [inputs.cpu.tagdrop]\n    cpu = [ \"cpu6\", \"cpu7\" ]\n\n[[inputs.disk]]\n  [inputs.disk.tagpass]\n    # tagpass conditions are OR, not AND.\n    # If the (filesystem is ext4 or xfs) OR (the path is /opt or /home)\n    # then the metric passes\n    fstype = [ \"ext4\", \"xfs\" ]\n    # Globs can also be used on the tag values\n    path = [ \"/opt\", \"/home*\" ]\n```\n\n输出数据示例\n\n与输入（采集）数据过滤类似，可定义多个输出源\n\n```shell\n[[outputs.influxdb]]\n  urls = [ \"http://localhost:8086\" ]\n  database = \"telegraf\"\n  # Drop all measurements that start with \"aerospike\"\n  namedrop = [\"aerospike*\"]\n\n[[outputs.influxdb]]\n  urls = [ \"http://localhost:8086\" ]\n  database = \"telegraf-aerospike-data\"\n  # Only accept aerospike data:\n  namepass = [\"aerospike*\"]\n\n[[outputs.influxdb]]\n  urls = [ \"http://localhost:8086\" ]\n  database = \"telegraf-cpu0-data\"\n  # Only store measurements where the tag \"cpu\" matches the value \"cpu0\"\n  [outputs.influxdb.tagpass]\n    cpu = [\"cpu0\"]\n```\n\nAggregator Plugins\n\n- [basicstats](https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/basicstats)\n- [minmax](https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/minmax)\n- [histogram](https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/histogram)\n\n### 部署方式\n\n客户端部署方式，可结合Ansible 进行部署，以及配置管理。官方说明并未看到。\n\n\n\n### 任务配置\n\n客户端配置文件配置 /etc/telegraf/telegraf.conf，可配置指标采集周期、过滤指标等。\n\n\n\n### 告警处理\n\n与Telegraf配合使用的告警处理程序是[kapacitor](https://github.com/influxdata/kapacitor) \n\nOpen source framework for processing, monitoring, and alerting on time series data。","source":"_posts/tick.md","raw":"---\ntitle: TICK 监控体系\ndate: 2018-02-27 12:33:38\ntags: \n - TICK\n - InfluxDB \n - Telegraf\n - Go\ncategories: 技术\n---\n\n## 1.Tick安装部署\n\n### Tick简介\n\nTICK 是由 InfluxData 开发的一套运维工具栈，由 Telegraf, InfluxDB, Chronograf, Kapacitor 四个工具的首字母组成。\n这一套组件将收集数据和入库、数据库存储、展示、告警四者囊括了。\n\n![TICK框架图](/img/tick.png \"TICK\") \n\n<!-- more -->\n\nTelegraf\n\n是一个数据收集和入库的工具。提供了很多 input 和 output 插件，比如收集本地的 cpu、load、网络流量等数据，然后写入 InfluxDB 、Kafka或者OpenTSDB等。相当于ELK栈中的 logstash 功能。\n\nInfluxDB\n\nInfluxDB 是一个开源的GO语言为基础的数据库, 用来处理时间序列数据,提供了较高的可用性。与opentsdb类似，支持HTTP API方式，写入和读取数据。相当于ELK栈中的elasticsearch功能。\n\nChronograf\n\n从InfluxDB时间序列数据的数据可视化工具，负责从InfluxDB收集数据，并将数据图表以web的形式发布。它使用简单,包括模板和库可以快速构建实时数据的可视化仪表板，轻松地创建报警和自动化的规则。相当于ELK栈中的kibana功能。\n\nKapacitor\n\nKapacitor是InfluxDB的数据处理引擎，主要作用是时间序列数据处理、监视和警报。\n\n### TICK安装（DOCKER版）\n\n[官方安装介绍](https://portal.influxdata.com/downloads)\n\n本地安装版本分别是telegraf1.5,influxdb1.42,chronograf1.4,kapacitor1.4\n\n```\ndocker pull telegraf\ndocker pull influxdb\ndocker pull quay.io/influxdb/chronograf\ndocker pull kapacitor\n```\n\n\n\n### TICK配置与运行\n\n[TICK Docker file](https://github.com/influxdata/influxdata-docker)\n\n\n\n#### InfluxDB\n\n[How to run](https://github.com/docker-library/docs/blob/master/influxdb/README.md)\n\n参数介绍：\n\n- 8086 HTTP API port\n- 8083 Administrator interface port, if it is enabled\n- 2003 Graphite support, if it is enabled\n\n启动server 可修改默认配置文件等，详见[How to run]\n\n```bash\ndocker run --name influxdb -d -p 8086:8086 -p 8083:8083  -e INFLUXDB_ADMIN_ENABLED=true  -v /var/lib/influxdb:/var/lib/influxdb  influxdb\n```\n\n初始化数据库\n\n```bash\ndocker run --rm \\\n      -e INFLUXDB_DB=db0 -e INFLUXDB_ADMIN_ENABLED=true \\\n      -e INFLUXDB_ADMIN_USER=admin -e INFLUXDB_ADMIN_USER=admin \\\n      -e INFLUXDB_USER=telegraf -e INFLUXDB_USER_PASSWORD=telegraf \\\n      -v /var/lib/influxdb:/var/lib/influxdb \\\n      influxdb /init-influxdb.sh\n```\n\n启动client\n\n```bash\ndocker run --rm --link=influxdb -it influxdb influx -host influxdb\n```\n\n其他命令\n\n创建数据库\n\n```shell\ncurl -G http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE mydb\"\n```\n\n插入数据\n\n```shell\ncurl -XPOST \"http://localhost:8086/write?db=mydb\" \\\n-d 'cpu,host=server01,region=uswest load=42 1434055562000000000'\n\ncurl -XPOST \"http://localhost:8086/write?db=mydb\" \\\n-d 'cpu,host=server02,region=uswest load=78 1434055562000000000'\n\ncurl -XPOST \"http://localhost:8086/write?db=mydb\" \\\n-d 'cpu,host=server03,region=useast load=15.4 1434055562000000000'\n```\n\n查询数据\n\n```shell\ncurl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\\n--data-urlencode \"q=SELECT * FROM cpu WHERE host='server01' AND time < now() - 1d\"\n```\n\n分析数据\n\n```shell\ncurl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\\n--data-urlencode \"q=SELECT mean(load) FROM cpu WHERE region='uswest'\"\n```\n\n[InfluxDB概念介绍](https://docs.influxdata.com/influxdb/v1.4/concepts/key_concepts/#field-key)\n\n#### Telegraf\n\n[Telegraf Docker file](https://github.com/influxdata/influxdata-docker/blob/ae56003075c8f39b6c265294ca8235c2c5235cc6/telegraf/1.5/alpine/Dockerfile)\n[How to run](https://github.com/docker-library/docs/blob/master/telegraf/content.md)\n\n参数介绍：\n\n- 8125 StatsD\n- 8092 UDP\n- 8094 TCP\n\n```bash\ndocker run --name telegraf -d -p 8125:8125 -p 8092:8092 -p 8094:8094  -v ~/telegraf.conf:/etc/telegraf/telegraf.conf telegraf\n```\n\n#### Chronograf\n\nExposed Ports\n\n- 8888TCP -- Listen  endpoint\n\n```shell\ndocker run -d --name chronograf -p 8888:8888 -v /var/lib/chronograf:/var/lib/chronograf quay.io/influxdb/chronograf chronograf\n```\n\n\n\n#### Kapacitor\n\nExposed Ports\n\n- 9092 TCP -- HTTP API endpoint\n\n需要修改默认的kapacitor.conf url地址，默认是配置localhost，而容器进程肯定不是localhost.\n\n```shell\ndocker run -d --name kapacitor -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor \n```\n\n查看帮助\n\n```shell\ndocker exec  kapacitor kapacitor help\ndocker exec  kapacitor kapacitor list tasks \ndocker exec  kapacitor kapacitor show CPURule\n\n```\n\n常见问题：\n\n容器告警因为ip原因无法，注册到influxdb时，ip是容器id，如下，导致Influxdb 无法识别该地址，性能数据无法发送到kapacitor。因此临时解决方案是修改容器的hostname\n\n```\n> show SUBSCRIPTIONS\nname: telegraf\nretention_policy name                                           mode destinations\n---------------- ----                                           ---- ------------\nautogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]\n\nname: _internal\nretention_policy name                                           mode destinations\n---------------- ----                                           ---- ------------\nmonitor          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]\n\nname: chronograf\nretention_policy name                                           mode destinations\n---------------- ----                                           ---- ------------\nautogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]\n\n```\n\n\n\n```\n docker run -d --name kapacitor -e KAPACITOR_HOSTNAME=192.168.14.165 -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor\n```\n\n\n\n## 2.Telgraf重点介绍\n\nTelegraf是一个用Go编写的代理程序，用于收集，处理，汇总和编写度量标准。\n\nTelegraf是插件驱动，并有4个不同的插件的概念：\n\n1. [输入插件](https://github.com/influxdata/telegraf#input-plugins)从系统，服务或第三方API收集指标。\n2. [处理器插件](https://github.com/influxdata/telegraf#processor-plugins)转换，修饰和/或过滤度量标准\n3. [聚合器插件](https://github.com/influxdata/telegraf#aggregator-plugins)创建聚合度量（例如平均值，最小值，最大值，分位数等）\n4. [输出插件](https://github.com/influxdata/telegraf#output-plugins)将指标写入各个目标\n\nTelegraf 二进制文件包含对所有支持的采集对象的采集功能，只是可以通过配置选择性的开启。如果更新某个对象的采集指标，则需要重新编译整个二进制文件。\n\n\n\n### 测试数据/帮助命令\n\n~/telegraf.conf 测试用配置文件，可定义输入插件\n\n```shell\ndocker run -v ~/telegraf.conf:/etc/telegraf/telegraf.conf --rm telegraf telegraf --config /etc/telegraf/telegraf.conf  --test\n```\n\n```\ndocker run --rm telegraf telegraf --help\n```\n\n### 数据收集方式\n\npush 模式，由telegraf 根据input配置主动采集并发送到output配置的后端。一般是InfluxDB数据库。TICK并无服务端的概念，在TICK监控部署文档的架构图中可知。\n\n[input-output-plugins](https://github.com/influxdata/telegraf/blob/master/README.md)\n\n\n\n### InfluxDB Line Protocol 数据格式\n\nInfluxDB Line Protocol 格式\n\nTelegraf metrics, like InfluxDB [points](https://docs.influxdata.com/influxdb/v0.10/write_protocols/line/), are a combination of four basic parts:\n\n```shell\nmeasurement_name[,tag1=val1,...]  field1=val1,field2=val2,...\n```\n\n1. Measurement Name\n\n2. Tags\n\n3. Fields\n\n4. Timestamp\n\n   ​\n\n### 输入数据格式\n\n[telegraf有六种采集数据输入格式](https://docs.influxdata.com/telegraf/v1.5/concepts/data_formats_input/)\n\nTelegraf is able to parse the following input data formats into metrics:\n\n1. [InfluxDB Line Protocol](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#influx)\n2. [JSON](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#json)\n3. [Graphite](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite)\n4. [Value](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#value), ie: 45 or \"booyah\"\n5. [Nagios](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#nagios) (exec input only)\n6. [Collectd](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#collectd)\n\n默认是第一种：InfluxDB Line Protocol。Graphite、Nagios、Collected都是其他开源监控项目，其中Nagios是比较完整的监控系统，其格式只能用在exec输入插件中；Collected一般用作系统守护进程，采集系统统计信息，并且通过网络开放数据；Graphite则是另外一套监控系统，也是C-S模式。\n\n如果是配置成其他格式，那么采集回来的数据（受限于采集方可吐出的数据），将会被Telegraf  转换为其可识别的InfluxDB Line Protocol。\n\n\n\n### 输出数据格式\n\n[telegraf有三种采集数据输出格式](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md)\n\nTelegraf is able to serialize metrics into the following output data formats:\n\n1. [InfluxDB Line Protocol](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#influx)\n2. [JSON](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#json)\n3. [Graphite](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#graphite)\n\n一般而言，输出格式如果是其他格式，例如Json，那么输出的对象则一般为file类型。从实际应用中来看，即通过telegraf采集回数据，生成json文件，发送至其他系统进行处理。\n\n以下是采集结果示例\n\n```shell\n* Plugin: inputs.cpu, Collection 1\n* Plugin: inputs.cpu, Collection 2\n> cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000\n> cpu,cpu=cpu1,host=0336dcb23579 usage_user=0,usage_guest_nice=0,usage_steal=0,usage_guest=0,usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_softirq=0 1515338025000000000\n> cpu,cpu=cpu2,host=0336dcb23579 usage_idle=100,usage_nice=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_irq=0,usage_softirq=0,usage_guest_nice=0 1515338025000000000\n> cpu,host=0336dcb23579,cpu=cpu3 usage_softirq=0,usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0 1515338025000000000\n> cpu,cpu=cpu-total,host=0336dcb23579 usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000\n\n```\n\ncpu：measurements ，类似oracle的表名\n\ncpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；\n\nusage_guest_nice=0,usage_idle=100,usage_nice=0... : usage_guest_nice等为field，即被采集的指标字段。field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面\n\n1515338025000000000： time 时间戳\n\n\n\n### 数据过滤/聚合\n\nMeasurement Filtering\n\n![数据处理](/img/agg-pro.jpg)\n\nFilters can be configured per input, output, processor, or aggregator, see below for examples.\n\n- **namepass**: An array of glob pattern strings. Only points whose measurement name matches a pattern in this list are emitted.\n- **namedrop**: The inverse of `namepass`. If a match is found the point is discarded. This is tested on points after they have passed the `namepass` test.\n- **fieldpass**: An array of glob pattern strings. Only fields whose field key matches a pattern in this list are emitted. Not available for outputs.\n- **fielddrop**: The inverse of `fieldpass`. Fields with a field key matching one of the patterns will be discarded from the point. This is tested on points after they have passed the `fieldpass` test. Not available for outputs.\n- **tagpass**: A table mapping tag keys to arrays of glob pattern strings. Only points that contain a tag key in the table and a tag value matching one of its patterns is emitted.\n- **tagdrop**: The inverse of `tagpass`. If a match is found the point is discarded. This is tested on points after they have passed the `tagpass` test.\n- **taginclude**: An array of glob pattern strings. Only tags with a tag key matching one of the patterns are emitted. In contrast to `tagpass`, which will pass an entire point based on its tag, `taginclude` removes all non matching tags from the point. This filter can be used on both inputs & outputs, but it is *recommended* to be used on inputs, as it is more efficient to filter out tags at the ingestion point.\n- **tagexclude**: The inverse of `taginclude`. Tags with a tag key matching one of the patterns will be discarded from the point.\n\n输入数据示例\n\n```shell\n[[inputs.cpu]]\n  percpu = true\n  totalcpu = false\n  fielddrop = [\"cpu_time\"]\n  # Don't collect CPU data for cpu6 & cpu7\n  [inputs.cpu.tagdrop]\n    cpu = [ \"cpu6\", \"cpu7\" ]\n\n[[inputs.disk]]\n  [inputs.disk.tagpass]\n    # tagpass conditions are OR, not AND.\n    # If the (filesystem is ext4 or xfs) OR (the path is /opt or /home)\n    # then the metric passes\n    fstype = [ \"ext4\", \"xfs\" ]\n    # Globs can also be used on the tag values\n    path = [ \"/opt\", \"/home*\" ]\n```\n\n输出数据示例\n\n与输入（采集）数据过滤类似，可定义多个输出源\n\n```shell\n[[outputs.influxdb]]\n  urls = [ \"http://localhost:8086\" ]\n  database = \"telegraf\"\n  # Drop all measurements that start with \"aerospike\"\n  namedrop = [\"aerospike*\"]\n\n[[outputs.influxdb]]\n  urls = [ \"http://localhost:8086\" ]\n  database = \"telegraf-aerospike-data\"\n  # Only accept aerospike data:\n  namepass = [\"aerospike*\"]\n\n[[outputs.influxdb]]\n  urls = [ \"http://localhost:8086\" ]\n  database = \"telegraf-cpu0-data\"\n  # Only store measurements where the tag \"cpu\" matches the value \"cpu0\"\n  [outputs.influxdb.tagpass]\n    cpu = [\"cpu0\"]\n```\n\nAggregator Plugins\n\n- [basicstats](https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/basicstats)\n- [minmax](https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/minmax)\n- [histogram](https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/histogram)\n\n### 部署方式\n\n客户端部署方式，可结合Ansible 进行部署，以及配置管理。官方说明并未看到。\n\n\n\n### 任务配置\n\n客户端配置文件配置 /etc/telegraf/telegraf.conf，可配置指标采集周期、过滤指标等。\n\n\n\n### 告警处理\n\n与Telegraf配合使用的告警处理程序是[kapacitor](https://github.com/influxdata/kapacitor) \n\nOpen source framework for processing, monitoring, and alerting on time series data。","slug":"tick","published":1,"updated":"2018-04-27T06:14:08.104Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczp90016e4rwbgwkji48","content":"<h2 id=\"1-Tick安装部署\"><a href=\"#1-Tick安装部署\" class=\"headerlink\" title=\"1.Tick安装部署\"></a>1.Tick安装部署</h2><h3 id=\"Tick简介\"><a href=\"#Tick简介\" class=\"headerlink\" title=\"Tick简介\"></a>Tick简介</h3><p>TICK 是由 InfluxData 开发的一套运维工具栈，由 Telegraf, InfluxDB, Chronograf, Kapacitor 四个工具的首字母组成。<br>这一套组件将收集数据和入库、数据库存储、展示、告警四者囊括了。</p>\n<p><img src=\"/img/tick.png\" alt=\"TICK框架图\" title=\"TICK\"> </p>\n<a id=\"more\"></a>\n<p>Telegraf</p>\n<p>是一个数据收集和入库的工具。提供了很多 input 和 output 插件，比如收集本地的 cpu、load、网络流量等数据，然后写入 InfluxDB 、Kafka或者OpenTSDB等。相当于ELK栈中的 logstash 功能。</p>\n<p>InfluxDB</p>\n<p>InfluxDB 是一个开源的GO语言为基础的数据库, 用来处理时间序列数据,提供了较高的可用性。与opentsdb类似，支持HTTP API方式，写入和读取数据。相当于ELK栈中的elasticsearch功能。</p>\n<p>Chronograf</p>\n<p>从InfluxDB时间序列数据的数据可视化工具，负责从InfluxDB收集数据，并将数据图表以web的形式发布。它使用简单,包括模板和库可以快速构建实时数据的可视化仪表板，轻松地创建报警和自动化的规则。相当于ELK栈中的kibana功能。</p>\n<p>Kapacitor</p>\n<p>Kapacitor是InfluxDB的数据处理引擎，主要作用是时间序列数据处理、监视和警报。</p>\n<h3 id=\"TICK安装（DOCKER版）\"><a href=\"#TICK安装（DOCKER版）\" class=\"headerlink\" title=\"TICK安装（DOCKER版）\"></a>TICK安装（DOCKER版）</h3><p><a href=\"https://portal.influxdata.com/downloads\" target=\"_blank\" rel=\"external\">官方安装介绍</a></p>\n<p>本地安装版本分别是telegraf1.5,influxdb1.42,chronograf1.4,kapacitor1.4</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker pull telegraf</div><div class=\"line\">docker pull influxdb</div><div class=\"line\">docker pull quay.io/influxdb/chronograf</div><div class=\"line\">docker pull kapacitor</div></pre></td></tr></table></figure>\n<h3 id=\"TICK配置与运行\"><a href=\"#TICK配置与运行\" class=\"headerlink\" title=\"TICK配置与运行\"></a>TICK配置与运行</h3><p><a href=\"https://github.com/influxdata/influxdata-docker\" target=\"_blank\" rel=\"external\">TICK Docker file</a></p>\n<h4 id=\"InfluxDB\"><a href=\"#InfluxDB\" class=\"headerlink\" title=\"InfluxDB\"></a>InfluxDB</h4><p><a href=\"https://github.com/docker-library/docs/blob/master/influxdb/README.md\" target=\"_blank\" rel=\"external\">How to run</a></p>\n<p>参数介绍：</p>\n<ul>\n<li>8086 HTTP API port</li>\n<li>8083 Administrator interface port, if it is enabled</li>\n<li>2003 Graphite support, if it is enabled</li>\n</ul>\n<p>启动server 可修改默认配置文件等，详见[How to run]</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name influxdb -d -p 8086:8086 -p 8083:8083  -e INFLUXDB_ADMIN_ENABLED=<span class=\"literal\">true</span>  -v /var/lib/influxdb:/var/lib/influxdb  influxdb</div></pre></td></tr></table></figure>\n<p>初始化数据库</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --rm \\</div><div class=\"line\">      -e INFLUXDB_DB=db0 -e INFLUXDB_ADMIN_ENABLED=<span class=\"literal\">true</span> \\</div><div class=\"line\">      -e INFLUXDB_ADMIN_USER=admin -e INFLUXDB_ADMIN_USER=admin \\</div><div class=\"line\">      -e INFLUXDB_USER=telegraf -e INFLUXDB_USER_PASSWORD=telegraf \\</div><div class=\"line\">      -v /var/lib/influxdb:/var/lib/influxdb \\</div><div class=\"line\">      influxdb /init-influxdb.sh</div></pre></td></tr></table></figure>\n<p>启动client</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --rm --link=influxdb -it influxdb influx -host influxdb</div></pre></td></tr></table></figure>\n<p>其他命令</p>\n<p>创建数据库</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE mydb\"</div></pre></td></tr></table></figure>\n<p>插入数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPOST \"http://localhost:8086/write?db=mydb\" \\</div><div class=\"line\">-d 'cpu,host=server01,region=uswest load=42 1434055562000000000'</div><div class=\"line\"></div><div class=\"line\">curl -XPOST \"http://localhost:8086/write?db=mydb\" \\</div><div class=\"line\">-d 'cpu,host=server02,region=uswest load=78 1434055562000000000'</div><div class=\"line\"></div><div class=\"line\">curl -XPOST \"http://localhost:8086/write?db=mydb\" \\</div><div class=\"line\">-d 'cpu,host=server03,region=useast load=15.4 1434055562000000000'</div></pre></td></tr></table></figure>\n<p>查询数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\</div><div class=\"line\">--data-urlencode \"q=SELECT * FROM cpu WHERE host='server01' AND time &lt; now() - 1d\"</div></pre></td></tr></table></figure>\n<p>分析数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\</div><div class=\"line\">--data-urlencode \"q=SELECT mean(load) FROM cpu WHERE region='uswest'\"</div></pre></td></tr></table></figure>\n<p><a href=\"https://docs.influxdata.com/influxdb/v1.4/concepts/key_concepts/#field-key\" target=\"_blank\" rel=\"external\">InfluxDB概念介绍</a></p>\n<h4 id=\"Telegraf\"><a href=\"#Telegraf\" class=\"headerlink\" title=\"Telegraf\"></a>Telegraf</h4><p><a href=\"https://github.com/influxdata/influxdata-docker/blob/ae56003075c8f39b6c265294ca8235c2c5235cc6/telegraf/1.5/alpine/Dockerfile\" target=\"_blank\" rel=\"external\">Telegraf Docker file</a><br><a href=\"https://github.com/docker-library/docs/blob/master/telegraf/content.md\" target=\"_blank\" rel=\"external\">How to run</a></p>\n<p>参数介绍：</p>\n<ul>\n<li>8125 StatsD</li>\n<li>8092 UDP</li>\n<li>8094 TCP</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name telegraf -d -p 8125:8125 -p 8092:8092 -p 8094:8094  -v ~/telegraf.conf:/etc/telegraf/telegraf.conf telegraf</div></pre></td></tr></table></figure>\n<h4 id=\"Chronograf\"><a href=\"#Chronograf\" class=\"headerlink\" title=\"Chronograf\"></a>Chronograf</h4><p>Exposed Ports</p>\n<ul>\n<li>8888TCP – Listen  endpoint</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name chronograf -p 8888:8888 -v /var/lib/chronograf:/var/lib/chronograf quay.io/influxdb/chronograf chronograf</div></pre></td></tr></table></figure>\n<h4 id=\"Kapacitor\"><a href=\"#Kapacitor\" class=\"headerlink\" title=\"Kapacitor\"></a>Kapacitor</h4><p>Exposed Ports</p>\n<ul>\n<li>9092 TCP – HTTP API endpoint</li>\n</ul>\n<p>需要修改默认的kapacitor.conf url地址，默认是配置localhost，而容器进程肯定不是localhost.</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name kapacitor -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor</div></pre></td></tr></table></figure>\n<p>查看帮助</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker exec  kapacitor kapacitor help</div><div class=\"line\">docker exec  kapacitor kapacitor list tasks </div><div class=\"line\">docker exec  kapacitor kapacitor show CPURule</div></pre></td></tr></table></figure>\n<p>常见问题：</p>\n<p>容器告警因为ip原因无法，注册到influxdb时，ip是容器id，如下，导致Influxdb 无法识别该地址，性能数据无法发送到kapacitor。因此临时解决方案是修改容器的hostname</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt; show SUBSCRIPTIONS</div><div class=\"line\">name: telegraf</div><div class=\"line\">retention_policy name                                           mode destinations</div><div class=\"line\">---------------- ----                                           ---- ------------</div><div class=\"line\">autogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]</div><div class=\"line\"></div><div class=\"line\">name: _internal</div><div class=\"line\">retention_policy name                                           mode destinations</div><div class=\"line\">---------------- ----                                           ---- ------------</div><div class=\"line\">monitor          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]</div><div class=\"line\"></div><div class=\"line\">name: chronograf</div><div class=\"line\">retention_policy name                                           mode destinations</div><div class=\"line\">---------------- ----                                           ---- ------------</div><div class=\"line\">autogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name kapacitor -e KAPACITOR_HOSTNAME=192.168.14.165 -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor</div></pre></td></tr></table></figure>\n<h2 id=\"2-Telgraf重点介绍\"><a href=\"#2-Telgraf重点介绍\" class=\"headerlink\" title=\"2.Telgraf重点介绍\"></a>2.Telgraf重点介绍</h2><p>Telegraf是一个用Go编写的代理程序，用于收集，处理，汇总和编写度量标准。</p>\n<p>Telegraf是插件驱动，并有4个不同的插件的概念：</p>\n<ol>\n<li><a href=\"https://github.com/influxdata/telegraf#input-plugins\" target=\"_blank\" rel=\"external\">输入插件</a>从系统，服务或第三方API收集指标。</li>\n<li><a href=\"https://github.com/influxdata/telegraf#processor-plugins\" target=\"_blank\" rel=\"external\">处理器插件</a>转换，修饰和/或过滤度量标准</li>\n<li><a href=\"https://github.com/influxdata/telegraf#aggregator-plugins\" target=\"_blank\" rel=\"external\">聚合器插件</a>创建聚合度量（例如平均值，最小值，最大值，分位数等）</li>\n<li><a href=\"https://github.com/influxdata/telegraf#output-plugins\" target=\"_blank\" rel=\"external\">输出插件</a>将指标写入各个目标</li>\n</ol>\n<p>Telegraf 二进制文件包含对所有支持的采集对象的采集功能，只是可以通过配置选择性的开启。如果更新某个对象的采集指标，则需要重新编译整个二进制文件。</p>\n<h3 id=\"测试数据-帮助命令\"><a href=\"#测试数据-帮助命令\" class=\"headerlink\" title=\"测试数据/帮助命令\"></a>测试数据/帮助命令</h3><p>~/telegraf.conf 测试用配置文件，可定义输入插件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -v ~/telegraf.conf:/etc/telegraf/telegraf.conf --rm telegraf telegraf --config /etc/telegraf/telegraf.conf  --test</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --rm telegraf telegraf --help</div></pre></td></tr></table></figure>\n<h3 id=\"数据收集方式\"><a href=\"#数据收集方式\" class=\"headerlink\" title=\"数据收集方式\"></a>数据收集方式</h3><p>push 模式，由telegraf 根据input配置主动采集并发送到output配置的后端。一般是InfluxDB数据库。TICK并无服务端的概念，在TICK监控部署文档的架构图中可知。</p>\n<p><a href=\"https://github.com/influxdata/telegraf/blob/master/README.md\" target=\"_blank\" rel=\"external\">input-output-plugins</a></p>\n<h3 id=\"InfluxDB-Line-Protocol-数据格式\"><a href=\"#InfluxDB-Line-Protocol-数据格式\" class=\"headerlink\" title=\"InfluxDB Line Protocol 数据格式\"></a>InfluxDB Line Protocol 数据格式</h3><p>InfluxDB Line Protocol 格式</p>\n<p>Telegraf metrics, like InfluxDB <a href=\"https://docs.influxdata.com/influxdb/v0.10/write_protocols/line/\" target=\"_blank\" rel=\"external\">points</a>, are a combination of four basic parts:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">measurement_name[,tag1=val1,...]  field1=val1,field2=val2,...</div></pre></td></tr></table></figure>\n<ol>\n<li><p>Measurement Name</p>\n</li>\n<li><p>Tags</p>\n</li>\n<li><p>Fields</p>\n</li>\n<li><p>Timestamp</p>\n<p>​</p>\n</li>\n</ol>\n<h3 id=\"输入数据格式\"><a href=\"#输入数据格式\" class=\"headerlink\" title=\"输入数据格式\"></a>输入数据格式</h3><p><a href=\"https://docs.influxdata.com/telegraf/v1.5/concepts/data_formats_input/\" target=\"_blank\" rel=\"external\">telegraf有六种采集数据输入格式</a></p>\n<p>Telegraf is able to parse the following input data formats into metrics:</p>\n<ol>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#influx\" target=\"_blank\" rel=\"external\">InfluxDB Line Protocol</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#json\" target=\"_blank\" rel=\"external\">JSON</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite\" target=\"_blank\" rel=\"external\">Graphite</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#value\" target=\"_blank\" rel=\"external\">Value</a>, ie: 45 or “booyah”</li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#nagios\" target=\"_blank\" rel=\"external\">Nagios</a> (exec input only)</li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#collectd\" target=\"_blank\" rel=\"external\">Collectd</a></li>\n</ol>\n<p>默认是第一种：InfluxDB Line Protocol。Graphite、Nagios、Collected都是其他开源监控项目，其中Nagios是比较完整的监控系统，其格式只能用在exec输入插件中；Collected一般用作系统守护进程，采集系统统计信息，并且通过网络开放数据；Graphite则是另外一套监控系统，也是C-S模式。</p>\n<p>如果是配置成其他格式，那么采集回来的数据（受限于采集方可吐出的数据），将会被Telegraf  转换为其可识别的InfluxDB Line Protocol。</p>\n<h3 id=\"输出数据格式\"><a href=\"#输出数据格式\" class=\"headerlink\" title=\"输出数据格式\"></a>输出数据格式</h3><p><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\" target=\"_blank\" rel=\"external\">telegraf有三种采集数据输出格式</a></p>\n<p>Telegraf is able to serialize metrics into the following output data formats:</p>\n<ol>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#influx\" target=\"_blank\" rel=\"external\">InfluxDB Line Protocol</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#json\" target=\"_blank\" rel=\"external\">JSON</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#graphite\" target=\"_blank\" rel=\"external\">Graphite</a></li>\n</ol>\n<p>一般而言，输出格式如果是其他格式，例如Json，那么输出的对象则一般为file类型。从实际应用中来看，即通过telegraf采集回数据，生成json文件，发送至其他系统进行处理。</p>\n<p>以下是采集结果示例</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">* Plugin: inputs.cpu, Collection 1</div><div class=\"line\">* Plugin: inputs.cpu, Collection 2</div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu1,host=0336dcb23579 usage_user=0,usage_guest_nice=0,usage_steal=0,usage_guest=0,usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_softirq=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu2,host=0336dcb23579 usage_idle=100,usage_nice=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_irq=0,usage_softirq=0,usage_guest_nice=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,host=0336dcb23579,cpu=cpu3 usage_softirq=0,usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu-total,host=0336dcb23579 usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000</span></div></pre></td></tr></table></figure>\n<p>cpu：measurements ，类似oracle的表名</p>\n<p>cpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；</p>\n<p>usage_guest_nice=0,usage_idle=100,usage_nice=0… : usage_guest_nice等为field，即被采集的指标字段。field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面</p>\n<p>1515338025000000000： time 时间戳</p>\n<h3 id=\"数据过滤-聚合\"><a href=\"#数据过滤-聚合\" class=\"headerlink\" title=\"数据过滤/聚合\"></a>数据过滤/聚合</h3><p>Measurement Filtering</p>\n<p><img src=\"/img/agg-pro.jpg\" alt=\"数据处理\"></p>\n<p>Filters can be configured per input, output, processor, or aggregator, see below for examples.</p>\n<ul>\n<li><strong>namepass</strong>: An array of glob pattern strings. Only points whose measurement name matches a pattern in this list are emitted.</li>\n<li><strong>namedrop</strong>: The inverse of <code>namepass</code>. If a match is found the point is discarded. This is tested on points after they have passed the <code>namepass</code> test.</li>\n<li><strong>fieldpass</strong>: An array of glob pattern strings. Only fields whose field key matches a pattern in this list are emitted. Not available for outputs.</li>\n<li><strong>fielddrop</strong>: The inverse of <code>fieldpass</code>. Fields with a field key matching one of the patterns will be discarded from the point. This is tested on points after they have passed the <code>fieldpass</code> test. Not available for outputs.</li>\n<li><strong>tagpass</strong>: A table mapping tag keys to arrays of glob pattern strings. Only points that contain a tag key in the table and a tag value matching one of its patterns is emitted.</li>\n<li><strong>tagdrop</strong>: The inverse of <code>tagpass</code>. If a match is found the point is discarded. This is tested on points after they have passed the <code>tagpass</code> test.</li>\n<li><strong>taginclude</strong>: An array of glob pattern strings. Only tags with a tag key matching one of the patterns are emitted. In contrast to <code>tagpass</code>, which will pass an entire point based on its tag, <code>taginclude</code> removes all non matching tags from the point. This filter can be used on both inputs &amp; outputs, but it is <em>recommended</em> to be used on inputs, as it is more efficient to filter out tags at the ingestion point.</li>\n<li><strong>tagexclude</strong>: The inverse of <code>taginclude</code>. Tags with a tag key matching one of the patterns will be discarded from the point.</li>\n</ul>\n<p>输入数据示例</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">[[inputs.cpu]]</div><div class=\"line\">  percpu = true</div><div class=\"line\">  totalcpu = false</div><div class=\"line\">  fielddrop = [\"cpu_time\"]</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Don<span class=\"string\">'t collect CPU data for cpu6 &amp; cpu7</span></span></div><div class=\"line\">  [inputs.cpu.tagdrop]</div><div class=\"line\">    cpu = [ \"cpu6\", \"cpu7\" ]</div><div class=\"line\"></div><div class=\"line\">[[inputs.disk]]</div><div class=\"line\">  [inputs.disk.tagpass]</div><div class=\"line\">    # tagpass conditions are OR, not AND.</div><div class=\"line\">    # If the (filesystem is ext4 or xfs) OR (the path is /opt or /home)</div><div class=\"line\">    # then the metric passes</div><div class=\"line\">    fstype = [ \"ext4\", \"xfs\" ]</div><div class=\"line\">    # Globs can also be used on the tag values</div><div class=\"line\">    path = [ \"/opt\", \"/home*\" ]</div></pre></td></tr></table></figure>\n<p>输出数据示例</p>\n<p>与输入（采集）数据过滤类似，可定义多个输出源</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">[[outputs.influxdb]]</div><div class=\"line\">  urls = [ \"http://localhost:8086\" ]</div><div class=\"line\">  database = \"telegraf\"</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Drop all measurements that start with <span class=\"string\">\"aerospike\"</span></span></div><div class=\"line\">  namedrop = [\"aerospike*\"]</div><div class=\"line\"></div><div class=\"line\">[[outputs.influxdb]]</div><div class=\"line\">  urls = [ \"http://localhost:8086\" ]</div><div class=\"line\">  database = \"telegraf-aerospike-data\"</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Only accept aerospike data:</span></div><div class=\"line\">  namepass = [\"aerospike*\"]</div><div class=\"line\"></div><div class=\"line\">[[outputs.influxdb]]</div><div class=\"line\">  urls = [ \"http://localhost:8086\" ]</div><div class=\"line\">  database = \"telegraf-cpu0-data\"</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Only store measurements <span class=\"built_in\">where</span> the tag <span class=\"string\">\"cpu\"</span> matches the value <span class=\"string\">\"cpu0\"</span></span></div><div class=\"line\">  [outputs.influxdb.tagpass]</div><div class=\"line\">    cpu = [\"cpu0\"]</div></pre></td></tr></table></figure>\n<p>Aggregator Plugins</p>\n<ul>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/basicstats\" target=\"_blank\" rel=\"external\">basicstats</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/minmax\" target=\"_blank\" rel=\"external\">minmax</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/histogram\" target=\"_blank\" rel=\"external\">histogram</a></li>\n</ul>\n<h3 id=\"部署方式\"><a href=\"#部署方式\" class=\"headerlink\" title=\"部署方式\"></a>部署方式</h3><p>客户端部署方式，可结合Ansible 进行部署，以及配置管理。官方说明并未看到。</p>\n<h3 id=\"任务配置\"><a href=\"#任务配置\" class=\"headerlink\" title=\"任务配置\"></a>任务配置</h3><p>客户端配置文件配置 /etc/telegraf/telegraf.conf，可配置指标采集周期、过滤指标等。</p>\n<h3 id=\"告警处理\"><a href=\"#告警处理\" class=\"headerlink\" title=\"告警处理\"></a>告警处理</h3><p>与Telegraf配合使用的告警处理程序是<a href=\"https://github.com/influxdata/kapacitor\" target=\"_blank\" rel=\"external\">kapacitor</a> </p>\n<p>Open source framework for processing, monitoring, and alerting on time series data。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-Tick安装部署\"><a href=\"#1-Tick安装部署\" class=\"headerlink\" title=\"1.Tick安装部署\"></a>1.Tick安装部署</h2><h3 id=\"Tick简介\"><a href=\"#Tick简介\" class=\"headerlink\" title=\"Tick简介\"></a>Tick简介</h3><p>TICK 是由 InfluxData 开发的一套运维工具栈，由 Telegraf, InfluxDB, Chronograf, Kapacitor 四个工具的首字母组成。<br>这一套组件将收集数据和入库、数据库存储、展示、告警四者囊括了。</p>\n<p><img src=\"/img/tick.png\" alt=\"TICK框架图\" title=\"TICK\"> </p>","more":"<p>Telegraf</p>\n<p>是一个数据收集和入库的工具。提供了很多 input 和 output 插件，比如收集本地的 cpu、load、网络流量等数据，然后写入 InfluxDB 、Kafka或者OpenTSDB等。相当于ELK栈中的 logstash 功能。</p>\n<p>InfluxDB</p>\n<p>InfluxDB 是一个开源的GO语言为基础的数据库, 用来处理时间序列数据,提供了较高的可用性。与opentsdb类似，支持HTTP API方式，写入和读取数据。相当于ELK栈中的elasticsearch功能。</p>\n<p>Chronograf</p>\n<p>从InfluxDB时间序列数据的数据可视化工具，负责从InfluxDB收集数据，并将数据图表以web的形式发布。它使用简单,包括模板和库可以快速构建实时数据的可视化仪表板，轻松地创建报警和自动化的规则。相当于ELK栈中的kibana功能。</p>\n<p>Kapacitor</p>\n<p>Kapacitor是InfluxDB的数据处理引擎，主要作用是时间序列数据处理、监视和警报。</p>\n<h3 id=\"TICK安装（DOCKER版）\"><a href=\"#TICK安装（DOCKER版）\" class=\"headerlink\" title=\"TICK安装（DOCKER版）\"></a>TICK安装（DOCKER版）</h3><p><a href=\"https://portal.influxdata.com/downloads\" target=\"_blank\" rel=\"external\">官方安装介绍</a></p>\n<p>本地安装版本分别是telegraf1.5,influxdb1.42,chronograf1.4,kapacitor1.4</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker pull telegraf</div><div class=\"line\">docker pull influxdb</div><div class=\"line\">docker pull quay.io/influxdb/chronograf</div><div class=\"line\">docker pull kapacitor</div></pre></td></tr></table></figure>\n<h3 id=\"TICK配置与运行\"><a href=\"#TICK配置与运行\" class=\"headerlink\" title=\"TICK配置与运行\"></a>TICK配置与运行</h3><p><a href=\"https://github.com/influxdata/influxdata-docker\" target=\"_blank\" rel=\"external\">TICK Docker file</a></p>\n<h4 id=\"InfluxDB\"><a href=\"#InfluxDB\" class=\"headerlink\" title=\"InfluxDB\"></a>InfluxDB</h4><p><a href=\"https://github.com/docker-library/docs/blob/master/influxdb/README.md\" target=\"_blank\" rel=\"external\">How to run</a></p>\n<p>参数介绍：</p>\n<ul>\n<li>8086 HTTP API port</li>\n<li>8083 Administrator interface port, if it is enabled</li>\n<li>2003 Graphite support, if it is enabled</li>\n</ul>\n<p>启动server 可修改默认配置文件等，详见[How to run]</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name influxdb -d -p 8086:8086 -p 8083:8083  -e INFLUXDB_ADMIN_ENABLED=<span class=\"literal\">true</span>  -v /var/lib/influxdb:/var/lib/influxdb  influxdb</div></pre></td></tr></table></figure>\n<p>初始化数据库</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --rm \\</div><div class=\"line\">      -e INFLUXDB_DB=db0 -e INFLUXDB_ADMIN_ENABLED=<span class=\"literal\">true</span> \\</div><div class=\"line\">      -e INFLUXDB_ADMIN_USER=admin -e INFLUXDB_ADMIN_USER=admin \\</div><div class=\"line\">      -e INFLUXDB_USER=telegraf -e INFLUXDB_USER_PASSWORD=telegraf \\</div><div class=\"line\">      -v /var/lib/influxdb:/var/lib/influxdb \\</div><div class=\"line\">      influxdb /init-influxdb.sh</div></pre></td></tr></table></figure>\n<p>启动client</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --rm --link=influxdb -it influxdb influx -host influxdb</div></pre></td></tr></table></figure>\n<p>其他命令</p>\n<p>创建数据库</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G http://localhost:8086/query --data-urlencode \"q=CREATE DATABASE mydb\"</div></pre></td></tr></table></figure>\n<p>插入数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -XPOST \"http://localhost:8086/write?db=mydb\" \\</div><div class=\"line\">-d 'cpu,host=server01,region=uswest load=42 1434055562000000000'</div><div class=\"line\"></div><div class=\"line\">curl -XPOST \"http://localhost:8086/write?db=mydb\" \\</div><div class=\"line\">-d 'cpu,host=server02,region=uswest load=78 1434055562000000000'</div><div class=\"line\"></div><div class=\"line\">curl -XPOST \"http://localhost:8086/write?db=mydb\" \\</div><div class=\"line\">-d 'cpu,host=server03,region=useast load=15.4 1434055562000000000'</div></pre></td></tr></table></figure>\n<p>查询数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\</div><div class=\"line\">--data-urlencode \"q=SELECT * FROM cpu WHERE host='server01' AND time &lt; now() - 1d\"</div></pre></td></tr></table></figure>\n<p>分析数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -G \"http://localhost:8086/query?pretty=true\" --data-urlencode \"db=mydb\" \\</div><div class=\"line\">--data-urlencode \"q=SELECT mean(load) FROM cpu WHERE region='uswest'\"</div></pre></td></tr></table></figure>\n<p><a href=\"https://docs.influxdata.com/influxdb/v1.4/concepts/key_concepts/#field-key\" target=\"_blank\" rel=\"external\">InfluxDB概念介绍</a></p>\n<h4 id=\"Telegraf\"><a href=\"#Telegraf\" class=\"headerlink\" title=\"Telegraf\"></a>Telegraf</h4><p><a href=\"https://github.com/influxdata/influxdata-docker/blob/ae56003075c8f39b6c265294ca8235c2c5235cc6/telegraf/1.5/alpine/Dockerfile\" target=\"_blank\" rel=\"external\">Telegraf Docker file</a><br><a href=\"https://github.com/docker-library/docs/blob/master/telegraf/content.md\" target=\"_blank\" rel=\"external\">How to run</a></p>\n<p>参数介绍：</p>\n<ul>\n<li>8125 StatsD</li>\n<li>8092 UDP</li>\n<li>8094 TCP</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name telegraf -d -p 8125:8125 -p 8092:8092 -p 8094:8094  -v ~/telegraf.conf:/etc/telegraf/telegraf.conf telegraf</div></pre></td></tr></table></figure>\n<h4 id=\"Chronograf\"><a href=\"#Chronograf\" class=\"headerlink\" title=\"Chronograf\"></a>Chronograf</h4><p>Exposed Ports</p>\n<ul>\n<li>8888TCP – Listen  endpoint</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name chronograf -p 8888:8888 -v /var/lib/chronograf:/var/lib/chronograf quay.io/influxdb/chronograf chronograf</div></pre></td></tr></table></figure>\n<h4 id=\"Kapacitor\"><a href=\"#Kapacitor\" class=\"headerlink\" title=\"Kapacitor\"></a>Kapacitor</h4><p>Exposed Ports</p>\n<ul>\n<li>9092 TCP – HTTP API endpoint</li>\n</ul>\n<p>需要修改默认的kapacitor.conf url地址，默认是配置localhost，而容器进程肯定不是localhost.</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name kapacitor -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor</div></pre></td></tr></table></figure>\n<p>查看帮助</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker exec  kapacitor kapacitor help</div><div class=\"line\">docker exec  kapacitor kapacitor list tasks </div><div class=\"line\">docker exec  kapacitor kapacitor show CPURule</div></pre></td></tr></table></figure>\n<p>常见问题：</p>\n<p>容器告警因为ip原因无法，注册到influxdb时，ip是容器id，如下，导致Influxdb 无法识别该地址，性能数据无法发送到kapacitor。因此临时解决方案是修改容器的hostname</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt; show SUBSCRIPTIONS</div><div class=\"line\">name: telegraf</div><div class=\"line\">retention_policy name                                           mode destinations</div><div class=\"line\">---------------- ----                                           ---- ------------</div><div class=\"line\">autogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]</div><div class=\"line\"></div><div class=\"line\">name: _internal</div><div class=\"line\">retention_policy name                                           mode destinations</div><div class=\"line\">---------------- ----                                           ---- ------------</div><div class=\"line\">monitor          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]</div><div class=\"line\"></div><div class=\"line\">name: chronograf</div><div class=\"line\">retention_policy name                                           mode destinations</div><div class=\"line\">---------------- ----                                           ---- ------------</div><div class=\"line\">autogen          kapacitor-8ca0780c-5208-41d5-91ec-05b28d13b2b8 ANY  [http://c9816b89f375:9092]</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -d --name kapacitor -e KAPACITOR_HOSTNAME=192.168.14.165 -p 9092:9092 -v /var/lib/kapacitor:/var/lib/kapacitor  -v ~/kapacitor.conf:/etc/kapacitor/kapacitor.conf  kapacitor</div></pre></td></tr></table></figure>\n<h2 id=\"2-Telgraf重点介绍\"><a href=\"#2-Telgraf重点介绍\" class=\"headerlink\" title=\"2.Telgraf重点介绍\"></a>2.Telgraf重点介绍</h2><p>Telegraf是一个用Go编写的代理程序，用于收集，处理，汇总和编写度量标准。</p>\n<p>Telegraf是插件驱动，并有4个不同的插件的概念：</p>\n<ol>\n<li><a href=\"https://github.com/influxdata/telegraf#input-plugins\" target=\"_blank\" rel=\"external\">输入插件</a>从系统，服务或第三方API收集指标。</li>\n<li><a href=\"https://github.com/influxdata/telegraf#processor-plugins\" target=\"_blank\" rel=\"external\">处理器插件</a>转换，修饰和/或过滤度量标准</li>\n<li><a href=\"https://github.com/influxdata/telegraf#aggregator-plugins\" target=\"_blank\" rel=\"external\">聚合器插件</a>创建聚合度量（例如平均值，最小值，最大值，分位数等）</li>\n<li><a href=\"https://github.com/influxdata/telegraf#output-plugins\" target=\"_blank\" rel=\"external\">输出插件</a>将指标写入各个目标</li>\n</ol>\n<p>Telegraf 二进制文件包含对所有支持的采集对象的采集功能，只是可以通过配置选择性的开启。如果更新某个对象的采集指标，则需要重新编译整个二进制文件。</p>\n<h3 id=\"测试数据-帮助命令\"><a href=\"#测试数据-帮助命令\" class=\"headerlink\" title=\"测试数据/帮助命令\"></a>测试数据/帮助命令</h3><p>~/telegraf.conf 测试用配置文件，可定义输入插件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run -v ~/telegraf.conf:/etc/telegraf/telegraf.conf --rm telegraf telegraf --config /etc/telegraf/telegraf.conf  --test</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --rm telegraf telegraf --help</div></pre></td></tr></table></figure>\n<h3 id=\"数据收集方式\"><a href=\"#数据收集方式\" class=\"headerlink\" title=\"数据收集方式\"></a>数据收集方式</h3><p>push 模式，由telegraf 根据input配置主动采集并发送到output配置的后端。一般是InfluxDB数据库。TICK并无服务端的概念，在TICK监控部署文档的架构图中可知。</p>\n<p><a href=\"https://github.com/influxdata/telegraf/blob/master/README.md\" target=\"_blank\" rel=\"external\">input-output-plugins</a></p>\n<h3 id=\"InfluxDB-Line-Protocol-数据格式\"><a href=\"#InfluxDB-Line-Protocol-数据格式\" class=\"headerlink\" title=\"InfluxDB Line Protocol 数据格式\"></a>InfluxDB Line Protocol 数据格式</h3><p>InfluxDB Line Protocol 格式</p>\n<p>Telegraf metrics, like InfluxDB <a href=\"https://docs.influxdata.com/influxdb/v0.10/write_protocols/line/\" target=\"_blank\" rel=\"external\">points</a>, are a combination of four basic parts:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">measurement_name[,tag1=val1,...]  field1=val1,field2=val2,...</div></pre></td></tr></table></figure>\n<ol>\n<li><p>Measurement Name</p>\n</li>\n<li><p>Tags</p>\n</li>\n<li><p>Fields</p>\n</li>\n<li><p>Timestamp</p>\n<p>​</p>\n</li>\n</ol>\n<h3 id=\"输入数据格式\"><a href=\"#输入数据格式\" class=\"headerlink\" title=\"输入数据格式\"></a>输入数据格式</h3><p><a href=\"https://docs.influxdata.com/telegraf/v1.5/concepts/data_formats_input/\" target=\"_blank\" rel=\"external\">telegraf有六种采集数据输入格式</a></p>\n<p>Telegraf is able to parse the following input data formats into metrics:</p>\n<ol>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#influx\" target=\"_blank\" rel=\"external\">InfluxDB Line Protocol</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#json\" target=\"_blank\" rel=\"external\">JSON</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite\" target=\"_blank\" rel=\"external\">Graphite</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#value\" target=\"_blank\" rel=\"external\">Value</a>, ie: 45 or “booyah”</li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#nagios\" target=\"_blank\" rel=\"external\">Nagios</a> (exec input only)</li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#collectd\" target=\"_blank\" rel=\"external\">Collectd</a></li>\n</ol>\n<p>默认是第一种：InfluxDB Line Protocol。Graphite、Nagios、Collected都是其他开源监控项目，其中Nagios是比较完整的监控系统，其格式只能用在exec输入插件中；Collected一般用作系统守护进程，采集系统统计信息，并且通过网络开放数据；Graphite则是另外一套监控系统，也是C-S模式。</p>\n<p>如果是配置成其他格式，那么采集回来的数据（受限于采集方可吐出的数据），将会被Telegraf  转换为其可识别的InfluxDB Line Protocol。</p>\n<h3 id=\"输出数据格式\"><a href=\"#输出数据格式\" class=\"headerlink\" title=\"输出数据格式\"></a>输出数据格式</h3><p><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\" target=\"_blank\" rel=\"external\">telegraf有三种采集数据输出格式</a></p>\n<p>Telegraf is able to serialize metrics into the following output data formats:</p>\n<ol>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#influx\" target=\"_blank\" rel=\"external\">InfluxDB Line Protocol</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#json\" target=\"_blank\" rel=\"external\">JSON</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#graphite\" target=\"_blank\" rel=\"external\">Graphite</a></li>\n</ol>\n<p>一般而言，输出格式如果是其他格式，例如Json，那么输出的对象则一般为file类型。从实际应用中来看，即通过telegraf采集回数据，生成json文件，发送至其他系统进行处理。</p>\n<p>以下是采集结果示例</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">* Plugin: inputs.cpu, Collection 1</div><div class=\"line\">* Plugin: inputs.cpu, Collection 2</div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu0,host=0336dcb23579 usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_guest=0,usage_user=0,usage_softirq=0,usage_steal=0,usage_guest_nice=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu1,host=0336dcb23579 usage_user=0,usage_guest_nice=0,usage_steal=0,usage_guest=0,usage_system=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_softirq=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu2,host=0336dcb23579 usage_idle=100,usage_nice=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_irq=0,usage_softirq=0,usage_guest_nice=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,host=0336dcb23579,cpu=cpu3 usage_softirq=0,usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_iowait=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0 1515338025000000000</span></div><div class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\"> cpu,cpu=cpu-total,host=0336dcb23579 usage_guest_nice=0,usage_idle=100,usage_nice=0,usage_irq=0,usage_steal=0,usage_guest=0,usage_user=0,usage_system=0,usage_iowait=0,usage_softirq=0 1515338025000000000</span></div></pre></td></tr></table></figure>\n<p>cpu：measurements ，类似oracle的表名</p>\n<p>cpu=cpu-total,host=0336dcb23579 ： cpu、host为tag，索引；</p>\n<p>usage_guest_nice=0,usage_idle=100,usage_nice=0… : usage_guest_nice等为field，即被采集的指标字段。field在measurements是不可或缺的，tag可无， tag与field用空格隔开，field放置在后面</p>\n<p>1515338025000000000： time 时间戳</p>\n<h3 id=\"数据过滤-聚合\"><a href=\"#数据过滤-聚合\" class=\"headerlink\" title=\"数据过滤/聚合\"></a>数据过滤/聚合</h3><p>Measurement Filtering</p>\n<p><img src=\"/img/agg-pro.jpg\" alt=\"数据处理\"></p>\n<p>Filters can be configured per input, output, processor, or aggregator, see below for examples.</p>\n<ul>\n<li><strong>namepass</strong>: An array of glob pattern strings. Only points whose measurement name matches a pattern in this list are emitted.</li>\n<li><strong>namedrop</strong>: The inverse of <code>namepass</code>. If a match is found the point is discarded. This is tested on points after they have passed the <code>namepass</code> test.</li>\n<li><strong>fieldpass</strong>: An array of glob pattern strings. Only fields whose field key matches a pattern in this list are emitted. Not available for outputs.</li>\n<li><strong>fielddrop</strong>: The inverse of <code>fieldpass</code>. Fields with a field key matching one of the patterns will be discarded from the point. This is tested on points after they have passed the <code>fieldpass</code> test. Not available for outputs.</li>\n<li><strong>tagpass</strong>: A table mapping tag keys to arrays of glob pattern strings. Only points that contain a tag key in the table and a tag value matching one of its patterns is emitted.</li>\n<li><strong>tagdrop</strong>: The inverse of <code>tagpass</code>. If a match is found the point is discarded. This is tested on points after they have passed the <code>tagpass</code> test.</li>\n<li><strong>taginclude</strong>: An array of glob pattern strings. Only tags with a tag key matching one of the patterns are emitted. In contrast to <code>tagpass</code>, which will pass an entire point based on its tag, <code>taginclude</code> removes all non matching tags from the point. This filter can be used on both inputs &amp; outputs, but it is <em>recommended</em> to be used on inputs, as it is more efficient to filter out tags at the ingestion point.</li>\n<li><strong>tagexclude</strong>: The inverse of <code>taginclude</code>. Tags with a tag key matching one of the patterns will be discarded from the point.</li>\n</ul>\n<p>输入数据示例</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">[[inputs.cpu]]</div><div class=\"line\">  percpu = true</div><div class=\"line\">  totalcpu = false</div><div class=\"line\">  fielddrop = [\"cpu_time\"]</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Don<span class=\"string\">'t collect CPU data for cpu6 &amp; cpu7</span></span></div><div class=\"line\">  [inputs.cpu.tagdrop]</div><div class=\"line\">    cpu = [ \"cpu6\", \"cpu7\" ]</div><div class=\"line\"></div><div class=\"line\">[[inputs.disk]]</div><div class=\"line\">  [inputs.disk.tagpass]</div><div class=\"line\">    # tagpass conditions are OR, not AND.</div><div class=\"line\">    # If the (filesystem is ext4 or xfs) OR (the path is /opt or /home)</div><div class=\"line\">    # then the metric passes</div><div class=\"line\">    fstype = [ \"ext4\", \"xfs\" ]</div><div class=\"line\">    # Globs can also be used on the tag values</div><div class=\"line\">    path = [ \"/opt\", \"/home*\" ]</div></pre></td></tr></table></figure>\n<p>输出数据示例</p>\n<p>与输入（采集）数据过滤类似，可定义多个输出源</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">[[outputs.influxdb]]</div><div class=\"line\">  urls = [ \"http://localhost:8086\" ]</div><div class=\"line\">  database = \"telegraf\"</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Drop all measurements that start with <span class=\"string\">\"aerospike\"</span></span></div><div class=\"line\">  namedrop = [\"aerospike*\"]</div><div class=\"line\"></div><div class=\"line\">[[outputs.influxdb]]</div><div class=\"line\">  urls = [ \"http://localhost:8086\" ]</div><div class=\"line\">  database = \"telegraf-aerospike-data\"</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Only accept aerospike data:</span></div><div class=\"line\">  namepass = [\"aerospike*\"]</div><div class=\"line\"></div><div class=\"line\">[[outputs.influxdb]]</div><div class=\"line\">  urls = [ \"http://localhost:8086\" ]</div><div class=\"line\">  database = \"telegraf-cpu0-data\"</div><div class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Only store measurements <span class=\"built_in\">where</span> the tag <span class=\"string\">\"cpu\"</span> matches the value <span class=\"string\">\"cpu0\"</span></span></div><div class=\"line\">  [outputs.influxdb.tagpass]</div><div class=\"line\">    cpu = [\"cpu0\"]</div></pre></td></tr></table></figure>\n<p>Aggregator Plugins</p>\n<ul>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/basicstats\" target=\"_blank\" rel=\"external\">basicstats</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/minmax\" target=\"_blank\" rel=\"external\">minmax</a></li>\n<li><a href=\"https://github.com/influxdata/telegraf/blob/master/plugins/aggregators/histogram\" target=\"_blank\" rel=\"external\">histogram</a></li>\n</ul>\n<h3 id=\"部署方式\"><a href=\"#部署方式\" class=\"headerlink\" title=\"部署方式\"></a>部署方式</h3><p>客户端部署方式，可结合Ansible 进行部署，以及配置管理。官方说明并未看到。</p>\n<h3 id=\"任务配置\"><a href=\"#任务配置\" class=\"headerlink\" title=\"任务配置\"></a>任务配置</h3><p>客户端配置文件配置 /etc/telegraf/telegraf.conf，可配置指标采集周期、过滤指标等。</p>\n<h3 id=\"告警处理\"><a href=\"#告警处理\" class=\"headerlink\" title=\"告警处理\"></a>告警处理</h3><p>与Telegraf配合使用的告警处理程序是<a href=\"https://github.com/influxdata/kapacitor\" target=\"_blank\" rel=\"external\">kapacitor</a> </p>\n<p>Open source framework for processing, monitoring, and alerting on time series data。</p>"},{"title":"Sensu 监控体系介绍","date":"2018-03-27T04:51:23.000Z","_content":"\n## 1.Sensu 安装部署\n\n### 主要特性\n\n[首页介绍](https://sensuapp.org/docs/1.2/overview/what-is-sensu.html)\n\nSensu was designed to provide a comprehensive monitoring platform for monitoring infrastructure (servers), services, application health, and business KPIs — and to collect and analyze custom metrics. \n\n主要包含以下功能与特性：\n\n- 检查系统、服务和程序的运行状态。\n- 基于分布式的设计，能够轻松的动态伸缩规模。\n- 支持通过插件的形式自定义检查的内容，拥有丰富的插件库。\n- 收集信息，获取被监控节点上的各项数据指标等。\n- 可视化的操作界面，提供实时的 GUI 用于显示和操作相关信息。\n- 内置的集成工具，可用于和其它系统集成，如 PagerDuty、Graphite、Email 等。\n- 提供丰富的 API 接口，支持通过 API 调用访问事件和客户端信息，触发检测等。\n- 加密的安全通信，支持各种复杂的网络拓扑。\n\n包括有类似我们拨测的功能，可对服务可用性进行检查，例如指定页面进行访问。\n\n结合其他软件：Sensu 从监控节点获取数据，将数据格式化成 Graphite 要求的格式，然后通过调用 Graphite 的接口将数据发给 Graphite。Graphite 将数据存储在时序数据中供 Grafana 绘图使用。最终用户通过在 Grafana 中[定制](http://www.liuhaihua.cn/archives/tag/private)需要显示的数据及显示的方式，获得最终的可视化图表。\n\n------\n\n### 架构\n\nSensu 由服务器、客户端、RabbitMQ、Redis 和 API 这五个部分构成。图 1 展示了这些组件之间的关系以及通信的数据流。如图所示，RabbitMQ 用于组件之间的通信，Redis 用于持久化 Sensu 服务器和 Sensu API 的数据。因为客户端都是通过文件进行配置，并且不需要在服务器端配置客户端的信息，所以可以很轻易的增加和减少客户端的数量。由于 Sensu 的服务器和 API 原生支持多节点部署，所以不存在效率的瓶颈问题。从图中可以看到，为了解耦服务器和客户端，通信都是通过 RabbitMQ 进行的。\n\n![组成部分](/img/sensu组成部分.png)\n\n核心代码由Ruby编写。[Github地址](https://github.com/sensu/sensu)\n\n实际安装中，不一定要使用RabbitMq作为消息中间件。直接使用redis即可。以下安装使用redis。\n\n<!-- more -->\n\n### 安装部署\n\nserver/clent 支持平台有\n\n![支持平台](/img/sensu-support-platforms.png)\n\n\n\nServer安装部署：\n\n安装配置yum源 /etc/yum.repos.d/sensu.repo\n\n```shell\n[sensu]\nname=sensu\nbaseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/\ngpgcheck=0\nenabled=1\n```\n\n```shell\nyum install redis -y\nyum install sensu -y\n```\n\nsensu server 配置 /etc/sensu/config.json\n\n```\n{\n  \"transport\": {\n    \"name\": \"redis\"\n  },\n  \"api\": {\n    \"host\": \"127.0.0.1\",\n    \"port\": 4567\n  }\n}\n```\n\nsensu client/server配置transport.redis\n\n```shell\n{\n  \"redis\":\n    {\n       \"host\": \"127.0.0.1\",\n       \"port\": 6379\n    }\n}\n```\n\nsensu client 配置 /etc/sensu/conf.d/client.json\n\n```\n{\n  \"client\": {\n    \"name\": \"rhel-client\",\n    \"address\": \"127.0.0.1\",\n    \"environment\": \"development\",\n    \"subscriptions\": [\n      \"dev\",\n      \"rhel-hosts\"\n    ],\n    \"socket\": {\n      \"bind\": \"127.0.0.1\",\n      \"port\": 3030\n    }\n  }\n｝\n```\n\nsensu dashboard配置 /etc/sensu/dashboard.json\n\n```\n{\n  \"sensu\": [\n    {\n      \"name\": \"sensu\",\n      \"host\": \"127.0.0.1\",\n      \"port\": 4567\n    }\n  ],\n  \"dashboard\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 3000\n  }\n}\n```\n\n启动进程\n\n```shell\nsystemctl enable sensu-{server,api,client} \nsystemctl start sensu-{server,api,client}\nsystemctl restart sensu-{server,api,client}\n```\n\nuchiwa 图形展示界面，需要额外安装。sensu提供了两个版本的展示界面，一个是企业版，一个就是uchiwa 。这里使用uchiwa，[下载链接](https://uchiwa.io/#/download)。 下载完成后，使用yum命令安装\n\n```\nyum -y localinstall uchiwa-1.1.1-1.x86_64.rpm\nsystemctl enable uchiwa\nsystemctl start uchiwa\n```\n\n配置好 uchiwa  /etc/sensu/uchiwa.json\n\n```shell\n{\n  \"sensu\": [\n    {\n      \"name\": \"Sensu-Server-1\",\n      \"host\": \"127.0.0.1\",\n      \"port\": 4567,\n      \"timeout\": 10\n    }\n  ],\n  \"uchiwa\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 3000,\n    \"refresh\": 10\n  }\n}\n```\n\n[URL](http://192.168.14.165:3000)\n\n![图例](/img/uchiwa.png)\n\n\n\nuchiwa 只是简单的展示功能，并不能对client等进行增删操作，即相当于对Sensu-API 只实现了Get相关的功能\n\n[HTTP API用例](https://sensuapp.org/docs/1.2/api/overview.html)\n\n### 部署过程中遇到的问题\n\n- uchiwa无法展示client和server，大部分都是json配置文件没有配置清楚导致。可查看日志/var/log/uchiwa，/var/log/sensu/sensu-client.log\n\n\n\n## 2.Sensu 使用\n\n### Sensu Client\n\nSensu Client 就是采集客户端agent。\n\n[介绍博文](https://blog.csdn.net/houzhe_adore/article/details/48518825)\n\n### Proxy Clients\n\n\n\n### Sensu Check\n\nSensu checks allow you to monitor server resources, services, and application health, as well as collect & analyze metrics; they are executed on servers running the Sensu client. Sensu checks allow you to monitor server resources, services, and application health, as well as collect & analyze metrics; they are executed on servers running the Sensu client. \n\n首先安装check插件\n\n```shell\nsensu-install -p process-checks\t\nsensu-install -p cpu-checks\n```\n\n插件是ruby脚本，安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。\n\n[github插件脚本](https://github.com/sensu-plugins/sensu-plugins-process-checks)\n\n配置check 服务端路径 /etc/sensu/conf.d/\n\n检查sensu进程个数 check_cron.json\n\n```shell\n{\n  \"checks\": {\n    \"cron\": {\n      \"command\": \"check-process.rb -p cron\",\n      \"standalone\": true,\n      \"subscribers\": [\n        \"production\"\n      ],\n      \"interval\": 60\n    }\n  }\n}\n```\n\n收集cpu指标 metrics_cpu.json\n\n```\n{\n  \"checks\": {\n    \"cpu_metrics\": {\n      \"type\": \"metric\",\n      \"command\": \"metrics-cpu.rb\",\n      \"subscribers\": [\n        \"production\"\n      ],\n      \"interval\": 10,\n      \"handler\": \"tcp_socket\"\n    }\n  }\n}\n\n```\n\n其中 \"standalone\": true 表示允许client 单独调度运行，不需要server 调度。\"type\": \"metric\" 表明这是指标类型的采集。\n\n在/var/log/sensu/sensu-client.log 、sensu-server.log、HTTP API 可以看到执行结果。后续可再对结果进行处理，需借助另外的插件[**sensu-plugins-graphite**](https://github.com/sensu-plugins/sensu-plugins-graphite) . \n\n*采集一个指标展示，真累。。。*\n\n接着通过redis查看cpu指标数据\n\n```shell\nredis-cli\nkeys * \nget result:tick-client:cpu_metrics\n\"{\\\"type\\\":\\\"metric\\\",\\\"command\\\":\\\"metrics-cpu.rb\\\",\\\"subscribers\\\":[\\\"production\\\"],\\\"interval\\\":10,\\\"handler\\\":\\\"tcp_socket\\\",\\\"standalone\\\":true,\\\"name\\\":\\\"cpu_metrics\\\",\\\"issued\\\":1524824239,\\\"executed\\\":1524824239,\\\"duration\\\":0.073,\\\"output\\\":\\\"tick.cpu.total.user 8057 1524824240\\\\n...\\\",\\\"status\\\":0}\"\n```\n\n\n\n也可以直接到脚本安装路径，运行ruby脚本，直接看看采集结果\n\n```shell\n[root@tick bin]# /opt/sensu/embedded/bin/ruby  check-cpu.rb\nCheckCPU TOTAL OK: total=0.25 user=0.0 nice=0.0 system=0.25 idle=99.75 iowait=0.0 irq=0.0 softirq=0.0 steal=0.0 guest=0.0 guest_nice=0.0\n```\n\n\n\n### Sensu data output\n\nMetric collection checks are used to collect measurements from server resources, services, and applications. Metric collection checks can output metric data in a variety of metric formats:\n\n- [Graphite plaintext](http://graphite.readthedocs.org/en/latest/feeding-carbon.html#the-plaintext-protocol)\n- [Nagios Performance Data](http://nagios.sourceforge.net/docs/3_0/perfdata.html)\n- [OpenTSDB](http://opentsdb.net/docs/build/html/user_guide/writing.html)\n- [Metrics 2.0 wire format](http://metrics20.org/spec/)\n\nThe output produced by the check `command` ，貌似不同的插件返回不同的结果集。\n\n\n\n### Sensu event processor\n\nThe Sensu server provides a scalable event processor. Event processing involves conversion of [check results](https://sensuapp.org/docs/latest/reference/checks.html#check-results) into Sensu events, and then applying any defined [event filters](https://sensuapp.org/docs/latest/reference/filters.html), [event data mutators](https://sensuapp.org/docs/latest/reference/mutators.html), and [event handlers](https://sensuapp.org/docs/latest/reference/handlers.html). All event processing happens on a Sensu server system.\n\n\n\n### Sensu event handlers\n\nSensu event handlers are for taking action on [events](https://sensuapp.org/docs/latest/reference/events.html) (produced by check results), such as sending an email alert, creating or resolving a PagerDuty incident, or storing metrics in Graphite. There are several types of handlers: `pipe`, `tcp`, `udp`, `transport`, and `set`.\n\n- **Pipe handlers** execute a command and pass the event data to the created process via `STDIN`.\n- **TCP and UDP handlers** send the event data to a remote socket.\n- **Transport handlers** publish the event data to the Sensu transport (by default, this is RabbitMQ).\n- **Set handlers** are used to group event handlers, making it easier to manage many event handlers.\n\n类似于告警。\n\n这里使用TCP handlers 作为验证，需安装nc 命令。开启两个终端，分别运行以下命令，一个是作为server端，监听6000端口，一个是客户端，往监听端口发送数据。\n\n```shell\n nc -l -k -4 -p 6000      \n echo \"testing\" | nc localhost 6000\n```\n\n新建TCP 配置文件 /etc/sensu/conf.d/tcp_socket.json\n\n```sh\n{\n  \"handlers\": {\n    \"tcp_socket\": {\n      \"type\": \"tcp\",\n      \"socket\": {\n        \"host\": \"localhost\",\n        \"port\": 6000\n      }\n    }\n  }\n}\n```\n\n注意，需修改对应的check 配置，把handler 修改为 *tcp_socket*  \n\n例如，cron 进程检测的异常情况，即进程不存在![Check Error Event](/img/check-error-event.png)\n\n\n\n### Sensu API\n\n常用的API \n\n```shell\ncurl -s http://127.0.0.1:4567/clients | jq .\ncurl -s http://localhost:4567/events | jq .\ncurl -s http://localhost:4567/results | jq .\ncurl -s http://localhost:4567/client | jq .\n```\n\n\n\n## 3.关注事项\n\n1. 数据收集方式（Pull、Push）   \n\n   默认都是Push，由Client发送采集数据到transport，服务端再去transport 读取数据。\n\n2. 数据格式\n\n   check-result-cpu.json\n\n3. 数据存储方式\n\n   数据存储在transport 中，可以固化到文件系统\n\n4. 数据输出方式\n\n   checks 返回的结果是有一定格式的，其中，output字段存储的是对应的实际插件执行的命令输出结果。不同插件返回的命令结果不同。\n\n5. agent 部署方式\n\n   并未提供部署方案。\n\n6. 任务下发方式\n\n   客户端配置任务。无法从通过sensu-server直接下发到客户端。","source":"_posts/sensu.md","raw":"---\ntitle: Sensu 监控体系介绍\ndate: 2018-03-27 12:51:23\ntags: \n - Sensu\n - Ruby\ncategories: 技术\n---\n\n## 1.Sensu 安装部署\n\n### 主要特性\n\n[首页介绍](https://sensuapp.org/docs/1.2/overview/what-is-sensu.html)\n\nSensu was designed to provide a comprehensive monitoring platform for monitoring infrastructure (servers), services, application health, and business KPIs — and to collect and analyze custom metrics. \n\n主要包含以下功能与特性：\n\n- 检查系统、服务和程序的运行状态。\n- 基于分布式的设计，能够轻松的动态伸缩规模。\n- 支持通过插件的形式自定义检查的内容，拥有丰富的插件库。\n- 收集信息，获取被监控节点上的各项数据指标等。\n- 可视化的操作界面，提供实时的 GUI 用于显示和操作相关信息。\n- 内置的集成工具，可用于和其它系统集成，如 PagerDuty、Graphite、Email 等。\n- 提供丰富的 API 接口，支持通过 API 调用访问事件和客户端信息，触发检测等。\n- 加密的安全通信，支持各种复杂的网络拓扑。\n\n包括有类似我们拨测的功能，可对服务可用性进行检查，例如指定页面进行访问。\n\n结合其他软件：Sensu 从监控节点获取数据，将数据格式化成 Graphite 要求的格式，然后通过调用 Graphite 的接口将数据发给 Graphite。Graphite 将数据存储在时序数据中供 Grafana 绘图使用。最终用户通过在 Grafana 中[定制](http://www.liuhaihua.cn/archives/tag/private)需要显示的数据及显示的方式，获得最终的可视化图表。\n\n------\n\n### 架构\n\nSensu 由服务器、客户端、RabbitMQ、Redis 和 API 这五个部分构成。图 1 展示了这些组件之间的关系以及通信的数据流。如图所示，RabbitMQ 用于组件之间的通信，Redis 用于持久化 Sensu 服务器和 Sensu API 的数据。因为客户端都是通过文件进行配置，并且不需要在服务器端配置客户端的信息，所以可以很轻易的增加和减少客户端的数量。由于 Sensu 的服务器和 API 原生支持多节点部署，所以不存在效率的瓶颈问题。从图中可以看到，为了解耦服务器和客户端，通信都是通过 RabbitMQ 进行的。\n\n![组成部分](/img/sensu组成部分.png)\n\n核心代码由Ruby编写。[Github地址](https://github.com/sensu/sensu)\n\n实际安装中，不一定要使用RabbitMq作为消息中间件。直接使用redis即可。以下安装使用redis。\n\n<!-- more -->\n\n### 安装部署\n\nserver/clent 支持平台有\n\n![支持平台](/img/sensu-support-platforms.png)\n\n\n\nServer安装部署：\n\n安装配置yum源 /etc/yum.repos.d/sensu.repo\n\n```shell\n[sensu]\nname=sensu\nbaseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/\ngpgcheck=0\nenabled=1\n```\n\n```shell\nyum install redis -y\nyum install sensu -y\n```\n\nsensu server 配置 /etc/sensu/config.json\n\n```\n{\n  \"transport\": {\n    \"name\": \"redis\"\n  },\n  \"api\": {\n    \"host\": \"127.0.0.1\",\n    \"port\": 4567\n  }\n}\n```\n\nsensu client/server配置transport.redis\n\n```shell\n{\n  \"redis\":\n    {\n       \"host\": \"127.0.0.1\",\n       \"port\": 6379\n    }\n}\n```\n\nsensu client 配置 /etc/sensu/conf.d/client.json\n\n```\n{\n  \"client\": {\n    \"name\": \"rhel-client\",\n    \"address\": \"127.0.0.1\",\n    \"environment\": \"development\",\n    \"subscriptions\": [\n      \"dev\",\n      \"rhel-hosts\"\n    ],\n    \"socket\": {\n      \"bind\": \"127.0.0.1\",\n      \"port\": 3030\n    }\n  }\n｝\n```\n\nsensu dashboard配置 /etc/sensu/dashboard.json\n\n```\n{\n  \"sensu\": [\n    {\n      \"name\": \"sensu\",\n      \"host\": \"127.0.0.1\",\n      \"port\": 4567\n    }\n  ],\n  \"dashboard\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 3000\n  }\n}\n```\n\n启动进程\n\n```shell\nsystemctl enable sensu-{server,api,client} \nsystemctl start sensu-{server,api,client}\nsystemctl restart sensu-{server,api,client}\n```\n\nuchiwa 图形展示界面，需要额外安装。sensu提供了两个版本的展示界面，一个是企业版，一个就是uchiwa 。这里使用uchiwa，[下载链接](https://uchiwa.io/#/download)。 下载完成后，使用yum命令安装\n\n```\nyum -y localinstall uchiwa-1.1.1-1.x86_64.rpm\nsystemctl enable uchiwa\nsystemctl start uchiwa\n```\n\n配置好 uchiwa  /etc/sensu/uchiwa.json\n\n```shell\n{\n  \"sensu\": [\n    {\n      \"name\": \"Sensu-Server-1\",\n      \"host\": \"127.0.0.1\",\n      \"port\": 4567,\n      \"timeout\": 10\n    }\n  ],\n  \"uchiwa\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 3000,\n    \"refresh\": 10\n  }\n}\n```\n\n[URL](http://192.168.14.165:3000)\n\n![图例](/img/uchiwa.png)\n\n\n\nuchiwa 只是简单的展示功能，并不能对client等进行增删操作，即相当于对Sensu-API 只实现了Get相关的功能\n\n[HTTP API用例](https://sensuapp.org/docs/1.2/api/overview.html)\n\n### 部署过程中遇到的问题\n\n- uchiwa无法展示client和server，大部分都是json配置文件没有配置清楚导致。可查看日志/var/log/uchiwa，/var/log/sensu/sensu-client.log\n\n\n\n## 2.Sensu 使用\n\n### Sensu Client\n\nSensu Client 就是采集客户端agent。\n\n[介绍博文](https://blog.csdn.net/houzhe_adore/article/details/48518825)\n\n### Proxy Clients\n\n\n\n### Sensu Check\n\nSensu checks allow you to monitor server resources, services, and application health, as well as collect & analyze metrics; they are executed on servers running the Sensu client. Sensu checks allow you to monitor server resources, services, and application health, as well as collect & analyze metrics; they are executed on servers running the Sensu client. \n\n首先安装check插件\n\n```shell\nsensu-install -p process-checks\t\nsensu-install -p cpu-checks\n```\n\n插件是ruby脚本，安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。\n\n[github插件脚本](https://github.com/sensu-plugins/sensu-plugins-process-checks)\n\n配置check 服务端路径 /etc/sensu/conf.d/\n\n检查sensu进程个数 check_cron.json\n\n```shell\n{\n  \"checks\": {\n    \"cron\": {\n      \"command\": \"check-process.rb -p cron\",\n      \"standalone\": true,\n      \"subscribers\": [\n        \"production\"\n      ],\n      \"interval\": 60\n    }\n  }\n}\n```\n\n收集cpu指标 metrics_cpu.json\n\n```\n{\n  \"checks\": {\n    \"cpu_metrics\": {\n      \"type\": \"metric\",\n      \"command\": \"metrics-cpu.rb\",\n      \"subscribers\": [\n        \"production\"\n      ],\n      \"interval\": 10,\n      \"handler\": \"tcp_socket\"\n    }\n  }\n}\n\n```\n\n其中 \"standalone\": true 表示允许client 单独调度运行，不需要server 调度。\"type\": \"metric\" 表明这是指标类型的采集。\n\n在/var/log/sensu/sensu-client.log 、sensu-server.log、HTTP API 可以看到执行结果。后续可再对结果进行处理，需借助另外的插件[**sensu-plugins-graphite**](https://github.com/sensu-plugins/sensu-plugins-graphite) . \n\n*采集一个指标展示，真累。。。*\n\n接着通过redis查看cpu指标数据\n\n```shell\nredis-cli\nkeys * \nget result:tick-client:cpu_metrics\n\"{\\\"type\\\":\\\"metric\\\",\\\"command\\\":\\\"metrics-cpu.rb\\\",\\\"subscribers\\\":[\\\"production\\\"],\\\"interval\\\":10,\\\"handler\\\":\\\"tcp_socket\\\",\\\"standalone\\\":true,\\\"name\\\":\\\"cpu_metrics\\\",\\\"issued\\\":1524824239,\\\"executed\\\":1524824239,\\\"duration\\\":0.073,\\\"output\\\":\\\"tick.cpu.total.user 8057 1524824240\\\\n...\\\",\\\"status\\\":0}\"\n```\n\n\n\n也可以直接到脚本安装路径，运行ruby脚本，直接看看采集结果\n\n```shell\n[root@tick bin]# /opt/sensu/embedded/bin/ruby  check-cpu.rb\nCheckCPU TOTAL OK: total=0.25 user=0.0 nice=0.0 system=0.25 idle=99.75 iowait=0.0 irq=0.0 softirq=0.0 steal=0.0 guest=0.0 guest_nice=0.0\n```\n\n\n\n### Sensu data output\n\nMetric collection checks are used to collect measurements from server resources, services, and applications. Metric collection checks can output metric data in a variety of metric formats:\n\n- [Graphite plaintext](http://graphite.readthedocs.org/en/latest/feeding-carbon.html#the-plaintext-protocol)\n- [Nagios Performance Data](http://nagios.sourceforge.net/docs/3_0/perfdata.html)\n- [OpenTSDB](http://opentsdb.net/docs/build/html/user_guide/writing.html)\n- [Metrics 2.0 wire format](http://metrics20.org/spec/)\n\nThe output produced by the check `command` ，貌似不同的插件返回不同的结果集。\n\n\n\n### Sensu event processor\n\nThe Sensu server provides a scalable event processor. Event processing involves conversion of [check results](https://sensuapp.org/docs/latest/reference/checks.html#check-results) into Sensu events, and then applying any defined [event filters](https://sensuapp.org/docs/latest/reference/filters.html), [event data mutators](https://sensuapp.org/docs/latest/reference/mutators.html), and [event handlers](https://sensuapp.org/docs/latest/reference/handlers.html). All event processing happens on a Sensu server system.\n\n\n\n### Sensu event handlers\n\nSensu event handlers are for taking action on [events](https://sensuapp.org/docs/latest/reference/events.html) (produced by check results), such as sending an email alert, creating or resolving a PagerDuty incident, or storing metrics in Graphite. There are several types of handlers: `pipe`, `tcp`, `udp`, `transport`, and `set`.\n\n- **Pipe handlers** execute a command and pass the event data to the created process via `STDIN`.\n- **TCP and UDP handlers** send the event data to a remote socket.\n- **Transport handlers** publish the event data to the Sensu transport (by default, this is RabbitMQ).\n- **Set handlers** are used to group event handlers, making it easier to manage many event handlers.\n\n类似于告警。\n\n这里使用TCP handlers 作为验证，需安装nc 命令。开启两个终端，分别运行以下命令，一个是作为server端，监听6000端口，一个是客户端，往监听端口发送数据。\n\n```shell\n nc -l -k -4 -p 6000      \n echo \"testing\" | nc localhost 6000\n```\n\n新建TCP 配置文件 /etc/sensu/conf.d/tcp_socket.json\n\n```sh\n{\n  \"handlers\": {\n    \"tcp_socket\": {\n      \"type\": \"tcp\",\n      \"socket\": {\n        \"host\": \"localhost\",\n        \"port\": 6000\n      }\n    }\n  }\n}\n```\n\n注意，需修改对应的check 配置，把handler 修改为 *tcp_socket*  \n\n例如，cron 进程检测的异常情况，即进程不存在![Check Error Event](/img/check-error-event.png)\n\n\n\n### Sensu API\n\n常用的API \n\n```shell\ncurl -s http://127.0.0.1:4567/clients | jq .\ncurl -s http://localhost:4567/events | jq .\ncurl -s http://localhost:4567/results | jq .\ncurl -s http://localhost:4567/client | jq .\n```\n\n\n\n## 3.关注事项\n\n1. 数据收集方式（Pull、Push）   \n\n   默认都是Push，由Client发送采集数据到transport，服务端再去transport 读取数据。\n\n2. 数据格式\n\n   check-result-cpu.json\n\n3. 数据存储方式\n\n   数据存储在transport 中，可以固化到文件系统\n\n4. 数据输出方式\n\n   checks 返回的结果是有一定格式的，其中，output字段存储的是对应的实际插件执行的命令输出结果。不同插件返回的命令结果不同。\n\n5. agent 部署方式\n\n   并未提供部署方案。\n\n6. 任务下发方式\n\n   客户端配置任务。无法从通过sensu-server直接下发到客户端。","slug":"sensu","published":1,"updated":"2018-04-27T05:02:06.550Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczpc0019e4rwe273vqqw","content":"<h2 id=\"1-Sensu-安装部署\"><a href=\"#1-Sensu-安装部署\" class=\"headerlink\" title=\"1.Sensu 安装部署\"></a>1.Sensu 安装部署</h2><h3 id=\"主要特性\"><a href=\"#主要特性\" class=\"headerlink\" title=\"主要特性\"></a>主要特性</h3><p><a href=\"https://sensuapp.org/docs/1.2/overview/what-is-sensu.html\" target=\"_blank\" rel=\"external\">首页介绍</a></p>\n<p>Sensu was designed to provide a comprehensive monitoring platform for monitoring infrastructure (servers), services, application health, and business KPIs — and to collect and analyze custom metrics. </p>\n<p>主要包含以下功能与特性：</p>\n<ul>\n<li>检查系统、服务和程序的运行状态。</li>\n<li>基于分布式的设计，能够轻松的动态伸缩规模。</li>\n<li>支持通过插件的形式自定义检查的内容，拥有丰富的插件库。</li>\n<li>收集信息，获取被监控节点上的各项数据指标等。</li>\n<li>可视化的操作界面，提供实时的 GUI 用于显示和操作相关信息。</li>\n<li>内置的集成工具，可用于和其它系统集成，如 PagerDuty、Graphite、Email 等。</li>\n<li>提供丰富的 API 接口，支持通过 API 调用访问事件和客户端信息，触发检测等。</li>\n<li>加密的安全通信，支持各种复杂的网络拓扑。</li>\n</ul>\n<p>包括有类似我们拨测的功能，可对服务可用性进行检查，例如指定页面进行访问。</p>\n<p>结合其他软件：Sensu 从监控节点获取数据，将数据格式化成 Graphite 要求的格式，然后通过调用 Graphite 的接口将数据发给 Graphite。Graphite 将数据存储在时序数据中供 Grafana 绘图使用。最终用户通过在 Grafana 中<a href=\"http://www.liuhaihua.cn/archives/tag/private\" target=\"_blank\" rel=\"external\">定制</a>需要显示的数据及显示的方式，获得最终的可视化图表。</p>\n<hr>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><p>Sensu 由服务器、客户端、RabbitMQ、Redis 和 API 这五个部分构成。图 1 展示了这些组件之间的关系以及通信的数据流。如图所示，RabbitMQ 用于组件之间的通信，Redis 用于持久化 Sensu 服务器和 Sensu API 的数据。因为客户端都是通过文件进行配置，并且不需要在服务器端配置客户端的信息，所以可以很轻易的增加和减少客户端的数量。由于 Sensu 的服务器和 API 原生支持多节点部署，所以不存在效率的瓶颈问题。从图中可以看到，为了解耦服务器和客户端，通信都是通过 RabbitMQ 进行的。</p>\n<p><img src=\"/img/sensu组成部分.png\" alt=\"组成部分\"></p>\n<p>核心代码由Ruby编写。<a href=\"https://github.com/sensu/sensu\" target=\"_blank\" rel=\"external\">Github地址</a></p>\n<p>实际安装中，不一定要使用RabbitMq作为消息中间件。直接使用redis即可。以下安装使用redis。</p>\n<a id=\"more\"></a>\n<h3 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h3><p>server/clent 支持平台有</p>\n<p><img src=\"/img/sensu-support-platforms.png\" alt=\"支持平台\"></p>\n<p>Server安装部署：</p>\n<p>安装配置yum源 /etc/yum.repos.d/sensu.repo</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">[sensu]</div><div class=\"line\">name=sensu</div><div class=\"line\">baseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/</div><div class=\"line\">gpgcheck=0</div><div class=\"line\">enabled=1</div></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install redis -y</div><div class=\"line\">yum install sensu -y</div></pre></td></tr></table></figure>\n<p>sensu server 配置 /etc/sensu/config.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;transport&quot;: &#123;</div><div class=\"line\">    &quot;name&quot;: &quot;redis&quot;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  &quot;api&quot;: &#123;</div><div class=\"line\">    &quot;host&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">    &quot;port&quot;: 4567</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>sensu client/server配置transport.redis</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  \"redis\":</div><div class=\"line\">    &#123;</div><div class=\"line\">       \"host\": \"127.0.0.1\",</div><div class=\"line\">       \"port\": 6379</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>sensu client 配置 /etc/sensu/conf.d/client.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;client&quot;: &#123;</div><div class=\"line\">    &quot;name&quot;: &quot;rhel-client&quot;,</div><div class=\"line\">    &quot;address&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">    &quot;environment&quot;: &quot;development&quot;,</div><div class=\"line\">    &quot;subscriptions&quot;: [</div><div class=\"line\">      &quot;dev&quot;,</div><div class=\"line\">      &quot;rhel-hosts&quot;</div><div class=\"line\">    ],</div><div class=\"line\">    &quot;socket&quot;: &#123;</div><div class=\"line\">      &quot;bind&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">      &quot;port&quot;: 3030</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">｝</div></pre></td></tr></table></figure>\n<p>sensu dashboard配置 /etc/sensu/dashboard.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;sensu&quot;: [</div><div class=\"line\">    &#123;</div><div class=\"line\">      &quot;name&quot;: &quot;sensu&quot;,</div><div class=\"line\">      &quot;host&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">      &quot;port&quot;: 4567</div><div class=\"line\">    &#125;</div><div class=\"line\">  ],</div><div class=\"line\">  &quot;dashboard&quot;: &#123;</div><div class=\"line\">    &quot;host&quot;: &quot;0.0.0.0&quot;,</div><div class=\"line\">    &quot;port&quot;: 3000</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>启动进程</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl enable sensu-&#123;server,api,client&#125; </div><div class=\"line\">systemctl start sensu-&#123;server,api,client&#125;</div><div class=\"line\">systemctl restart sensu-&#123;server,api,client&#125;</div></pre></td></tr></table></figure>\n<p>uchiwa 图形展示界面，需要额外安装。sensu提供了两个版本的展示界面，一个是企业版，一个就是uchiwa 。这里使用uchiwa，<a href=\"https://uchiwa.io/#/download\" target=\"_blank\" rel=\"external\">下载链接</a>。 下载完成后，使用yum命令安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum -y localinstall uchiwa-1.1.1-1.x86_64.rpm</div><div class=\"line\">systemctl enable uchiwa</div><div class=\"line\">systemctl start uchiwa</div></pre></td></tr></table></figure>\n<p>配置好 uchiwa  /etc/sensu/uchiwa.json</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  \"sensu\": [</div><div class=\"line\">    &#123;</div><div class=\"line\">      \"name\": \"Sensu-Server-1\",</div><div class=\"line\">      \"host\": \"127.0.0.1\",</div><div class=\"line\">      \"port\": 4567,</div><div class=\"line\">      \"timeout\": 10</div><div class=\"line\">    &#125;</div><div class=\"line\">  ],</div><div class=\"line\">  \"uchiwa\": &#123;</div><div class=\"line\">    \"host\": \"0.0.0.0\",</div><div class=\"line\">    \"port\": 3000,</div><div class=\"line\">    \"refresh\": 10</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><a href=\"http://192.168.14.165:3000\" target=\"_blank\" rel=\"external\">URL</a></p>\n<p><img src=\"/img/uchiwa.png\" alt=\"图例\"></p>\n<p>uchiwa 只是简单的展示功能，并不能对client等进行增删操作，即相当于对Sensu-API 只实现了Get相关的功能</p>\n<p><a href=\"https://sensuapp.org/docs/1.2/api/overview.html\" target=\"_blank\" rel=\"external\">HTTP API用例</a></p>\n<h3 id=\"部署过程中遇到的问题\"><a href=\"#部署过程中遇到的问题\" class=\"headerlink\" title=\"部署过程中遇到的问题\"></a>部署过程中遇到的问题</h3><ul>\n<li>uchiwa无法展示client和server，大部分都是json配置文件没有配置清楚导致。可查看日志/var/log/uchiwa，/var/log/sensu/sensu-client.log</li>\n</ul>\n<h2 id=\"2-Sensu-使用\"><a href=\"#2-Sensu-使用\" class=\"headerlink\" title=\"2.Sensu 使用\"></a>2.Sensu 使用</h2><h3 id=\"Sensu-Client\"><a href=\"#Sensu-Client\" class=\"headerlink\" title=\"Sensu Client\"></a>Sensu Client</h3><p>Sensu Client 就是采集客户端agent。</p>\n<p><a href=\"https://blog.csdn.net/houzhe_adore/article/details/48518825\" target=\"_blank\" rel=\"external\">介绍博文</a></p>\n<h3 id=\"Proxy-Clients\"><a href=\"#Proxy-Clients\" class=\"headerlink\" title=\"Proxy Clients\"></a>Proxy Clients</h3><h3 id=\"Sensu-Check\"><a href=\"#Sensu-Check\" class=\"headerlink\" title=\"Sensu Check\"></a>Sensu Check</h3><p>Sensu checks allow you to monitor server resources, services, and application health, as well as collect &amp; analyze metrics; they are executed on servers running the Sensu client. Sensu checks allow you to monitor server resources, services, and application health, as well as collect &amp; analyze metrics; they are executed on servers running the Sensu client. </p>\n<p>首先安装check插件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">sensu-install -p process-checks\t</div><div class=\"line\">sensu-install -p cpu-checks</div></pre></td></tr></table></figure>\n<p>插件是ruby脚本，安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。</p>\n<p><a href=\"https://github.com/sensu-plugins/sensu-plugins-process-checks\" target=\"_blank\" rel=\"external\">github插件脚本</a></p>\n<p>配置check 服务端路径 /etc/sensu/conf.d/</p>\n<p>检查sensu进程个数 check_cron.json</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  \"checks\": &#123;</div><div class=\"line\">    \"cron\": &#123;</div><div class=\"line\">      \"command\": \"check-process.rb -p cron\",</div><div class=\"line\">      \"standalone\": true,</div><div class=\"line\">      \"subscribers\": [</div><div class=\"line\">        \"production\"</div><div class=\"line\">      ],</div><div class=\"line\">      \"interval\": 60</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>收集cpu指标 metrics_cpu.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;checks&quot;: &#123;</div><div class=\"line\">    &quot;cpu_metrics&quot;: &#123;</div><div class=\"line\">      &quot;type&quot;: &quot;metric&quot;,</div><div class=\"line\">      &quot;command&quot;: &quot;metrics-cpu.rb&quot;,</div><div class=\"line\">      &quot;subscribers&quot;: [</div><div class=\"line\">        &quot;production&quot;</div><div class=\"line\">      ],</div><div class=\"line\">      &quot;interval&quot;: 10,</div><div class=\"line\">      &quot;handler&quot;: &quot;tcp_socket&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>其中 “standalone”: true 表示允许client 单独调度运行，不需要server 调度。”type”: “metric” 表明这是指标类型的采集。</p>\n<p>在/var/log/sensu/sensu-client.log 、sensu-server.log、HTTP API 可以看到执行结果。后续可再对结果进行处理，需借助另外的插件<a href=\"https://github.com/sensu-plugins/sensu-plugins-graphite\" target=\"_blank\" rel=\"external\"><strong>sensu-plugins-graphite</strong></a> . </p>\n<p><em>采集一个指标展示，真累。。。</em></p>\n<p>接着通过redis查看cpu指标数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">redis-cli</div><div class=\"line\">keys * </div><div class=\"line\">get result:tick-client:cpu_metrics</div><div class=\"line\">\"&#123;\\\"type\\\":\\\"metric\\\",\\\"command\\\":\\\"metrics-cpu.rb\\\",\\\"subscribers\\\":[\\\"production\\\"],\\\"interval\\\":10,\\\"handler\\\":\\\"tcp_socket\\\",\\\"standalone\\\":true,\\\"name\\\":\\\"cpu_metrics\\\",\\\"issued\\\":1524824239,\\\"executed\\\":1524824239,\\\"duration\\\":0.073,\\\"output\\\":\\\"tick.cpu.total.user 8057 1524824240\\\\n...\\\",\\\"status\\\":0&#125;\"</div></pre></td></tr></table></figure>\n<p>也可以直接到脚本安装路径，运行ruby脚本，直接看看采集结果</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@tick bin]# /opt/sensu/embedded/bin/ruby  check-cpu.rb</div><div class=\"line\">CheckCPU TOTAL OK: total=0.25 user=0.0 nice=0.0 system=0.25 idle=99.75 iowait=0.0 irq=0.0 softirq=0.0 steal=0.0 guest=0.0 guest_nice=0.0</div></pre></td></tr></table></figure>\n<h3 id=\"Sensu-data-output\"><a href=\"#Sensu-data-output\" class=\"headerlink\" title=\"Sensu data output\"></a>Sensu data output</h3><p>Metric collection checks are used to collect measurements from server resources, services, and applications. Metric collection checks can output metric data in a variety of metric formats:</p>\n<ul>\n<li><a href=\"http://graphite.readthedocs.org/en/latest/feeding-carbon.html#the-plaintext-protocol\" target=\"_blank\" rel=\"external\">Graphite plaintext</a></li>\n<li><a href=\"http://nagios.sourceforge.net/docs/3_0/perfdata.html\" target=\"_blank\" rel=\"external\">Nagios Performance Data</a></li>\n<li><a href=\"http://opentsdb.net/docs/build/html/user_guide/writing.html\" target=\"_blank\" rel=\"external\">OpenTSDB</a></li>\n<li><a href=\"http://metrics20.org/spec/\" target=\"_blank\" rel=\"external\">Metrics 2.0 wire format</a></li>\n</ul>\n<p>The output produced by the check <code>command</code> ，貌似不同的插件返回不同的结果集。</p>\n<h3 id=\"Sensu-event-processor\"><a href=\"#Sensu-event-processor\" class=\"headerlink\" title=\"Sensu event processor\"></a>Sensu event processor</h3><p>The Sensu server provides a scalable event processor. Event processing involves conversion of <a href=\"https://sensuapp.org/docs/latest/reference/checks.html#check-results\" target=\"_blank\" rel=\"external\">check results</a> into Sensu events, and then applying any defined <a href=\"https://sensuapp.org/docs/latest/reference/filters.html\" target=\"_blank\" rel=\"external\">event filters</a>, <a href=\"https://sensuapp.org/docs/latest/reference/mutators.html\" target=\"_blank\" rel=\"external\">event data mutators</a>, and <a href=\"https://sensuapp.org/docs/latest/reference/handlers.html\" target=\"_blank\" rel=\"external\">event handlers</a>. All event processing happens on a Sensu server system.</p>\n<h3 id=\"Sensu-event-handlers\"><a href=\"#Sensu-event-handlers\" class=\"headerlink\" title=\"Sensu event handlers\"></a>Sensu event handlers</h3><p>Sensu event handlers are for taking action on <a href=\"https://sensuapp.org/docs/latest/reference/events.html\" target=\"_blank\" rel=\"external\">events</a> (produced by check results), such as sending an email alert, creating or resolving a PagerDuty incident, or storing metrics in Graphite. There are several types of handlers: <code>pipe</code>, <code>tcp</code>, <code>udp</code>, <code>transport</code>, and <code>set</code>.</p>\n<ul>\n<li><strong>Pipe handlers</strong> execute a command and pass the event data to the created process via <code>STDIN</code>.</li>\n<li><strong>TCP and UDP handlers</strong> send the event data to a remote socket.</li>\n<li><strong>Transport handlers</strong> publish the event data to the Sensu transport (by default, this is RabbitMQ).</li>\n<li><strong>Set handlers</strong> are used to group event handlers, making it easier to manage many event handlers.</li>\n</ul>\n<p>类似于告警。</p>\n<p>这里使用TCP handlers 作为验证，需安装nc 命令。开启两个终端，分别运行以下命令，一个是作为server端，监听6000端口，一个是客户端，往监听端口发送数据。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">nc -l -k -4 -p 6000      </div><div class=\"line\">echo \"testing\" | nc localhost 6000</div></pre></td></tr></table></figure>\n<p>新建TCP 配置文件 /etc/sensu/conf.d/tcp_socket.json</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"string\">\"handlers\"</span>: &#123;</div><div class=\"line\">    <span class=\"string\">\"tcp_socket\"</span>: &#123;</div><div class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"tcp\"</span>,</div><div class=\"line\">      <span class=\"string\">\"socket\"</span>: &#123;</div><div class=\"line\">        <span class=\"string\">\"host\"</span>: <span class=\"string\">\"localhost\"</span>,</div><div class=\"line\">        <span class=\"string\">\"port\"</span>: 6000</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>注意，需修改对应的check 配置，把handler 修改为 <em>tcp_socket</em>  </p>\n<p>例如，cron 进程检测的异常情况，即进程不存在<img src=\"/img/check-error-event.png\" alt=\"Check Error Event\"></p>\n<h3 id=\"Sensu-API\"><a href=\"#Sensu-API\" class=\"headerlink\" title=\"Sensu API\"></a>Sensu API</h3><p>常用的API </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -s http://127.0.0.1:4567/clients | jq .</div><div class=\"line\">curl -s http://localhost:4567/events | jq .</div><div class=\"line\">curl -s http://localhost:4567/results | jq .</div><div class=\"line\">curl -s http://localhost:4567/client | jq .</div></pre></td></tr></table></figure>\n<h2 id=\"3-关注事项\"><a href=\"#3-关注事项\" class=\"headerlink\" title=\"3.关注事项\"></a>3.关注事项</h2><ol>\n<li><p>数据收集方式（Pull、Push）   </p>\n<p>默认都是Push，由Client发送采集数据到transport，服务端再去transport 读取数据。</p>\n</li>\n<li><p>数据格式</p>\n<p>check-result-cpu.json</p>\n</li>\n<li><p>数据存储方式</p>\n<p>数据存储在transport 中，可以固化到文件系统</p>\n</li>\n<li><p>数据输出方式</p>\n<p>checks 返回的结果是有一定格式的，其中，output字段存储的是对应的实际插件执行的命令输出结果。不同插件返回的命令结果不同。</p>\n</li>\n<li><p>agent 部署方式</p>\n<p>并未提供部署方案。</p>\n</li>\n<li><p>任务下发方式</p>\n<p>客户端配置任务。无法从通过sensu-server直接下发到客户端。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-Sensu-安装部署\"><a href=\"#1-Sensu-安装部署\" class=\"headerlink\" title=\"1.Sensu 安装部署\"></a>1.Sensu 安装部署</h2><h3 id=\"主要特性\"><a href=\"#主要特性\" class=\"headerlink\" title=\"主要特性\"></a>主要特性</h3><p><a href=\"https://sensuapp.org/docs/1.2/overview/what-is-sensu.html\" target=\"_blank\" rel=\"external\">首页介绍</a></p>\n<p>Sensu was designed to provide a comprehensive monitoring platform for monitoring infrastructure (servers), services, application health, and business KPIs — and to collect and analyze custom metrics. </p>\n<p>主要包含以下功能与特性：</p>\n<ul>\n<li>检查系统、服务和程序的运行状态。</li>\n<li>基于分布式的设计，能够轻松的动态伸缩规模。</li>\n<li>支持通过插件的形式自定义检查的内容，拥有丰富的插件库。</li>\n<li>收集信息，获取被监控节点上的各项数据指标等。</li>\n<li>可视化的操作界面，提供实时的 GUI 用于显示和操作相关信息。</li>\n<li>内置的集成工具，可用于和其它系统集成，如 PagerDuty、Graphite、Email 等。</li>\n<li>提供丰富的 API 接口，支持通过 API 调用访问事件和客户端信息，触发检测等。</li>\n<li>加密的安全通信，支持各种复杂的网络拓扑。</li>\n</ul>\n<p>包括有类似我们拨测的功能，可对服务可用性进行检查，例如指定页面进行访问。</p>\n<p>结合其他软件：Sensu 从监控节点获取数据，将数据格式化成 Graphite 要求的格式，然后通过调用 Graphite 的接口将数据发给 Graphite。Graphite 将数据存储在时序数据中供 Grafana 绘图使用。最终用户通过在 Grafana 中<a href=\"http://www.liuhaihua.cn/archives/tag/private\" target=\"_blank\" rel=\"external\">定制</a>需要显示的数据及显示的方式，获得最终的可视化图表。</p>\n<hr>\n<h3 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h3><p>Sensu 由服务器、客户端、RabbitMQ、Redis 和 API 这五个部分构成。图 1 展示了这些组件之间的关系以及通信的数据流。如图所示，RabbitMQ 用于组件之间的通信，Redis 用于持久化 Sensu 服务器和 Sensu API 的数据。因为客户端都是通过文件进行配置，并且不需要在服务器端配置客户端的信息，所以可以很轻易的增加和减少客户端的数量。由于 Sensu 的服务器和 API 原生支持多节点部署，所以不存在效率的瓶颈问题。从图中可以看到，为了解耦服务器和客户端，通信都是通过 RabbitMQ 进行的。</p>\n<p><img src=\"/img/sensu组成部分.png\" alt=\"组成部分\"></p>\n<p>核心代码由Ruby编写。<a href=\"https://github.com/sensu/sensu\" target=\"_blank\" rel=\"external\">Github地址</a></p>\n<p>实际安装中，不一定要使用RabbitMq作为消息中间件。直接使用redis即可。以下安装使用redis。</p>","more":"<h3 id=\"安装部署\"><a href=\"#安装部署\" class=\"headerlink\" title=\"安装部署\"></a>安装部署</h3><p>server/clent 支持平台有</p>\n<p><img src=\"/img/sensu-support-platforms.png\" alt=\"支持平台\"></p>\n<p>Server安装部署：</p>\n<p>安装配置yum源 /etc/yum.repos.d/sensu.repo</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">[sensu]</div><div class=\"line\">name=sensu</div><div class=\"line\">baseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/</div><div class=\"line\">gpgcheck=0</div><div class=\"line\">enabled=1</div></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install redis -y</div><div class=\"line\">yum install sensu -y</div></pre></td></tr></table></figure>\n<p>sensu server 配置 /etc/sensu/config.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;transport&quot;: &#123;</div><div class=\"line\">    &quot;name&quot;: &quot;redis&quot;</div><div class=\"line\">  &#125;,</div><div class=\"line\">  &quot;api&quot;: &#123;</div><div class=\"line\">    &quot;host&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">    &quot;port&quot;: 4567</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>sensu client/server配置transport.redis</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  \"redis\":</div><div class=\"line\">    &#123;</div><div class=\"line\">       \"host\": \"127.0.0.1\",</div><div class=\"line\">       \"port\": 6379</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>sensu client 配置 /etc/sensu/conf.d/client.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;client&quot;: &#123;</div><div class=\"line\">    &quot;name&quot;: &quot;rhel-client&quot;,</div><div class=\"line\">    &quot;address&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">    &quot;environment&quot;: &quot;development&quot;,</div><div class=\"line\">    &quot;subscriptions&quot;: [</div><div class=\"line\">      &quot;dev&quot;,</div><div class=\"line\">      &quot;rhel-hosts&quot;</div><div class=\"line\">    ],</div><div class=\"line\">    &quot;socket&quot;: &#123;</div><div class=\"line\">      &quot;bind&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">      &quot;port&quot;: 3030</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">｝</div></pre></td></tr></table></figure>\n<p>sensu dashboard配置 /etc/sensu/dashboard.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;sensu&quot;: [</div><div class=\"line\">    &#123;</div><div class=\"line\">      &quot;name&quot;: &quot;sensu&quot;,</div><div class=\"line\">      &quot;host&quot;: &quot;127.0.0.1&quot;,</div><div class=\"line\">      &quot;port&quot;: 4567</div><div class=\"line\">    &#125;</div><div class=\"line\">  ],</div><div class=\"line\">  &quot;dashboard&quot;: &#123;</div><div class=\"line\">    &quot;host&quot;: &quot;0.0.0.0&quot;,</div><div class=\"line\">    &quot;port&quot;: 3000</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>启动进程</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">systemctl enable sensu-&#123;server,api,client&#125; </div><div class=\"line\">systemctl start sensu-&#123;server,api,client&#125;</div><div class=\"line\">systemctl restart sensu-&#123;server,api,client&#125;</div></pre></td></tr></table></figure>\n<p>uchiwa 图形展示界面，需要额外安装。sensu提供了两个版本的展示界面，一个是企业版，一个就是uchiwa 。这里使用uchiwa，<a href=\"https://uchiwa.io/#/download\" target=\"_blank\" rel=\"external\">下载链接</a>。 下载完成后，使用yum命令安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum -y localinstall uchiwa-1.1.1-1.x86_64.rpm</div><div class=\"line\">systemctl enable uchiwa</div><div class=\"line\">systemctl start uchiwa</div></pre></td></tr></table></figure>\n<p>配置好 uchiwa  /etc/sensu/uchiwa.json</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  \"sensu\": [</div><div class=\"line\">    &#123;</div><div class=\"line\">      \"name\": \"Sensu-Server-1\",</div><div class=\"line\">      \"host\": \"127.0.0.1\",</div><div class=\"line\">      \"port\": 4567,</div><div class=\"line\">      \"timeout\": 10</div><div class=\"line\">    &#125;</div><div class=\"line\">  ],</div><div class=\"line\">  \"uchiwa\": &#123;</div><div class=\"line\">    \"host\": \"0.0.0.0\",</div><div class=\"line\">    \"port\": 3000,</div><div class=\"line\">    \"refresh\": 10</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><a href=\"http://192.168.14.165:3000\" target=\"_blank\" rel=\"external\">URL</a></p>\n<p><img src=\"/img/uchiwa.png\" alt=\"图例\"></p>\n<p>uchiwa 只是简单的展示功能，并不能对client等进行增删操作，即相当于对Sensu-API 只实现了Get相关的功能</p>\n<p><a href=\"https://sensuapp.org/docs/1.2/api/overview.html\" target=\"_blank\" rel=\"external\">HTTP API用例</a></p>\n<h3 id=\"部署过程中遇到的问题\"><a href=\"#部署过程中遇到的问题\" class=\"headerlink\" title=\"部署过程中遇到的问题\"></a>部署过程中遇到的问题</h3><ul>\n<li>uchiwa无法展示client和server，大部分都是json配置文件没有配置清楚导致。可查看日志/var/log/uchiwa，/var/log/sensu/sensu-client.log</li>\n</ul>\n<h2 id=\"2-Sensu-使用\"><a href=\"#2-Sensu-使用\" class=\"headerlink\" title=\"2.Sensu 使用\"></a>2.Sensu 使用</h2><h3 id=\"Sensu-Client\"><a href=\"#Sensu-Client\" class=\"headerlink\" title=\"Sensu Client\"></a>Sensu Client</h3><p>Sensu Client 就是采集客户端agent。</p>\n<p><a href=\"https://blog.csdn.net/houzhe_adore/article/details/48518825\" target=\"_blank\" rel=\"external\">介绍博文</a></p>\n<h3 id=\"Proxy-Clients\"><a href=\"#Proxy-Clients\" class=\"headerlink\" title=\"Proxy Clients\"></a>Proxy Clients</h3><h3 id=\"Sensu-Check\"><a href=\"#Sensu-Check\" class=\"headerlink\" title=\"Sensu Check\"></a>Sensu Check</h3><p>Sensu checks allow you to monitor server resources, services, and application health, as well as collect &amp; analyze metrics; they are executed on servers running the Sensu client. Sensu checks allow you to monitor server resources, services, and application health, as well as collect &amp; analyze metrics; they are executed on servers running the Sensu client. </p>\n<p>首先安装check插件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">sensu-install -p process-checks\t</div><div class=\"line\">sensu-install -p cpu-checks</div></pre></td></tr></table></figure>\n<p>插件是ruby脚本，安装后会在/opt/sensu/embedded/bin/ 路径下下载安装rubu解释器和check插件。process-checks 是进程检测插件，cpu-checks 是cpu检测指标插件。</p>\n<p><a href=\"https://github.com/sensu-plugins/sensu-plugins-process-checks\" target=\"_blank\" rel=\"external\">github插件脚本</a></p>\n<p>配置check 服务端路径 /etc/sensu/conf.d/</p>\n<p>检查sensu进程个数 check_cron.json</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  \"checks\": &#123;</div><div class=\"line\">    \"cron\": &#123;</div><div class=\"line\">      \"command\": \"check-process.rb -p cron\",</div><div class=\"line\">      \"standalone\": true,</div><div class=\"line\">      \"subscribers\": [</div><div class=\"line\">        \"production\"</div><div class=\"line\">      ],</div><div class=\"line\">      \"interval\": 60</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>收集cpu指标 metrics_cpu.json</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;checks&quot;: &#123;</div><div class=\"line\">    &quot;cpu_metrics&quot;: &#123;</div><div class=\"line\">      &quot;type&quot;: &quot;metric&quot;,</div><div class=\"line\">      &quot;command&quot;: &quot;metrics-cpu.rb&quot;,</div><div class=\"line\">      &quot;subscribers&quot;: [</div><div class=\"line\">        &quot;production&quot;</div><div class=\"line\">      ],</div><div class=\"line\">      &quot;interval&quot;: 10,</div><div class=\"line\">      &quot;handler&quot;: &quot;tcp_socket&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>其中 “standalone”: true 表示允许client 单独调度运行，不需要server 调度。”type”: “metric” 表明这是指标类型的采集。</p>\n<p>在/var/log/sensu/sensu-client.log 、sensu-server.log、HTTP API 可以看到执行结果。后续可再对结果进行处理，需借助另外的插件<a href=\"https://github.com/sensu-plugins/sensu-plugins-graphite\" target=\"_blank\" rel=\"external\"><strong>sensu-plugins-graphite</strong></a> . </p>\n<p><em>采集一个指标展示，真累。。。</em></p>\n<p>接着通过redis查看cpu指标数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">redis-cli</div><div class=\"line\">keys * </div><div class=\"line\">get result:tick-client:cpu_metrics</div><div class=\"line\">\"&#123;\\\"type\\\":\\\"metric\\\",\\\"command\\\":\\\"metrics-cpu.rb\\\",\\\"subscribers\\\":[\\\"production\\\"],\\\"interval\\\":10,\\\"handler\\\":\\\"tcp_socket\\\",\\\"standalone\\\":true,\\\"name\\\":\\\"cpu_metrics\\\",\\\"issued\\\":1524824239,\\\"executed\\\":1524824239,\\\"duration\\\":0.073,\\\"output\\\":\\\"tick.cpu.total.user 8057 1524824240\\\\n...\\\",\\\"status\\\":0&#125;\"</div></pre></td></tr></table></figure>\n<p>也可以直接到脚本安装路径，运行ruby脚本，直接看看采集结果</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">[root@tick bin]# /opt/sensu/embedded/bin/ruby  check-cpu.rb</div><div class=\"line\">CheckCPU TOTAL OK: total=0.25 user=0.0 nice=0.0 system=0.25 idle=99.75 iowait=0.0 irq=0.0 softirq=0.0 steal=0.0 guest=0.0 guest_nice=0.0</div></pre></td></tr></table></figure>\n<h3 id=\"Sensu-data-output\"><a href=\"#Sensu-data-output\" class=\"headerlink\" title=\"Sensu data output\"></a>Sensu data output</h3><p>Metric collection checks are used to collect measurements from server resources, services, and applications. Metric collection checks can output metric data in a variety of metric formats:</p>\n<ul>\n<li><a href=\"http://graphite.readthedocs.org/en/latest/feeding-carbon.html#the-plaintext-protocol\" target=\"_blank\" rel=\"external\">Graphite plaintext</a></li>\n<li><a href=\"http://nagios.sourceforge.net/docs/3_0/perfdata.html\" target=\"_blank\" rel=\"external\">Nagios Performance Data</a></li>\n<li><a href=\"http://opentsdb.net/docs/build/html/user_guide/writing.html\" target=\"_blank\" rel=\"external\">OpenTSDB</a></li>\n<li><a href=\"http://metrics20.org/spec/\" target=\"_blank\" rel=\"external\">Metrics 2.0 wire format</a></li>\n</ul>\n<p>The output produced by the check <code>command</code> ，貌似不同的插件返回不同的结果集。</p>\n<h3 id=\"Sensu-event-processor\"><a href=\"#Sensu-event-processor\" class=\"headerlink\" title=\"Sensu event processor\"></a>Sensu event processor</h3><p>The Sensu server provides a scalable event processor. Event processing involves conversion of <a href=\"https://sensuapp.org/docs/latest/reference/checks.html#check-results\" target=\"_blank\" rel=\"external\">check results</a> into Sensu events, and then applying any defined <a href=\"https://sensuapp.org/docs/latest/reference/filters.html\" target=\"_blank\" rel=\"external\">event filters</a>, <a href=\"https://sensuapp.org/docs/latest/reference/mutators.html\" target=\"_blank\" rel=\"external\">event data mutators</a>, and <a href=\"https://sensuapp.org/docs/latest/reference/handlers.html\" target=\"_blank\" rel=\"external\">event handlers</a>. All event processing happens on a Sensu server system.</p>\n<h3 id=\"Sensu-event-handlers\"><a href=\"#Sensu-event-handlers\" class=\"headerlink\" title=\"Sensu event handlers\"></a>Sensu event handlers</h3><p>Sensu event handlers are for taking action on <a href=\"https://sensuapp.org/docs/latest/reference/events.html\" target=\"_blank\" rel=\"external\">events</a> (produced by check results), such as sending an email alert, creating or resolving a PagerDuty incident, or storing metrics in Graphite. There are several types of handlers: <code>pipe</code>, <code>tcp</code>, <code>udp</code>, <code>transport</code>, and <code>set</code>.</p>\n<ul>\n<li><strong>Pipe handlers</strong> execute a command and pass the event data to the created process via <code>STDIN</code>.</li>\n<li><strong>TCP and UDP handlers</strong> send the event data to a remote socket.</li>\n<li><strong>Transport handlers</strong> publish the event data to the Sensu transport (by default, this is RabbitMQ).</li>\n<li><strong>Set handlers</strong> are used to group event handlers, making it easier to manage many event handlers.</li>\n</ul>\n<p>类似于告警。</p>\n<p>这里使用TCP handlers 作为验证，需安装nc 命令。开启两个终端，分别运行以下命令，一个是作为server端，监听6000端口，一个是客户端，往监听端口发送数据。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">nc -l -k -4 -p 6000      </div><div class=\"line\">echo \"testing\" | nc localhost 6000</div></pre></td></tr></table></figure>\n<p>新建TCP 配置文件 /etc/sensu/conf.d/tcp_socket.json</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"string\">\"handlers\"</span>: &#123;</div><div class=\"line\">    <span class=\"string\">\"tcp_socket\"</span>: &#123;</div><div class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"tcp\"</span>,</div><div class=\"line\">      <span class=\"string\">\"socket\"</span>: &#123;</div><div class=\"line\">        <span class=\"string\">\"host\"</span>: <span class=\"string\">\"localhost\"</span>,</div><div class=\"line\">        <span class=\"string\">\"port\"</span>: 6000</div><div class=\"line\">      &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>注意，需修改对应的check 配置，把handler 修改为 <em>tcp_socket</em>  </p>\n<p>例如，cron 进程检测的异常情况，即进程不存在<img src=\"/img/check-error-event.png\" alt=\"Check Error Event\"></p>\n<h3 id=\"Sensu-API\"><a href=\"#Sensu-API\" class=\"headerlink\" title=\"Sensu API\"></a>Sensu API</h3><p>常用的API </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">curl -s http://127.0.0.1:4567/clients | jq .</div><div class=\"line\">curl -s http://localhost:4567/events | jq .</div><div class=\"line\">curl -s http://localhost:4567/results | jq .</div><div class=\"line\">curl -s http://localhost:4567/client | jq .</div></pre></td></tr></table></figure>\n<h2 id=\"3-关注事项\"><a href=\"#3-关注事项\" class=\"headerlink\" title=\"3.关注事项\"></a>3.关注事项</h2><ol>\n<li><p>数据收集方式（Pull、Push）   </p>\n<p>默认都是Push，由Client发送采集数据到transport，服务端再去transport 读取数据。</p>\n</li>\n<li><p>数据格式</p>\n<p>check-result-cpu.json</p>\n</li>\n<li><p>数据存储方式</p>\n<p>数据存储在transport 中，可以固化到文件系统</p>\n</li>\n<li><p>数据输出方式</p>\n<p>checks 返回的结果是有一定格式的，其中，output字段存储的是对应的实际插件执行的命令输出结果。不同插件返回的命令结果不同。</p>\n</li>\n<li><p>agent 部署方式</p>\n<p>并未提供部署方案。</p>\n</li>\n<li><p>任务下发方式</p>\n<p>客户端配置任务。无法从通过sensu-server直接下发到客户端。</p>\n</li>\n</ol>"},{"title":"炒股的智慧 --陈江挺","date":"2015-06-12T15:34:28.000Z","_content":"\n# 本书大纲\n>* 第一章就谈些股市的特性及它对人性的挑战。 \n* 第二章讲一些和炒股最直接相关的知识。读者应带着两个疑问来读这一章： 一，什么是影响股价的因素；二， 股票在什么情况下运动正常。 这一章包括三个部分； 基本分析、 技术分析及股票的大市。 当这三部分的分析都给你下面信号的时候，是你在股市胜算最大的时候。 \n* 第三章谈成功的要素。它告诉你炒股成功应做到什么及怎样做， 还告诉你应该具备什么样的心理素质。 知道什么该做并不难， 难在怎么在实践中做好它。 \n* 第四章是何时买卖股票。在这一章你看不到“ 低点买入要谨慎， 高点卖出不要贪” 之类的废话，什么时候才是低？ 高到多高才是高？ 在办公室空想出来的炒股绝招没有什么实用价值。 ***买卖股票的要点在于怎么寻找“临界点”。*** 希望这章能改变你炒股的整个思维方式。 \n* 第五章是华尔街的家训。牛顿说：“我所以能看得更远， 是因为我站在巨人的肩膀上。” 在这一章， 让我们看看炒股这行的先辈们给我们留下了什么经验。 \n* 第六章谈心理建设。人性中根深蒂固的恐惧、 希望、 贪婪影响着我们所做的每一个决定， 使我们常常做不到自己知道应该做的事。 要完全克服人性中的弱点是很困难的， 但我们首先必须知道它是什么及什么是正确的做法。 \n* 第七章分析了什么是大机会及其特点。 读完这一章你就明白了我在谈什么。 这里不只是在谈股票。  \n* 第八章是和炒手谈谈天。在这一章我简述了我的学股历程。 如果人性共通的说法不错的话，你学股走过的道路应和我相似。 希望你在学股的挣扎过程中因为有了路标而能显得平顺一些。  \n* 附录：在今天的社会，我看到很多人为金钱不择手段。 而这本又是教人怎样赚钱的书， 不加点“金 钱的反思”让我觉得这本书不够均衡。 如果因为这一附录能使读者对人生有更进一步的认识，我会觉得努力没有白费。\n\n# 精彩语句\n>* 买卖股票的要点在于怎么寻找“临界点”。 \n* 截短亏损，让利润奔跑！ \n* 关注股票的正常运动、不正常运动和周期运动\n* 有理有据：理就是获胜的概率，据在于你知道怎样找临界点。\n* 不要心存幻想，必须牢牢记住： 股市从来都不会错，它总是走自己要走的路，会错的只有人自己。\n* 正确地感悟股票运动何时正常是最难学的，这也是炒股成功最关键的技巧之一。随着经验的增加，你的悟性越来越好，对股票运动的判断力越来越强，你就能将每次入场的获胜概率从 50%提高到 60%，甚至 70%，慢慢地你就成了炒股专家。要准备\"熬\"。 \n* 你的资金总是在盈利机会最大的时候才留在场内。--何时卖，等重新突破前高，再重新买入，而不是抄底！！！\n* 你如果能够做到仅在临界买点入场，临界卖点出场，入场时牢记止损，并注意分摊风险，你的成功的概率就能提至最高，你也就真正成为炒股专家了。\n<!-- more -->\n\n# 人性的弱点\n好获小利，不吃小亏\n人性讨厌风险\n人好自以为是\n人好跟风  --必须自己建立规则， 并完全由自己为这些规则 所产生的后果负责\n人好因循守旧\n人好报复\n\n# 技术分析\n* 走势图（上升、下降、无势图）\n* 支撑线和阻力线\n* 双肩图和头肩图，倒双肩和倒头肩\n* 均线\n* 综合看图\n\n# 炒股成功的基本要诀\n* 保本，止损，分批建仓\n* 不断盈利，反例:读者们若有机会到赌场看看， 就明白股民们为什么会这样做。 赌客们站在赌台旁， 一注都不肯放过， 生怕下一手就是自己赢钱的机会。 直到输完才会收手。\n* 赚大钱\n>为什么失去赚大钱的机会：\n\t一， 人好小便宜;\n\t二， 不够经验判断股票运动是否正常\n\t另一点要强调的是： 如果你确定股票运动正常， 你的胜算很大， 这时你应该在这只股票上适 当加大下注的比重。 \n* 资金管理，怎样下注\n> 输得起多少\n提高获胜的概率\n抓住正常运动中的股票，参考例子\n注意危险信号，突然大起大落\n\n\n# 正常运动与不正常运动的例子\n>* 如果股票开始一个上升的走势， 比如说准备从 20 元升到 50 元。 你将发现走势开始的前几\n天， 交易量突然增加， 股价开始攀升， 几天以后， 升势停止， 开始下跌。 这是“正常” 的获利回 吐， 下\n跌时的交易量较上升时显著减少。 读者朋友， 这个下调是很正常的， 属正常运动， 千 万不要在这个时候\n将股票卖掉。 如果这只股票具有上冲的潜力， 你会发现在几天内股票又开 始活跃， 交易量又开始增加，\n上次“自然调低” 所失去的“领土” 应在短时间内收复， 股票 开始冲到新的高度。 这次运动将持续一段\n时间， 其间每日通常是收盘价高过开盘价， 偶尔收 盘价低过开盘价， 其差额通常不大； 交易量也不会有\n显著的变化， 通常情况是减少。 或迟或 早， 股票又会开始下跌， 这是新一轮的“ 获利回吐” 。 这次获利\n回吐的股票运动和交易量的特 点应该和第一次很相似。 上述是股票走升势的正常运动。 下面的图显示出\n它们应有的特点。 如果读者觉得还很抽象的话， 我以下用数字来描述一遍， 因为掌握股票正常运动的\n特点对炒 股成功是极其重要的。 在股票 20 元的时候， 交易量增加， 可以是平时的一两倍， 股价从 20 元\n升到 21， 22， 甚至 27 元。 这几天的交易量较前段时间显著增加是其特征。 到 27 元时升势 可能停顿，\n随之开始下调， 股价走势为 27->26->24 元。 这段时间的交易量应较从 20 升到 27 元时的平均交易量为\n少， 即股票从 20->27 元时买盘大过卖盘， 从 27->24 元时的卖盘大过买 盘。 但这如果是正常的升势，\n从 20->27->24 这段时间总的买盘大过卖盘。 在 24 元徘徊几天 后， 股票应开始上升， 交易量又开始增\n加， 这次上冲应很快超过 27 元， 股价走势为 24->25->27->35 元。 当股票冲到 35 元时， 又开始停顿，\n随之下调， 重复第一阶段的运动。 这次下调同样应有交易量减少的特点。\n一只正常运动的股票， 每次上冲的强度通常较上一次更为猛烈。 以我们这个例子， 当股票再 次冲破 35\n元时， 应很容易地直冲到 45 元或 50 元， 其间不会感觉到有很大障碍。 反调是正常 的。 一位专业炒手\n决不能在正常回调的时候被吓出场。 入场后开始有利润了， 每次回调都意 味着纸上利润的减少。 常人的\n第一感觉就是赶快卖掉获利。 这是新手的显著特点。 这也是新 手很难在股市赚到大钱的原因。\n炒手的任务不仅仅在于确认何时股票运动正常， 同样重要的是要能认识股票何时运动不正常。 股票\n这种前进两步、 退后一步的过程可能延续一段时间， 有时可能是很长的一段时间。 这段时间炒手或许在精\n神上会松懈下来， 这是要不得的。 因为往往在你松懈下来的时候， 股票的 运动发生变化。 股票缓缓地周\n期性上升， 突然有一天， 股票狂涨， 从 50 元一下子升到 55 元， 第二天升到 62 元， 这两天交易量突\n然大增， 但在第二天收市的前半小时股票从 62 元跌回 58 元收盘。 第三天开市一样强劲， 股票一下子升\n到 64 元， 但第四天， 股票似乎失去了冲劲， 它 跌回了 61 元（ 如下图）。\n\n\n>* 我是这样理解这一现象的： 股票运动后面的主要力量是大户， 这些大户通常是手握巨资的基金或保险\n公司等。 当这些基金的管理人看好这只股票， 开始吸纳， 你将看到交易量上升， 股 价上升。 通常这些基\n金管理人在吸纳股票时， 并不希望引起大众的注意， 所以这一过程通常 是缓慢的， 它不会上报纸或电视\n的头条。 一旦这些大户吸股完毕， 你通常会听到他们开始公 开地推荐这些股票， 引起大众的注意。 这些\n大户们的信息通常较普通人灵通， 他们也会很快 看到公司有好消息公布， 如开发成功新产品， 盈利较预\n期为好等。 等到这些大户觉得好消息 已全部反映在股价之中， 他们开始准备脱手。 由于他们手中握有的\n股票数量通常很大， 如果 一下子砸进市场， 市场根本承受不了， 他们手中的股票很大部分只能在低价出\n手。 为了解决 这一问题， 他们要找傻瓜用高价来承接这些股票。 找傻瓜的最佳途径就是令股价暴升， 暴\n升 时通常伴随点好消息， 如公司任命新董事长了， 某证券商强力推荐该股票了等等。 报纸电视 整天重复\n这些消息， 引发小股民峰拥入市。 想想看， 小股民因股价暴升而引发贪念入市时买 的股票都是谁卖的？\n一旦大户找足傻瓜， 全身而退， 还去哪里找大买主把股价继续推高？ 你现在明白了股票的正常运动及\n危险信号后面的理由了吗？ 我一直强调， 炒股是艺术， 不是 科学。 当不正常的信号灯亮起， 是否表示这\n只股票就一定要下跌？ 答案是：“否！” 没有人能 够在任何时候百分之百地肯定股票明天会怎么样， 也许\n暴升的理由是公司真的发明了长生不 老药！ 你必须将股票的运动和公司的发展综合起来考虑。 让我重复\n一次： 炒股的最基本信条 是在任何时候， 你手上持有股票的上升潜力必须大过下跌的可能， 否则你就不\n应留在手里。 看到危险信号， 表示你的获胜概率此时已不超出 50%。 每位严肃的炒手都必须注意危\n险信号， 但问题是在内心深处总有些奇怪的力量使他们在该卖 出的时候提不起勇气这么做。 或许是侥幸\n心理在作怪。 在迟疑的这段时间， 他们常看到股票 又跌了好多点， 这时他们会拍着脑袋， 大骂自己傻瓜，\n同时发誓一旦股票一有反弹就走人， “股票跌了这么多， 该会有个小反弹吧？ ” 但反弹来到的时候， 他\n们又忘记了自己的誓言， 因为在他们眼睛里， 这时股票的运动又开始“正常” 起来。 通常， 这样的反弹\n仅是股票在下 跌路上的喘气， 它很快就要继续要走的路。 人性有很多缺陷。 人希望股票会怎么运动， 认\n定 股票会怎么运动， 当股票的运动和预想不符合时， 就会认为股市错了， 自己没有错。 但炒友 们必须牢\n牢记住： 股市从来都不会错， 它总是走自己要走的路， 会错的只有人自己。 你所能做 的只有追随股市。\n见到危险信号， 不要三心二意， 不要存有幻想， 把股票全部脱手。 几天以 后， 也许一切又恢复正常， 你\n一样可以重新入场。 如果能这样做， 你将发现你为自己省下了很多焦虑及学费。\n\n\n# 3-3 成功投资者所具有的共性\n>要有成为投资专家的欲望\n必须具备锲而不舍的精神\n要有“ 与股市斗， 其乐无穷” 的气派\n要甘于做孤独者\n必须具有耐心和自制力\n**必须有一套适合自己的炒股模式**\n必须具有超前的想像力及对未来的判断\n成功的投资者绝不幻想\n要有应用知识的毅力   \n\n一位成功的投资者， 他应十分留意怎样将他的知识应用在炒股中， 他不会为应用这些知识的 枯燥而\n忽略细节。 在日常生活中， 获得知识通常并不困难， 困难在于用毅力应用这些知识。 在炒股问题上， 我\n是坚信“知易行难” 之说的。\n\n\n# 4 何时买卖股票\n学习寻找临界点的过程其实就是学股的过程， 当然其中还包括学习炒股的正确心态。华尔街将炒股的诀巧归纳成两句话： 截短亏损，让利润奔跑！\n关于人性的思考，自我的突破 \n## 4.1 何时买 ！！！ 一定要多读透彻\n>如何选股\n选股之后，如何进场\n如何设置止损点\n## 4.2 何时卖 ！！！ 一定要多读透彻\n何时卖股票的考虑可以分成两部分： 一， 刚进股时怎样选止损点； 二， 有利润后怎样选择合 适的卖点获利。 \n**买今天在上涨的股票：我自己喜欢把止损点定在入市当天的最低点。 比如我今天以 10.75 元买 进股票， 今天的最高价是 11 元， 最低价是 10 元， 我便以 10 元作为止损点。 以我的经验， 如 果我的入场点选的正确，股票开始上升， 它不应跌回我当天入场的最低点。**\n\n>庄家的把戏\n大户们操纵股票其实就是那么几招， 你只要专心， 观察股票的运动和交易量的变 化， 想像你是大户的话会怎么调动公众的心理， 大户的花招其实明显的很。 \n讲白了， 他们想 买进的进修要么静悄悄地， 要么想法引起大众的恐慌性抛售， 前者你会看到交易量增加， 但不明显， 股价慢慢地一步步升高， 后者便是搞一些大家公认的好卖点。\n大户想卖的时候，要么先买进， 造成股价狂升，引发股民的贪念去抢搭轿子， 要么就搞一些公众们共认的好买点。 \n由于他们通常手握巨资， 要做到这些并不困难。便他们的动作必须会从股价的变动及交易量 的变动中露出尾巴，只要你有足够的经验， 你就明白怎样跟着玩。\n\n请再读一遍何时买股票， 何时卖股票这两节， 再体会一下“截短亏损， 让利润奔跑” 这句话， 炒股的诀窍尽在其中。\n\n\n# 8 和炒手们聊天\n## 8.1 学股的四个阶段\n>第四阶段久赌必赢\n一个可行的计划， 不能凭空想像， 它必须有理有据。“理” 就是数学的概率， 如果你每次下注的赢面\n超过 50%， 而且你只下本金的小部分， 不会为几次坏运气就剃光头， 从长期而言你是 胜定了。 道理和开\n赌场一样。“据” 在于你知道怎样找临界点， 在长期的观察和实践过程中， 你知道这些点是出入场的关键\n点， 在这些点操作， 你的赢面超出 50%， 再加上应用“截短亏 损， 让利润奔跑” 的原则， 赢时赢大的，\n亏时亏小的， 你的获胜概率其实远远超出了 50%。 到久赌必赢阶段， 你不应对亏钱和赚钱有任何情绪\n上的波动。 你对止损不再痛苦， 你明白这 是游戏的一部分， 你对赚钱也不再喜悦， 你知道这是必然结果。\n你不再将胜负放在心上， 你 只注重在正确的时间， 做正确的事情。 你知道利润会随之而来。","source":"_posts/wisdom-in-stocks.md","raw":"---\ntitle: 炒股的智慧 --陈江挺\ndate: 2015-06-12 23:34:28\n---\n\n# 本书大纲\n>* 第一章就谈些股市的特性及它对人性的挑战。 \n* 第二章讲一些和炒股最直接相关的知识。读者应带着两个疑问来读这一章： 一，什么是影响股价的因素；二， 股票在什么情况下运动正常。 这一章包括三个部分； 基本分析、 技术分析及股票的大市。 当这三部分的分析都给你下面信号的时候，是你在股市胜算最大的时候。 \n* 第三章谈成功的要素。它告诉你炒股成功应做到什么及怎样做， 还告诉你应该具备什么样的心理素质。 知道什么该做并不难， 难在怎么在实践中做好它。 \n* 第四章是何时买卖股票。在这一章你看不到“ 低点买入要谨慎， 高点卖出不要贪” 之类的废话，什么时候才是低？ 高到多高才是高？ 在办公室空想出来的炒股绝招没有什么实用价值。 ***买卖股票的要点在于怎么寻找“临界点”。*** 希望这章能改变你炒股的整个思维方式。 \n* 第五章是华尔街的家训。牛顿说：“我所以能看得更远， 是因为我站在巨人的肩膀上。” 在这一章， 让我们看看炒股这行的先辈们给我们留下了什么经验。 \n* 第六章谈心理建设。人性中根深蒂固的恐惧、 希望、 贪婪影响着我们所做的每一个决定， 使我们常常做不到自己知道应该做的事。 要完全克服人性中的弱点是很困难的， 但我们首先必须知道它是什么及什么是正确的做法。 \n* 第七章分析了什么是大机会及其特点。 读完这一章你就明白了我在谈什么。 这里不只是在谈股票。  \n* 第八章是和炒手谈谈天。在这一章我简述了我的学股历程。 如果人性共通的说法不错的话，你学股走过的道路应和我相似。 希望你在学股的挣扎过程中因为有了路标而能显得平顺一些。  \n* 附录：在今天的社会，我看到很多人为金钱不择手段。 而这本又是教人怎样赚钱的书， 不加点“金 钱的反思”让我觉得这本书不够均衡。 如果因为这一附录能使读者对人生有更进一步的认识，我会觉得努力没有白费。\n\n# 精彩语句\n>* 买卖股票的要点在于怎么寻找“临界点”。 \n* 截短亏损，让利润奔跑！ \n* 关注股票的正常运动、不正常运动和周期运动\n* 有理有据：理就是获胜的概率，据在于你知道怎样找临界点。\n* 不要心存幻想，必须牢牢记住： 股市从来都不会错，它总是走自己要走的路，会错的只有人自己。\n* 正确地感悟股票运动何时正常是最难学的，这也是炒股成功最关键的技巧之一。随着经验的增加，你的悟性越来越好，对股票运动的判断力越来越强，你就能将每次入场的获胜概率从 50%提高到 60%，甚至 70%，慢慢地你就成了炒股专家。要准备\"熬\"。 \n* 你的资金总是在盈利机会最大的时候才留在场内。--何时卖，等重新突破前高，再重新买入，而不是抄底！！！\n* 你如果能够做到仅在临界买点入场，临界卖点出场，入场时牢记止损，并注意分摊风险，你的成功的概率就能提至最高，你也就真正成为炒股专家了。\n<!-- more -->\n\n# 人性的弱点\n好获小利，不吃小亏\n人性讨厌风险\n人好自以为是\n人好跟风  --必须自己建立规则， 并完全由自己为这些规则 所产生的后果负责\n人好因循守旧\n人好报复\n\n# 技术分析\n* 走势图（上升、下降、无势图）\n* 支撑线和阻力线\n* 双肩图和头肩图，倒双肩和倒头肩\n* 均线\n* 综合看图\n\n# 炒股成功的基本要诀\n* 保本，止损，分批建仓\n* 不断盈利，反例:读者们若有机会到赌场看看， 就明白股民们为什么会这样做。 赌客们站在赌台旁， 一注都不肯放过， 生怕下一手就是自己赢钱的机会。 直到输完才会收手。\n* 赚大钱\n>为什么失去赚大钱的机会：\n\t一， 人好小便宜;\n\t二， 不够经验判断股票运动是否正常\n\t另一点要强调的是： 如果你确定股票运动正常， 你的胜算很大， 这时你应该在这只股票上适 当加大下注的比重。 \n* 资金管理，怎样下注\n> 输得起多少\n提高获胜的概率\n抓住正常运动中的股票，参考例子\n注意危险信号，突然大起大落\n\n\n# 正常运动与不正常运动的例子\n>* 如果股票开始一个上升的走势， 比如说准备从 20 元升到 50 元。 你将发现走势开始的前几\n天， 交易量突然增加， 股价开始攀升， 几天以后， 升势停止， 开始下跌。 这是“正常” 的获利回 吐， 下\n跌时的交易量较上升时显著减少。 读者朋友， 这个下调是很正常的， 属正常运动， 千 万不要在这个时候\n将股票卖掉。 如果这只股票具有上冲的潜力， 你会发现在几天内股票又开 始活跃， 交易量又开始增加，\n上次“自然调低” 所失去的“领土” 应在短时间内收复， 股票 开始冲到新的高度。 这次运动将持续一段\n时间， 其间每日通常是收盘价高过开盘价， 偶尔收 盘价低过开盘价， 其差额通常不大； 交易量也不会有\n显著的变化， 通常情况是减少。 或迟或 早， 股票又会开始下跌， 这是新一轮的“ 获利回吐” 。 这次获利\n回吐的股票运动和交易量的特 点应该和第一次很相似。 上述是股票走升势的正常运动。 下面的图显示出\n它们应有的特点。 如果读者觉得还很抽象的话， 我以下用数字来描述一遍， 因为掌握股票正常运动的\n特点对炒 股成功是极其重要的。 在股票 20 元的时候， 交易量增加， 可以是平时的一两倍， 股价从 20 元\n升到 21， 22， 甚至 27 元。 这几天的交易量较前段时间显著增加是其特征。 到 27 元时升势 可能停顿，\n随之开始下调， 股价走势为 27->26->24 元。 这段时间的交易量应较从 20 升到 27 元时的平均交易量为\n少， 即股票从 20->27 元时买盘大过卖盘， 从 27->24 元时的卖盘大过买 盘。 但这如果是正常的升势，\n从 20->27->24 这段时间总的买盘大过卖盘。 在 24 元徘徊几天 后， 股票应开始上升， 交易量又开始增\n加， 这次上冲应很快超过 27 元， 股价走势为 24->25->27->35 元。 当股票冲到 35 元时， 又开始停顿，\n随之下调， 重复第一阶段的运动。 这次下调同样应有交易量减少的特点。\n一只正常运动的股票， 每次上冲的强度通常较上一次更为猛烈。 以我们这个例子， 当股票再 次冲破 35\n元时， 应很容易地直冲到 45 元或 50 元， 其间不会感觉到有很大障碍。 反调是正常 的。 一位专业炒手\n决不能在正常回调的时候被吓出场。 入场后开始有利润了， 每次回调都意 味着纸上利润的减少。 常人的\n第一感觉就是赶快卖掉获利。 这是新手的显著特点。 这也是新 手很难在股市赚到大钱的原因。\n炒手的任务不仅仅在于确认何时股票运动正常， 同样重要的是要能认识股票何时运动不正常。 股票\n这种前进两步、 退后一步的过程可能延续一段时间， 有时可能是很长的一段时间。 这段时间炒手或许在精\n神上会松懈下来， 这是要不得的。 因为往往在你松懈下来的时候， 股票的 运动发生变化。 股票缓缓地周\n期性上升， 突然有一天， 股票狂涨， 从 50 元一下子升到 55 元， 第二天升到 62 元， 这两天交易量突\n然大增， 但在第二天收市的前半小时股票从 62 元跌回 58 元收盘。 第三天开市一样强劲， 股票一下子升\n到 64 元， 但第四天， 股票似乎失去了冲劲， 它 跌回了 61 元（ 如下图）。\n\n\n>* 我是这样理解这一现象的： 股票运动后面的主要力量是大户， 这些大户通常是手握巨资的基金或保险\n公司等。 当这些基金的管理人看好这只股票， 开始吸纳， 你将看到交易量上升， 股 价上升。 通常这些基\n金管理人在吸纳股票时， 并不希望引起大众的注意， 所以这一过程通常 是缓慢的， 它不会上报纸或电视\n的头条。 一旦这些大户吸股完毕， 你通常会听到他们开始公 开地推荐这些股票， 引起大众的注意。 这些\n大户们的信息通常较普通人灵通， 他们也会很快 看到公司有好消息公布， 如开发成功新产品， 盈利较预\n期为好等。 等到这些大户觉得好消息 已全部反映在股价之中， 他们开始准备脱手。 由于他们手中握有的\n股票数量通常很大， 如果 一下子砸进市场， 市场根本承受不了， 他们手中的股票很大部分只能在低价出\n手。 为了解决 这一问题， 他们要找傻瓜用高价来承接这些股票。 找傻瓜的最佳途径就是令股价暴升， 暴\n升 时通常伴随点好消息， 如公司任命新董事长了， 某证券商强力推荐该股票了等等。 报纸电视 整天重复\n这些消息， 引发小股民峰拥入市。 想想看， 小股民因股价暴升而引发贪念入市时买 的股票都是谁卖的？\n一旦大户找足傻瓜， 全身而退， 还去哪里找大买主把股价继续推高？ 你现在明白了股票的正常运动及\n危险信号后面的理由了吗？ 我一直强调， 炒股是艺术， 不是 科学。 当不正常的信号灯亮起， 是否表示这\n只股票就一定要下跌？ 答案是：“否！” 没有人能 够在任何时候百分之百地肯定股票明天会怎么样， 也许\n暴升的理由是公司真的发明了长生不 老药！ 你必须将股票的运动和公司的发展综合起来考虑。 让我重复\n一次： 炒股的最基本信条 是在任何时候， 你手上持有股票的上升潜力必须大过下跌的可能， 否则你就不\n应留在手里。 看到危险信号， 表示你的获胜概率此时已不超出 50%。 每位严肃的炒手都必须注意危\n险信号， 但问题是在内心深处总有些奇怪的力量使他们在该卖 出的时候提不起勇气这么做。 或许是侥幸\n心理在作怪。 在迟疑的这段时间， 他们常看到股票 又跌了好多点， 这时他们会拍着脑袋， 大骂自己傻瓜，\n同时发誓一旦股票一有反弹就走人， “股票跌了这么多， 该会有个小反弹吧？ ” 但反弹来到的时候， 他\n们又忘记了自己的誓言， 因为在他们眼睛里， 这时股票的运动又开始“正常” 起来。 通常， 这样的反弹\n仅是股票在下 跌路上的喘气， 它很快就要继续要走的路。 人性有很多缺陷。 人希望股票会怎么运动， 认\n定 股票会怎么运动， 当股票的运动和预想不符合时， 就会认为股市错了， 自己没有错。 但炒友 们必须牢\n牢记住： 股市从来都不会错， 它总是走自己要走的路， 会错的只有人自己。 你所能做 的只有追随股市。\n见到危险信号， 不要三心二意， 不要存有幻想， 把股票全部脱手。 几天以 后， 也许一切又恢复正常， 你\n一样可以重新入场。 如果能这样做， 你将发现你为自己省下了很多焦虑及学费。\n\n\n# 3-3 成功投资者所具有的共性\n>要有成为投资专家的欲望\n必须具备锲而不舍的精神\n要有“ 与股市斗， 其乐无穷” 的气派\n要甘于做孤独者\n必须具有耐心和自制力\n**必须有一套适合自己的炒股模式**\n必须具有超前的想像力及对未来的判断\n成功的投资者绝不幻想\n要有应用知识的毅力   \n\n一位成功的投资者， 他应十分留意怎样将他的知识应用在炒股中， 他不会为应用这些知识的 枯燥而\n忽略细节。 在日常生活中， 获得知识通常并不困难， 困难在于用毅力应用这些知识。 在炒股问题上， 我\n是坚信“知易行难” 之说的。\n\n\n# 4 何时买卖股票\n学习寻找临界点的过程其实就是学股的过程， 当然其中还包括学习炒股的正确心态。华尔街将炒股的诀巧归纳成两句话： 截短亏损，让利润奔跑！\n关于人性的思考，自我的突破 \n## 4.1 何时买 ！！！ 一定要多读透彻\n>如何选股\n选股之后，如何进场\n如何设置止损点\n## 4.2 何时卖 ！！！ 一定要多读透彻\n何时卖股票的考虑可以分成两部分： 一， 刚进股时怎样选止损点； 二， 有利润后怎样选择合 适的卖点获利。 \n**买今天在上涨的股票：我自己喜欢把止损点定在入市当天的最低点。 比如我今天以 10.75 元买 进股票， 今天的最高价是 11 元， 最低价是 10 元， 我便以 10 元作为止损点。 以我的经验， 如 果我的入场点选的正确，股票开始上升， 它不应跌回我当天入场的最低点。**\n\n>庄家的把戏\n大户们操纵股票其实就是那么几招， 你只要专心， 观察股票的运动和交易量的变 化， 想像你是大户的话会怎么调动公众的心理， 大户的花招其实明显的很。 \n讲白了， 他们想 买进的进修要么静悄悄地， 要么想法引起大众的恐慌性抛售， 前者你会看到交易量增加， 但不明显， 股价慢慢地一步步升高， 后者便是搞一些大家公认的好卖点。\n大户想卖的时候，要么先买进， 造成股价狂升，引发股民的贪念去抢搭轿子， 要么就搞一些公众们共认的好买点。 \n由于他们通常手握巨资， 要做到这些并不困难。便他们的动作必须会从股价的变动及交易量 的变动中露出尾巴，只要你有足够的经验， 你就明白怎样跟着玩。\n\n请再读一遍何时买股票， 何时卖股票这两节， 再体会一下“截短亏损， 让利润奔跑” 这句话， 炒股的诀窍尽在其中。\n\n\n# 8 和炒手们聊天\n## 8.1 学股的四个阶段\n>第四阶段久赌必赢\n一个可行的计划， 不能凭空想像， 它必须有理有据。“理” 就是数学的概率， 如果你每次下注的赢面\n超过 50%， 而且你只下本金的小部分， 不会为几次坏运气就剃光头， 从长期而言你是 胜定了。 道理和开\n赌场一样。“据” 在于你知道怎样找临界点， 在长期的观察和实践过程中， 你知道这些点是出入场的关键\n点， 在这些点操作， 你的赢面超出 50%， 再加上应用“截短亏 损， 让利润奔跑” 的原则， 赢时赢大的，\n亏时亏小的， 你的获胜概率其实远远超出了 50%。 到久赌必赢阶段， 你不应对亏钱和赚钱有任何情绪\n上的波动。 你对止损不再痛苦， 你明白这 是游戏的一部分， 你对赚钱也不再喜悦， 你知道这是必然结果。\n你不再将胜负放在心上， 你 只注重在正确的时间， 做正确的事情。 你知道利润会随之而来。","slug":"wisdom-in-stocks","published":1,"updated":"2018-04-27T04:11:03.370Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczpf001ce4rwe15yopm9","content":"<h1 id=\"本书大纲\"><a href=\"#本书大纲\" class=\"headerlink\" title=\"本书大纲\"></a>本书大纲</h1><blockquote>\n<ul>\n<li>第一章就谈些股市的特性及它对人性的挑战。 </li>\n<li>第二章讲一些和炒股最直接相关的知识。读者应带着两个疑问来读这一章： 一，什么是影响股价的因素；二， 股票在什么情况下运动正常。 这一章包括三个部分； 基本分析、 技术分析及股票的大市。 当这三部分的分析都给你下面信号的时候，是你在股市胜算最大的时候。 </li>\n<li>第三章谈成功的要素。它告诉你炒股成功应做到什么及怎样做， 还告诉你应该具备什么样的心理素质。 知道什么该做并不难， 难在怎么在实践中做好它。 </li>\n<li>第四章是何时买卖股票。在这一章你看不到“ 低点买入要谨慎， 高点卖出不要贪” 之类的废话，什么时候才是低？ 高到多高才是高？ 在办公室空想出来的炒股绝招没有什么实用价值。 <strong><em>买卖股票的要点在于怎么寻找“临界点”。</em></strong> 希望这章能改变你炒股的整个思维方式。 </li>\n<li>第五章是华尔街的家训。牛顿说：“我所以能看得更远， 是因为我站在巨人的肩膀上。” 在这一章， 让我们看看炒股这行的先辈们给我们留下了什么经验。 </li>\n<li>第六章谈心理建设。人性中根深蒂固的恐惧、 希望、 贪婪影响着我们所做的每一个决定， 使我们常常做不到自己知道应该做的事。 要完全克服人性中的弱点是很困难的， 但我们首先必须知道它是什么及什么是正确的做法。 </li>\n<li>第七章分析了什么是大机会及其特点。 读完这一章你就明白了我在谈什么。 这里不只是在谈股票。  </li>\n<li>第八章是和炒手谈谈天。在这一章我简述了我的学股历程。 如果人性共通的说法不错的话，你学股走过的道路应和我相似。 希望你在学股的挣扎过程中因为有了路标而能显得平顺一些。  </li>\n<li>附录：在今天的社会，我看到很多人为金钱不择手段。 而这本又是教人怎样赚钱的书， 不加点“金 钱的反思”让我觉得这本书不够均衡。 如果因为这一附录能使读者对人生有更进一步的认识，我会觉得努力没有白费。</li>\n</ul>\n</blockquote>\n<h1 id=\"精彩语句\"><a href=\"#精彩语句\" class=\"headerlink\" title=\"精彩语句\"></a>精彩语句</h1><blockquote>\n<ul>\n<li>买卖股票的要点在于怎么寻找“临界点”。 </li>\n<li>截短亏损，让利润奔跑！ </li>\n<li>关注股票的正常运动、不正常运动和周期运动</li>\n<li>有理有据：理就是获胜的概率，据在于你知道怎样找临界点。</li>\n<li>不要心存幻想，必须牢牢记住： 股市从来都不会错，它总是走自己要走的路，会错的只有人自己。</li>\n<li>正确地感悟股票运动何时正常是最难学的，这也是炒股成功最关键的技巧之一。随着经验的增加，你的悟性越来越好，对股票运动的判断力越来越强，你就能将每次入场的获胜概率从 50%提高到 60%，甚至 70%，慢慢地你就成了炒股专家。要准备”熬”。 </li>\n<li>你的资金总是在盈利机会最大的时候才留在场内。–何时卖，等重新突破前高，再重新买入，而不是抄底！！！</li>\n<li>你如果能够做到仅在临界买点入场，临界卖点出场，入场时牢记止损，并注意分摊风险，你的成功的概率就能提至最高，你也就真正成为炒股专家了。<a id=\"more\"></a>\n</li>\n</ul>\n</blockquote>\n<h1 id=\"人性的弱点\"><a href=\"#人性的弱点\" class=\"headerlink\" title=\"人性的弱点\"></a>人性的弱点</h1><p>好获小利，不吃小亏<br>人性讨厌风险<br>人好自以为是<br>人好跟风  –必须自己建立规则， 并完全由自己为这些规则 所产生的后果负责<br>人好因循守旧<br>人好报复</p>\n<h1 id=\"技术分析\"><a href=\"#技术分析\" class=\"headerlink\" title=\"技术分析\"></a>技术分析</h1><ul>\n<li>走势图（上升、下降、无势图）</li>\n<li>支撑线和阻力线</li>\n<li>双肩图和头肩图，倒双肩和倒头肩</li>\n<li>均线</li>\n<li>综合看图</li>\n</ul>\n<h1 id=\"炒股成功的基本要诀\"><a href=\"#炒股成功的基本要诀\" class=\"headerlink\" title=\"炒股成功的基本要诀\"></a>炒股成功的基本要诀</h1><ul>\n<li>保本，止损，分批建仓</li>\n<li>不断盈利，反例:读者们若有机会到赌场看看， 就明白股民们为什么会这样做。 赌客们站在赌台旁， 一注都不肯放过， 生怕下一手就是自己赢钱的机会。 直到输完才会收手。</li>\n<li>赚大钱<blockquote>\n<p>为什么失去赚大钱的机会：<br>  一， 人好小便宜;<br>  二， 不够经验判断股票运动是否正常<br>  另一点要强调的是： 如果你确定股票运动正常， 你的胜算很大， 这时你应该在这只股票上适 当加大下注的比重。 </p>\n</blockquote>\n</li>\n<li>资金管理，怎样下注<blockquote>\n<p>输得起多少<br>提高获胜的概率<br>抓住正常运动中的股票，参考例子<br>注意危险信号，突然大起大落</p>\n</blockquote>\n</li>\n</ul>\n<h1 id=\"正常运动与不正常运动的例子\"><a href=\"#正常运动与不正常运动的例子\" class=\"headerlink\" title=\"正常运动与不正常运动的例子\"></a>正常运动与不正常运动的例子</h1><blockquote>\n<ul>\n<li>如果股票开始一个上升的走势， 比如说准备从 20 元升到 50 元。 你将发现走势开始的前几<br>天， 交易量突然增加， 股价开始攀升， 几天以后， 升势停止， 开始下跌。 这是“正常” 的获利回 吐， 下<br>跌时的交易量较上升时显著减少。 读者朋友， 这个下调是很正常的， 属正常运动， 千 万不要在这个时候<br>将股票卖掉。 如果这只股票具有上冲的潜力， 你会发现在几天内股票又开 始活跃， 交易量又开始增加，<br>上次“自然调低” 所失去的“领土” 应在短时间内收复， 股票 开始冲到新的高度。 这次运动将持续一段<br>时间， 其间每日通常是收盘价高过开盘价， 偶尔收 盘价低过开盘价， 其差额通常不大； 交易量也不会有<br>显著的变化， 通常情况是减少。 或迟或 早， 股票又会开始下跌， 这是新一轮的“ 获利回吐” 。 这次获利<br>回吐的股票运动和交易量的特 点应该和第一次很相似。 上述是股票走升势的正常运动。 下面的图显示出<br>它们应有的特点。 如果读者觉得还很抽象的话， 我以下用数字来描述一遍， 因为掌握股票正常运动的<br>特点对炒 股成功是极其重要的。 在股票 20 元的时候， 交易量增加， 可以是平时的一两倍， 股价从 20 元<br>升到 21， 22， 甚至 27 元。 这几天的交易量较前段时间显著增加是其特征。 到 27 元时升势 可能停顿，<br>随之开始下调， 股价走势为 27-&gt;26-&gt;24 元。 这段时间的交易量应较从 20 升到 27 元时的平均交易量为<br>少， 即股票从 20-&gt;27 元时买盘大过卖盘， 从 27-&gt;24 元时的卖盘大过买 盘。 但这如果是正常的升势，<br>从 20-&gt;27-&gt;24 这段时间总的买盘大过卖盘。 在 24 元徘徊几天 后， 股票应开始上升， 交易量又开始增<br>加， 这次上冲应很快超过 27 元， 股价走势为 24-&gt;25-&gt;27-&gt;35 元。 当股票冲到 35 元时， 又开始停顿，<br>随之下调， 重复第一阶段的运动。 这次下调同样应有交易量减少的特点。<br>一只正常运动的股票， 每次上冲的强度通常较上一次更为猛烈。 以我们这个例子， 当股票再 次冲破 35<br>元时， 应很容易地直冲到 45 元或 50 元， 其间不会感觉到有很大障碍。 反调是正常 的。 一位专业炒手<br>决不能在正常回调的时候被吓出场。 入场后开始有利润了， 每次回调都意 味着纸上利润的减少。 常人的<br>第一感觉就是赶快卖掉获利。 这是新手的显著特点。 这也是新 手很难在股市赚到大钱的原因。<br>炒手的任务不仅仅在于确认何时股票运动正常， 同样重要的是要能认识股票何时运动不正常。 股票<br>这种前进两步、 退后一步的过程可能延续一段时间， 有时可能是很长的一段时间。 这段时间炒手或许在精<br>神上会松懈下来， 这是要不得的。 因为往往在你松懈下来的时候， 股票的 运动发生变化。 股票缓缓地周<br>期性上升， 突然有一天， 股票狂涨， 从 50 元一下子升到 55 元， 第二天升到 62 元， 这两天交易量突<br>然大增， 但在第二天收市的前半小时股票从 62 元跌回 58 元收盘。 第三天开市一样强劲， 股票一下子升<br>到 64 元， 但第四天， 股票似乎失去了冲劲， 它 跌回了 61 元（ 如下图）。</li>\n</ul>\n<ul>\n<li>我是这样理解这一现象的： 股票运动后面的主要力量是大户， 这些大户通常是手握巨资的基金或保险<br>公司等。 当这些基金的管理人看好这只股票， 开始吸纳， 你将看到交易量上升， 股 价上升。 通常这些基<br>金管理人在吸纳股票时， 并不希望引起大众的注意， 所以这一过程通常 是缓慢的， 它不会上报纸或电视<br>的头条。 一旦这些大户吸股完毕， 你通常会听到他们开始公 开地推荐这些股票， 引起大众的注意。 这些<br>大户们的信息通常较普通人灵通， 他们也会很快 看到公司有好消息公布， 如开发成功新产品， 盈利较预<br>期为好等。 等到这些大户觉得好消息 已全部反映在股价之中， 他们开始准备脱手。 由于他们手中握有的<br>股票数量通常很大， 如果 一下子砸进市场， 市场根本承受不了， 他们手中的股票很大部分只能在低价出<br>手。 为了解决 这一问题， 他们要找傻瓜用高价来承接这些股票。 找傻瓜的最佳途径就是令股价暴升， 暴<br>升 时通常伴随点好消息， 如公司任命新董事长了， 某证券商强力推荐该股票了等等。 报纸电视 整天重复<br>这些消息， 引发小股民峰拥入市。 想想看， 小股民因股价暴升而引发贪念入市时买 的股票都是谁卖的？<br>一旦大户找足傻瓜， 全身而退， 还去哪里找大买主把股价继续推高？ 你现在明白了股票的正常运动及<br>危险信号后面的理由了吗？ 我一直强调， 炒股是艺术， 不是 科学。 当不正常的信号灯亮起， 是否表示这<br>只股票就一定要下跌？ 答案是：“否！” 没有人能 够在任何时候百分之百地肯定股票明天会怎么样， 也许<br>暴升的理由是公司真的发明了长生不 老药！ 你必须将股票的运动和公司的发展综合起来考虑。 让我重复<br>一次： 炒股的最基本信条 是在任何时候， 你手上持有股票的上升潜力必须大过下跌的可能， 否则你就不<br>应留在手里。 看到危险信号， 表示你的获胜概率此时已不超出 50%。 每位严肃的炒手都必须注意危<br>险信号， 但问题是在内心深处总有些奇怪的力量使他们在该卖 出的时候提不起勇气这么做。 或许是侥幸<br>心理在作怪。 在迟疑的这段时间， 他们常看到股票 又跌了好多点， 这时他们会拍着脑袋， 大骂自己傻瓜，<br>同时发誓一旦股票一有反弹就走人， “股票跌了这么多， 该会有个小反弹吧？ ” 但反弹来到的时候， 他<br>们又忘记了自己的誓言， 因为在他们眼睛里， 这时股票的运动又开始“正常” 起来。 通常， 这样的反弹<br>仅是股票在下 跌路上的喘气， 它很快就要继续要走的路。 人性有很多缺陷。 人希望股票会怎么运动， 认<br>定 股票会怎么运动， 当股票的运动和预想不符合时， 就会认为股市错了， 自己没有错。 但炒友 们必须牢<br>牢记住： 股市从来都不会错， 它总是走自己要走的路， 会错的只有人自己。 你所能做 的只有追随股市。<br>见到危险信号， 不要三心二意， 不要存有幻想， 把股票全部脱手。 几天以 后， 也许一切又恢复正常， 你<br>一样可以重新入场。 如果能这样做， 你将发现你为自己省下了很多焦虑及学费。</li>\n</ul>\n</blockquote>\n<h1 id=\"3-3-成功投资者所具有的共性\"><a href=\"#3-3-成功投资者所具有的共性\" class=\"headerlink\" title=\"3-3 成功投资者所具有的共性\"></a>3-3 成功投资者所具有的共性</h1><blockquote>\n<p>要有成为投资专家的欲望<br>必须具备锲而不舍的精神<br>要有“ 与股市斗， 其乐无穷” 的气派<br>要甘于做孤独者<br>必须具有耐心和自制力<br><strong>必须有一套适合自己的炒股模式</strong><br>必须具有超前的想像力及对未来的判断<br>成功的投资者绝不幻想<br>要有应用知识的毅力   </p>\n</blockquote>\n<p>一位成功的投资者， 他应十分留意怎样将他的知识应用在炒股中， 他不会为应用这些知识的 枯燥而<br>忽略细节。 在日常生活中， 获得知识通常并不困难， 困难在于用毅力应用这些知识。 在炒股问题上， 我<br>是坚信“知易行难” 之说的。</p>\n<h1 id=\"4-何时买卖股票\"><a href=\"#4-何时买卖股票\" class=\"headerlink\" title=\"4 何时买卖股票\"></a>4 何时买卖股票</h1><p>学习寻找临界点的过程其实就是学股的过程， 当然其中还包括学习炒股的正确心态。华尔街将炒股的诀巧归纳成两句话： 截短亏损，让利润奔跑！<br>关于人性的思考，自我的突破 </p>\n<h2 id=\"4-1-何时买-！！！-一定要多读透彻\"><a href=\"#4-1-何时买-！！！-一定要多读透彻\" class=\"headerlink\" title=\"4.1 何时买 ！！！ 一定要多读透彻\"></a>4.1 何时买 ！！！ 一定要多读透彻</h2><blockquote>\n<p>如何选股<br>选股之后，如何进场<br>如何设置止损点</p>\n<h2 id=\"4-2-何时卖-！！！-一定要多读透彻\"><a href=\"#4-2-何时卖-！！！-一定要多读透彻\" class=\"headerlink\" title=\"4.2 何时卖 ！！！ 一定要多读透彻\"></a>4.2 何时卖 ！！！ 一定要多读透彻</h2><p>何时卖股票的考虑可以分成两部分： 一， 刚进股时怎样选止损点； 二， 有利润后怎样选择合 适的卖点获利。<br><strong>买今天在上涨的股票：我自己喜欢把止损点定在入市当天的最低点。 比如我今天以 10.75 元买 进股票， 今天的最高价是 11 元， 最低价是 10 元， 我便以 10 元作为止损点。 以我的经验， 如 果我的入场点选的正确，股票开始上升， 它不应跌回我当天入场的最低点。</strong></p>\n<p>庄家的把戏<br>大户们操纵股票其实就是那么几招， 你只要专心， 观察股票的运动和交易量的变 化， 想像你是大户的话会怎么调动公众的心理， 大户的花招其实明显的很。<br>讲白了， 他们想 买进的进修要么静悄悄地， 要么想法引起大众的恐慌性抛售， 前者你会看到交易量增加， 但不明显， 股价慢慢地一步步升高， 后者便是搞一些大家公认的好卖点。<br>大户想卖的时候，要么先买进， 造成股价狂升，引发股民的贪念去抢搭轿子， 要么就搞一些公众们共认的好买点。<br>由于他们通常手握巨资， 要做到这些并不困难。便他们的动作必须会从股价的变动及交易量 的变动中露出尾巴，只要你有足够的经验， 你就明白怎样跟着玩。</p>\n</blockquote>\n<p>请再读一遍何时买股票， 何时卖股票这两节， 再体会一下“截短亏损， 让利润奔跑” 这句话， 炒股的诀窍尽在其中。</p>\n<h1 id=\"8-和炒手们聊天\"><a href=\"#8-和炒手们聊天\" class=\"headerlink\" title=\"8 和炒手们聊天\"></a>8 和炒手们聊天</h1><h2 id=\"8-1-学股的四个阶段\"><a href=\"#8-1-学股的四个阶段\" class=\"headerlink\" title=\"8.1 学股的四个阶段\"></a>8.1 学股的四个阶段</h2><blockquote>\n<p>第四阶段久赌必赢<br>一个可行的计划， 不能凭空想像， 它必须有理有据。“理” 就是数学的概率， 如果你每次下注的赢面<br>超过 50%， 而且你只下本金的小部分， 不会为几次坏运气就剃光头， 从长期而言你是 胜定了。 道理和开<br>赌场一样。“据” 在于你知道怎样找临界点， 在长期的观察和实践过程中， 你知道这些点是出入场的关键<br>点， 在这些点操作， 你的赢面超出 50%， 再加上应用“截短亏 损， 让利润奔跑” 的原则， 赢时赢大的，<br>亏时亏小的， 你的获胜概率其实远远超出了 50%。 到久赌必赢阶段， 你不应对亏钱和赚钱有任何情绪<br>上的波动。 你对止损不再痛苦， 你明白这 是游戏的一部分， 你对赚钱也不再喜悦， 你知道这是必然结果。<br>你不再将胜负放在心上， 你 只注重在正确的时间， 做正确的事情。 你知道利润会随之而来。</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<h1 id=\"本书大纲\"><a href=\"#本书大纲\" class=\"headerlink\" title=\"本书大纲\"></a>本书大纲</h1><blockquote>\n<ul>\n<li>第一章就谈些股市的特性及它对人性的挑战。 </li>\n<li>第二章讲一些和炒股最直接相关的知识。读者应带着两个疑问来读这一章： 一，什么是影响股价的因素；二， 股票在什么情况下运动正常。 这一章包括三个部分； 基本分析、 技术分析及股票的大市。 当这三部分的分析都给你下面信号的时候，是你在股市胜算最大的时候。 </li>\n<li>第三章谈成功的要素。它告诉你炒股成功应做到什么及怎样做， 还告诉你应该具备什么样的心理素质。 知道什么该做并不难， 难在怎么在实践中做好它。 </li>\n<li>第四章是何时买卖股票。在这一章你看不到“ 低点买入要谨慎， 高点卖出不要贪” 之类的废话，什么时候才是低？ 高到多高才是高？ 在办公室空想出来的炒股绝招没有什么实用价值。 <strong><em>买卖股票的要点在于怎么寻找“临界点”。</em></strong> 希望这章能改变你炒股的整个思维方式。 </li>\n<li>第五章是华尔街的家训。牛顿说：“我所以能看得更远， 是因为我站在巨人的肩膀上。” 在这一章， 让我们看看炒股这行的先辈们给我们留下了什么经验。 </li>\n<li>第六章谈心理建设。人性中根深蒂固的恐惧、 希望、 贪婪影响着我们所做的每一个决定， 使我们常常做不到自己知道应该做的事。 要完全克服人性中的弱点是很困难的， 但我们首先必须知道它是什么及什么是正确的做法。 </li>\n<li>第七章分析了什么是大机会及其特点。 读完这一章你就明白了我在谈什么。 这里不只是在谈股票。  </li>\n<li>第八章是和炒手谈谈天。在这一章我简述了我的学股历程。 如果人性共通的说法不错的话，你学股走过的道路应和我相似。 希望你在学股的挣扎过程中因为有了路标而能显得平顺一些。  </li>\n<li>附录：在今天的社会，我看到很多人为金钱不择手段。 而这本又是教人怎样赚钱的书， 不加点“金 钱的反思”让我觉得这本书不够均衡。 如果因为这一附录能使读者对人生有更进一步的认识，我会觉得努力没有白费。</li>\n</ul>\n</blockquote>\n<h1 id=\"精彩语句\"><a href=\"#精彩语句\" class=\"headerlink\" title=\"精彩语句\"></a>精彩语句</h1><blockquote>\n<ul>\n<li>买卖股票的要点在于怎么寻找“临界点”。 </li>\n<li>截短亏损，让利润奔跑！ </li>\n<li>关注股票的正常运动、不正常运动和周期运动</li>\n<li>有理有据：理就是获胜的概率，据在于你知道怎样找临界点。</li>\n<li>不要心存幻想，必须牢牢记住： 股市从来都不会错，它总是走自己要走的路，会错的只有人自己。</li>\n<li>正确地感悟股票运动何时正常是最难学的，这也是炒股成功最关键的技巧之一。随着经验的增加，你的悟性越来越好，对股票运动的判断力越来越强，你就能将每次入场的获胜概率从 50%提高到 60%，甚至 70%，慢慢地你就成了炒股专家。要准备”熬”。 </li>\n<li>你的资金总是在盈利机会最大的时候才留在场内。–何时卖，等重新突破前高，再重新买入，而不是抄底！！！</li>\n<li>你如果能够做到仅在临界买点入场，临界卖点出场，入场时牢记止损，并注意分摊风险，你的成功的概率就能提至最高，你也就真正成为炒股专家了。","more":"</li>\n</ul>\n</blockquote>\n<h1 id=\"人性的弱点\"><a href=\"#人性的弱点\" class=\"headerlink\" title=\"人性的弱点\"></a>人性的弱点</h1><p>好获小利，不吃小亏<br>人性讨厌风险<br>人好自以为是<br>人好跟风  –必须自己建立规则， 并完全由自己为这些规则 所产生的后果负责<br>人好因循守旧<br>人好报复</p>\n<h1 id=\"技术分析\"><a href=\"#技术分析\" class=\"headerlink\" title=\"技术分析\"></a>技术分析</h1><ul>\n<li>走势图（上升、下降、无势图）</li>\n<li>支撑线和阻力线</li>\n<li>双肩图和头肩图，倒双肩和倒头肩</li>\n<li>均线</li>\n<li>综合看图</li>\n</ul>\n<h1 id=\"炒股成功的基本要诀\"><a href=\"#炒股成功的基本要诀\" class=\"headerlink\" title=\"炒股成功的基本要诀\"></a>炒股成功的基本要诀</h1><ul>\n<li>保本，止损，分批建仓</li>\n<li>不断盈利，反例:读者们若有机会到赌场看看， 就明白股民们为什么会这样做。 赌客们站在赌台旁， 一注都不肯放过， 生怕下一手就是自己赢钱的机会。 直到输完才会收手。</li>\n<li>赚大钱<blockquote>\n<p>为什么失去赚大钱的机会：<br>  一， 人好小便宜;<br>  二， 不够经验判断股票运动是否正常<br>  另一点要强调的是： 如果你确定股票运动正常， 你的胜算很大， 这时你应该在这只股票上适 当加大下注的比重。 </p>\n</blockquote>\n</li>\n<li>资金管理，怎样下注<blockquote>\n<p>输得起多少<br>提高获胜的概率<br>抓住正常运动中的股票，参考例子<br>注意危险信号，突然大起大落</p>\n</blockquote>\n</li>\n</ul>\n<h1 id=\"正常运动与不正常运动的例子\"><a href=\"#正常运动与不正常运动的例子\" class=\"headerlink\" title=\"正常运动与不正常运动的例子\"></a>正常运动与不正常运动的例子</h1><blockquote>\n<ul>\n<li>如果股票开始一个上升的走势， 比如说准备从 20 元升到 50 元。 你将发现走势开始的前几<br>天， 交易量突然增加， 股价开始攀升， 几天以后， 升势停止， 开始下跌。 这是“正常” 的获利回 吐， 下<br>跌时的交易量较上升时显著减少。 读者朋友， 这个下调是很正常的， 属正常运动， 千 万不要在这个时候<br>将股票卖掉。 如果这只股票具有上冲的潜力， 你会发现在几天内股票又开 始活跃， 交易量又开始增加，<br>上次“自然调低” 所失去的“领土” 应在短时间内收复， 股票 开始冲到新的高度。 这次运动将持续一段<br>时间， 其间每日通常是收盘价高过开盘价， 偶尔收 盘价低过开盘价， 其差额通常不大； 交易量也不会有<br>显著的变化， 通常情况是减少。 或迟或 早， 股票又会开始下跌， 这是新一轮的“ 获利回吐” 。 这次获利<br>回吐的股票运动和交易量的特 点应该和第一次很相似。 上述是股票走升势的正常运动。 下面的图显示出<br>它们应有的特点。 如果读者觉得还很抽象的话， 我以下用数字来描述一遍， 因为掌握股票正常运动的<br>特点对炒 股成功是极其重要的。 在股票 20 元的时候， 交易量增加， 可以是平时的一两倍， 股价从 20 元<br>升到 21， 22， 甚至 27 元。 这几天的交易量较前段时间显著增加是其特征。 到 27 元时升势 可能停顿，<br>随之开始下调， 股价走势为 27-&gt;26-&gt;24 元。 这段时间的交易量应较从 20 升到 27 元时的平均交易量为<br>少， 即股票从 20-&gt;27 元时买盘大过卖盘， 从 27-&gt;24 元时的卖盘大过买 盘。 但这如果是正常的升势，<br>从 20-&gt;27-&gt;24 这段时间总的买盘大过卖盘。 在 24 元徘徊几天 后， 股票应开始上升， 交易量又开始增<br>加， 这次上冲应很快超过 27 元， 股价走势为 24-&gt;25-&gt;27-&gt;35 元。 当股票冲到 35 元时， 又开始停顿，<br>随之下调， 重复第一阶段的运动。 这次下调同样应有交易量减少的特点。<br>一只正常运动的股票， 每次上冲的强度通常较上一次更为猛烈。 以我们这个例子， 当股票再 次冲破 35<br>元时， 应很容易地直冲到 45 元或 50 元， 其间不会感觉到有很大障碍。 反调是正常 的。 一位专业炒手<br>决不能在正常回调的时候被吓出场。 入场后开始有利润了， 每次回调都意 味着纸上利润的减少。 常人的<br>第一感觉就是赶快卖掉获利。 这是新手的显著特点。 这也是新 手很难在股市赚到大钱的原因。<br>炒手的任务不仅仅在于确认何时股票运动正常， 同样重要的是要能认识股票何时运动不正常。 股票<br>这种前进两步、 退后一步的过程可能延续一段时间， 有时可能是很长的一段时间。 这段时间炒手或许在精<br>神上会松懈下来， 这是要不得的。 因为往往在你松懈下来的时候， 股票的 运动发生变化。 股票缓缓地周<br>期性上升， 突然有一天， 股票狂涨， 从 50 元一下子升到 55 元， 第二天升到 62 元， 这两天交易量突<br>然大增， 但在第二天收市的前半小时股票从 62 元跌回 58 元收盘。 第三天开市一样强劲， 股票一下子升<br>到 64 元， 但第四天， 股票似乎失去了冲劲， 它 跌回了 61 元（ 如下图）。</li>\n</ul>\n<ul>\n<li>我是这样理解这一现象的： 股票运动后面的主要力量是大户， 这些大户通常是手握巨资的基金或保险<br>公司等。 当这些基金的管理人看好这只股票， 开始吸纳， 你将看到交易量上升， 股 价上升。 通常这些基<br>金管理人在吸纳股票时， 并不希望引起大众的注意， 所以这一过程通常 是缓慢的， 它不会上报纸或电视<br>的头条。 一旦这些大户吸股完毕， 你通常会听到他们开始公 开地推荐这些股票， 引起大众的注意。 这些<br>大户们的信息通常较普通人灵通， 他们也会很快 看到公司有好消息公布， 如开发成功新产品， 盈利较预<br>期为好等。 等到这些大户觉得好消息 已全部反映在股价之中， 他们开始准备脱手。 由于他们手中握有的<br>股票数量通常很大， 如果 一下子砸进市场， 市场根本承受不了， 他们手中的股票很大部分只能在低价出<br>手。 为了解决 这一问题， 他们要找傻瓜用高价来承接这些股票。 找傻瓜的最佳途径就是令股价暴升， 暴<br>升 时通常伴随点好消息， 如公司任命新董事长了， 某证券商强力推荐该股票了等等。 报纸电视 整天重复<br>这些消息， 引发小股民峰拥入市。 想想看， 小股民因股价暴升而引发贪念入市时买 的股票都是谁卖的？<br>一旦大户找足傻瓜， 全身而退， 还去哪里找大买主把股价继续推高？ 你现在明白了股票的正常运动及<br>危险信号后面的理由了吗？ 我一直强调， 炒股是艺术， 不是 科学。 当不正常的信号灯亮起， 是否表示这<br>只股票就一定要下跌？ 答案是：“否！” 没有人能 够在任何时候百分之百地肯定股票明天会怎么样， 也许<br>暴升的理由是公司真的发明了长生不 老药！ 你必须将股票的运动和公司的发展综合起来考虑。 让我重复<br>一次： 炒股的最基本信条 是在任何时候， 你手上持有股票的上升潜力必须大过下跌的可能， 否则你就不<br>应留在手里。 看到危险信号， 表示你的获胜概率此时已不超出 50%。 每位严肃的炒手都必须注意危<br>险信号， 但问题是在内心深处总有些奇怪的力量使他们在该卖 出的时候提不起勇气这么做。 或许是侥幸<br>心理在作怪。 在迟疑的这段时间， 他们常看到股票 又跌了好多点， 这时他们会拍着脑袋， 大骂自己傻瓜，<br>同时发誓一旦股票一有反弹就走人， “股票跌了这么多， 该会有个小反弹吧？ ” 但反弹来到的时候， 他<br>们又忘记了自己的誓言， 因为在他们眼睛里， 这时股票的运动又开始“正常” 起来。 通常， 这样的反弹<br>仅是股票在下 跌路上的喘气， 它很快就要继续要走的路。 人性有很多缺陷。 人希望股票会怎么运动， 认<br>定 股票会怎么运动， 当股票的运动和预想不符合时， 就会认为股市错了， 自己没有错。 但炒友 们必须牢<br>牢记住： 股市从来都不会错， 它总是走自己要走的路， 会错的只有人自己。 你所能做 的只有追随股市。<br>见到危险信号， 不要三心二意， 不要存有幻想， 把股票全部脱手。 几天以 后， 也许一切又恢复正常， 你<br>一样可以重新入场。 如果能这样做， 你将发现你为自己省下了很多焦虑及学费。</li>\n</ul>\n</blockquote>\n<h1 id=\"3-3-成功投资者所具有的共性\"><a href=\"#3-3-成功投资者所具有的共性\" class=\"headerlink\" title=\"3-3 成功投资者所具有的共性\"></a>3-3 成功投资者所具有的共性</h1><blockquote>\n<p>要有成为投资专家的欲望<br>必须具备锲而不舍的精神<br>要有“ 与股市斗， 其乐无穷” 的气派<br>要甘于做孤独者<br>必须具有耐心和自制力<br><strong>必须有一套适合自己的炒股模式</strong><br>必须具有超前的想像力及对未来的判断<br>成功的投资者绝不幻想<br>要有应用知识的毅力   </p>\n</blockquote>\n<p>一位成功的投资者， 他应十分留意怎样将他的知识应用在炒股中， 他不会为应用这些知识的 枯燥而<br>忽略细节。 在日常生活中， 获得知识通常并不困难， 困难在于用毅力应用这些知识。 在炒股问题上， 我<br>是坚信“知易行难” 之说的。</p>\n<h1 id=\"4-何时买卖股票\"><a href=\"#4-何时买卖股票\" class=\"headerlink\" title=\"4 何时买卖股票\"></a>4 何时买卖股票</h1><p>学习寻找临界点的过程其实就是学股的过程， 当然其中还包括学习炒股的正确心态。华尔街将炒股的诀巧归纳成两句话： 截短亏损，让利润奔跑！<br>关于人性的思考，自我的突破 </p>\n<h2 id=\"4-1-何时买-！！！-一定要多读透彻\"><a href=\"#4-1-何时买-！！！-一定要多读透彻\" class=\"headerlink\" title=\"4.1 何时买 ！！！ 一定要多读透彻\"></a>4.1 何时买 ！！！ 一定要多读透彻</h2><blockquote>\n<p>如何选股<br>选股之后，如何进场<br>如何设置止损点</p>\n<h2 id=\"4-2-何时卖-！！！-一定要多读透彻\"><a href=\"#4-2-何时卖-！！！-一定要多读透彻\" class=\"headerlink\" title=\"4.2 何时卖 ！！！ 一定要多读透彻\"></a>4.2 何时卖 ！！！ 一定要多读透彻</h2><p>何时卖股票的考虑可以分成两部分： 一， 刚进股时怎样选止损点； 二， 有利润后怎样选择合 适的卖点获利。<br><strong>买今天在上涨的股票：我自己喜欢把止损点定在入市当天的最低点。 比如我今天以 10.75 元买 进股票， 今天的最高价是 11 元， 最低价是 10 元， 我便以 10 元作为止损点。 以我的经验， 如 果我的入场点选的正确，股票开始上升， 它不应跌回我当天入场的最低点。</strong></p>\n<p>庄家的把戏<br>大户们操纵股票其实就是那么几招， 你只要专心， 观察股票的运动和交易量的变 化， 想像你是大户的话会怎么调动公众的心理， 大户的花招其实明显的很。<br>讲白了， 他们想 买进的进修要么静悄悄地， 要么想法引起大众的恐慌性抛售， 前者你会看到交易量增加， 但不明显， 股价慢慢地一步步升高， 后者便是搞一些大家公认的好卖点。<br>大户想卖的时候，要么先买进， 造成股价狂升，引发股民的贪念去抢搭轿子， 要么就搞一些公众们共认的好买点。<br>由于他们通常手握巨资， 要做到这些并不困难。便他们的动作必须会从股价的变动及交易量 的变动中露出尾巴，只要你有足够的经验， 你就明白怎样跟着玩。</p>\n</blockquote>\n<p>请再读一遍何时买股票， 何时卖股票这两节， 再体会一下“截短亏损， 让利润奔跑” 这句话， 炒股的诀窍尽在其中。</p>\n<h1 id=\"8-和炒手们聊天\"><a href=\"#8-和炒手们聊天\" class=\"headerlink\" title=\"8 和炒手们聊天\"></a>8 和炒手们聊天</h1><h2 id=\"8-1-学股的四个阶段\"><a href=\"#8-1-学股的四个阶段\" class=\"headerlink\" title=\"8.1 学股的四个阶段\"></a>8.1 学股的四个阶段</h2><blockquote>\n<p>第四阶段久赌必赢<br>一个可行的计划， 不能凭空想像， 它必须有理有据。“理” 就是数学的概率， 如果你每次下注的赢面<br>超过 50%， 而且你只下本金的小部分， 不会为几次坏运气就剃光头， 从长期而言你是 胜定了。 道理和开<br>赌场一样。“据” 在于你知道怎样找临界点， 在长期的观察和实践过程中， 你知道这些点是出入场的关键<br>点， 在这些点操作， 你的赢面超出 50%， 再加上应用“截短亏 损， 让利润奔跑” 的原则， 赢时赢大的，<br>亏时亏小的， 你的获胜概率其实远远超出了 50%。 到久赌必赢阶段， 你不应对亏钱和赚钱有任何情绪<br>上的波动。 你对止损不再痛苦， 你明白这 是游戏的一部分， 你对赚钱也不再喜悦， 你知道这是必然结果。<br>你不再将胜负放在心上， 你 只注重在正确的时间， 做正确的事情。 你知道利润会随之而来。</p>\n</blockquote>"},{"title":"Zookeeper 监控","date":"2017-08-20T12:07:50.000Z","_content":"ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n# Zookeeper 命令行监控方法  \n[zookeeper monitor](http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands \"zookeeper 4字节命令监控\")\n\n常见四字命令：\n* `echo stat|nc 127.0.0.1 2181 `来查看哪个节点被选择作为follower或者leader\n* `echo ruok|nc 127.0.0.1 2181 `测试是否启动了该Server，若回复imok表示已经启动。\n* `echo cons | nc 127.0.0.1 2181 `列出所有连接到服务器的客户端的完全的连接/会话的详情。\n* `echo wchs | nc 127.0.0.1 2181 `列出服务器 watch 的详细信息。\n\n<!-- more -->\n\n# Zookeeper Jmx监控方法  \n需先启用JMX端口。修改zookeeper的启动脚本vim zkServer.sh。找到启动参数ZOOMAIN，修改为下面值。其中local.only=false，设为false才能在远程建立连接。\n可使用Jconsole 通过IP、jmx端口连接到Zookeeper。","source":"_posts/zookeeper-monitor.md","raw":"---\ntitle: Zookeeper 监控\ndate: 2017-08-20 20:07:50\ntags: \n - Zookeeper\n - Monitor \ncategory: 技术 \n---\nZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\n# Zookeeper 命令行监控方法  \n[zookeeper monitor](http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands \"zookeeper 4字节命令监控\")\n\n常见四字命令：\n* `echo stat|nc 127.0.0.1 2181 `来查看哪个节点被选择作为follower或者leader\n* `echo ruok|nc 127.0.0.1 2181 `测试是否启动了该Server，若回复imok表示已经启动。\n* `echo cons | nc 127.0.0.1 2181 `列出所有连接到服务器的客户端的完全的连接/会话的详情。\n* `echo wchs | nc 127.0.0.1 2181 `列出服务器 watch 的详细信息。\n\n<!-- more -->\n\n# Zookeeper Jmx监控方法  \n需先启用JMX端口。修改zookeeper的启动脚本vim zkServer.sh。找到启动参数ZOOMAIN，修改为下面值。其中local.only=false，设为false才能在远程建立连接。\n可使用Jconsole 通过IP、jmx端口连接到Zookeeper。","slug":"zookeeper-monitor","published":1,"updated":"2018-04-27T04:11:03.373Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjhajczpp001ge4rw72egfcwg","content":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<h1 id=\"Zookeeper-命令行监控方法\"><a href=\"#Zookeeper-命令行监控方法\" class=\"headerlink\" title=\"Zookeeper 命令行监控方法\"></a>Zookeeper 命令行监控方法</h1><p><a href=\"http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands\" title=\"zookeeper 4字节命令监控\" target=\"_blank\" rel=\"external\">zookeeper monitor</a></p>\n<p>常见四字命令：</p>\n<ul>\n<li><code>echo stat|nc 127.0.0.1 2181</code>来查看哪个节点被选择作为follower或者leader</li>\n<li><code>echo ruok|nc 127.0.0.1 2181</code>测试是否启动了该Server，若回复imok表示已经启动。</li>\n<li><code>echo cons | nc 127.0.0.1 2181</code>列出所有连接到服务器的客户端的完全的连接/会话的详情。</li>\n<li><code>echo wchs | nc 127.0.0.1 2181</code>列出服务器 watch 的详细信息。</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"Zookeeper-Jmx监控方法\"><a href=\"#Zookeeper-Jmx监控方法\" class=\"headerlink\" title=\"Zookeeper Jmx监控方法\"></a>Zookeeper Jmx监控方法</h1><p>需先启用JMX端口。修改zookeeper的启动脚本vim zkServer.sh。找到启动参数ZOOMAIN，修改为下面值。其中local.only=false，设为false才能在远程建立连接。<br>可使用Jconsole 通过IP、jmx端口连接到Zookeeper。</p>\n","site":{"data":{}},"excerpt":"<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>\n<h1 id=\"Zookeeper-命令行监控方法\"><a href=\"#Zookeeper-命令行监控方法\" class=\"headerlink\" title=\"Zookeeper 命令行监控方法\"></a>Zookeeper 命令行监控方法</h1><p><a href=\"http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands\" title=\"zookeeper 4字节命令监控\" target=\"_blank\" rel=\"external\">zookeeper monitor</a></p>\n<p>常见四字命令：</p>\n<ul>\n<li><code>echo stat|nc 127.0.0.1 2181</code>来查看哪个节点被选择作为follower或者leader</li>\n<li><code>echo ruok|nc 127.0.0.1 2181</code>测试是否启动了该Server，若回复imok表示已经启动。</li>\n<li><code>echo cons | nc 127.0.0.1 2181</code>列出所有连接到服务器的客户端的完全的连接/会话的详情。</li>\n<li><code>echo wchs | nc 127.0.0.1 2181</code>列出服务器 watch 的详细信息。</li>\n</ul>","more":"<h1 id=\"Zookeeper-Jmx监控方法\"><a href=\"#Zookeeper-Jmx监控方法\" class=\"headerlink\" title=\"Zookeeper Jmx监控方法\"></a>Zookeeper Jmx监控方法</h1><p>需先启用JMX端口。修改zookeeper的启动脚本vim zkServer.sh。找到启动参数ZOOMAIN，修改为下面值。其中local.only=false，设为false才能在远程建立连接。<br>可使用Jconsole 通过IP、jmx端口连接到Zookeeper。</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjhajczof000be4rww9peqwrt","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczop000ie4rwtu7k89jk"},{"post_id":"cjhajczo60004e4rwozbl2dwd","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczor000le4rwqyh3p0nz"},{"post_id":"cjhajczod0009e4rwm9mn90tf","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczou000pe4rwc0wkr6ce"},{"post_id":"cjhajczos000me4rwfi9ljy1r","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczp0000ue4rwnp3lxac1"},{"post_id":"cjhajczoy000se4rwaasmefg4","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczp4000ze4rwdgx9by9b"},{"post_id":"cjhajczp50011e4rwtcresxyd","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczpb0018e4rwak0up7xm"},{"post_id":"cjhajczp70014e4rwpju9ryqs","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczpf001be4rw56qym44c"},{"post_id":"cjhajczp90016e4rwbgwkji48","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczpo001fe4rwif4sk2uc"},{"post_id":"cjhajczpc0019e4rwe273vqqw","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczpu001ie4rwdnlv1u3e"},{"post_id":"cjhajczpp001ge4rw72egfcwg","category_id":"cjhajczoc0007e4rw4adiezct","_id":"cjhajczpz001le4rwpxw49tb6"}],"PostTag":[{"post_id":"cjhajcznm0000e4rwcj6fy8zu","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczoc0008e4rwb9oxiltv"},{"post_id":"cjhajczo80005e4rw9po13kw9","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczoe000ae4rwtwlq1k7t"},{"post_id":"cjhajcznv0001e4rwxsxtyr3d","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczoi000de4rw8tpakbvr"},{"post_id":"cjhajczo30003e4rw5oibrebo","tag_id":"cjhajczof000ce4rwn2l1g5yc","_id":"cjhajczor000ke4rwgz8nbvpw"},{"post_id":"cjhajczon000ge4rw29ef8d1k","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczot000ne4rwek86cain"},{"post_id":"cjhajczoq000je4rw5qye8mqf","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczox000re4rwwm07hpou"},{"post_id":"cjhajczov000qe4rws0y5ozjl","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczoz000te4rw66g580mv"},{"post_id":"cjhajczod0009e4rwm9mn90tf","tag_id":"cjhajczon000he4rwepopz7ng","_id":"cjhajczp2000xe4rws2bhy6na"},{"post_id":"cjhajczod0009e4rwm9mn90tf","tag_id":"cjhajczou000oe4rwqqx1geo3","_id":"cjhajczp40010e4rwbfy2k6hy"},{"post_id":"cjhajczp0000we4rwkfbth5ah","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczp70013e4rw9x0ae913"},{"post_id":"cjhajczp2000ye4rw357hwar7","tag_id":"cjhajczo20002e4rw2n47g46z","_id":"cjhajczp80015e4rwiuqw5das"},{"post_id":"cjhajczof000be4rww9peqwrt","tag_id":"cjhajczp0000ve4rwglzurwvf","_id":"cjhajczpe001ae4rwpgu193x4"},{"post_id":"cjhajczof000be4rww9peqwrt","tag_id":"cjhajczp60012e4rwtx9wiucm","_id":"cjhajczpm001de4rwtapvgvk6"},{"post_id":"cjhajczoj000ee4rwob7rym5n","tag_id":"cjhajczpa0017e4rw2en13wmp","_id":"cjhajczpt001he4rwadjs8yd6"},{"post_id":"cjhajczos000me4rwfi9ljy1r","tag_id":"cjhajczpn001ee4rwz83649iv","_id":"cjhajczpx001ke4rwnny85hho"},{"post_id":"cjhajczoy000se4rwaasmefg4","tag_id":"cjhajczpw001je4rwytcxdcy7","_id":"cjhajczq3001oe4rw6tr48c0i"},{"post_id":"cjhajczoy000se4rwaasmefg4","tag_id":"cjhajczq0001me4rw705w7u7q","_id":"cjhajczq4001pe4rwdzv6kzsz"},{"post_id":"cjhajczp50011e4rwtcresxyd","tag_id":"cjhajczq1001ne4rwygrxg4ce","_id":"cjhajczq9001se4rw62qrfrqo"},{"post_id":"cjhajczp50011e4rwtcresxyd","tag_id":"cjhajczq0001me4rw705w7u7q","_id":"cjhajczqa001te4rwo0rq7aja"},{"post_id":"cjhajczp70014e4rwpju9ryqs","tag_id":"cjhajczq7001re4rwnop7ijvo","_id":"cjhajczqb001ve4rwcln454v3"},{"post_id":"cjhajczp90016e4rwbgwkji48","tag_id":"cjhajczqa001ue4rw5nk2ouo8","_id":"cjhajczqe0020e4rwb1tcugfw"},{"post_id":"cjhajczp90016e4rwbgwkji48","tag_id":"cjhajczqb001we4rwaloy9umt","_id":"cjhajczqe0021e4rwvjkmmsap"},{"post_id":"cjhajczp90016e4rwbgwkji48","tag_id":"cjhajczqb001xe4rwqpg8ts4z","_id":"cjhajczqf0023e4rw29e9v87n"},{"post_id":"cjhajczp90016e4rwbgwkji48","tag_id":"cjhajczq0001me4rw705w7u7q","_id":"cjhajczqf0024e4rwwzy7w79y"},{"post_id":"cjhajczpc0019e4rwe273vqqw","tag_id":"cjhajczqd001ze4rwemq0y6sh","_id":"cjhajczqj0026e4rwe8td5u5q"},{"post_id":"cjhajczpc0019e4rwe273vqqw","tag_id":"cjhajczqe0022e4rwko3973u6","_id":"cjhajczqj0027e4rw66c6xwsv"},{"post_id":"cjhajczpp001ge4rw72egfcwg","tag_id":"cjhajczqh0025e4rwy17gbqrf","_id":"cjhajczqk0028e4rwxb2es7tc"},{"post_id":"cjhajczpp001ge4rw72egfcwg","tag_id":"cjhajczou000oe4rwqqx1geo3","_id":"cjhajczqk0029e4rwrtpq1cef"}],"Tag":[{"name":"随笔","_id":"cjhajczo20002e4rw2n47g46z"},{"name":"Google","_id":"cjhajczof000ce4rwn2l1g5yc"},{"name":"Elasticsearch","_id":"cjhajczon000he4rwepopz7ng"},{"name":"Monitor","_id":"cjhajczou000oe4rwqqx1geo3"},{"name":"Git","_id":"cjhajczp0000ve4rwglzurwvf"},{"name":"GitHub","_id":"cjhajczp60012e4rwtx9wiucm"},{"name":"Hexo","_id":"cjhajczpa0017e4rw2en13wmp"},{"name":"LAMP","_id":"cjhajczpn001ee4rwz83649iv"},{"name":"Open-falcon","_id":"cjhajczpw001je4rwytcxdcy7"},{"name":"Go","_id":"cjhajczq0001me4rw705w7u7q"},{"name":"Prometheus","_id":"cjhajczq1001ne4rwygrxg4ce"},{"name":"Python","_id":"cjhajczq7001re4rwnop7ijvo"},{"name":"TICK","_id":"cjhajczqa001ue4rw5nk2ouo8"},{"name":"InfluxDB","_id":"cjhajczqb001we4rwaloy9umt"},{"name":"Telegraf","_id":"cjhajczqb001xe4rwqpg8ts4z"},{"name":"Sensu","_id":"cjhajczqd001ze4rwemq0y6sh"},{"name":"Ruby","_id":"cjhajczqe0022e4rwko3973u6"},{"name":"Zookeeper","_id":"cjhajczqh0025e4rwy17gbqrf"}]}}